<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0" xml:base="https://news.mit.edu">
  <channel>
    <title>MIT News - Brain and cognitive sciences | Neuroscience</title>
    <link>https://news.mit.edu/rss/topic/neuroscience-neurology-and-cognitive-sciences</link>
    <atom:link href="https://news.mit.edu/rss/topic/neuroscience-neurology-and-cognitive-sciences" rel="self" type="application/rss+xml"/>
    <description>MIT news feed about: Brain and cognitive sciences | Neuroscience</description>
    <language>en</language>
    
    <lastBuildDate>Thu, 27 Feb 2025 17:00:00 -0500</lastBuildDate>
    <item>
  <title>Study suggests new molecular strategy for treating fragile X syndrome</title>
  <link>https://news.mit.edu/2025/study-suggests-new-molecular-strategy-treating-fragile-x-syndrome-0304</link>
  <description><![CDATA[Enhancing activity of a specific component of neurons’ “NMDA” receptors normalized protein synthesis, neural activity, and seizure susceptibility in the hippocampus of fragile X lab mice.]]></description>
  <pubDate>Tue, 04 Mar 2025 15:55:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/study-suggests-new-molecular-strategy-treating-fragile-x-syndrome-0304</guid>
        <dc:creator>David Orenstein | The Picower Institute for Learning and Memory</dc:creator>
  <content:encoded>&lt;p&gt;Building on more than two decades of research, a study by MIT neuroscientists at The Picower Institute for Learning and Memory reports a new way to treat pathology and symptoms of fragile X syndrome, the most common genetically-caused autism spectrum disorder. The team showed that augmenting a novel type of neurotransmitter signaling reduced hallmarks of fragile X in mouse models of the disorder.&lt;/p&gt;&lt;p&gt;The new approach, &lt;a href="https://www.sciencedirect.com/science/article/pii/S2211124725000828?via%3Dihub" target="_blank"&gt;described in &lt;em&gt;Cell Reports&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; works by targeting a specific molecular subunit of “NMDA” receptors that they discovered plays a key role in how neurons synthesize proteins to regulate their connections, or “synapses,” with other neurons in brain circuits.&amp;nbsp;The scientists showed that in fragile X model mice, increasing the receptor’s activity caused neurons in the hippocampus region of the brain to increase molecular signaling that suppressed excessive bulk protein synthesis, leading to other key improvements.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Setting the table&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“One of the things I find most satisfying about this study is that the pieces of the puzzle fit so nicely into what had come before,” says study senior author &lt;a href="https://picower.mit.edu/mark-bear" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Mark Bear&lt;/a&gt;, Picower Professor in MIT’s Department of Brain and Cognitive Sciences. Former postdoc Stephanie Barnes, now a lecturer at the University of Glasgow, is the study’s lead author.&lt;/p&gt;&lt;p&gt;Bear’s lab studies how neurons continually edit their circuit connections, a process called “synaptic plasticity” that scientists believe to underlie the brain’s ability to adapt to experience and to form and process memories. These studies led to two discoveries that set the table for the newly published advance. In 2011, Bear’s lab showed that fragile X and another autism disorder, tuberous sclerosis (Tsc), &lt;a href="https://www.nature.com/articles/nature10658" target="_blank"&gt;represented two ends of a continuum&lt;/a&gt; of a kind of protein synthesis in the same neurons. In fragile X there was too much. In Tsc there was too little. When lab members crossbred fragile X and Tsc mice, in fact, their offspring emerged healthy, as the mutations of each disorder essentially canceled each other out.&lt;/p&gt;&lt;p&gt;More recently, Bear’s lab showed a different dichotomy. It has long been understood from their influential work in the 1990s that the flow of calcium ions through NMDA receptors can trigger a form of synaptic plasticity called “long-term depression” (LTD). But in 2020, they found that another mode of signaling by the receptor — one that did not require ion flow — &lt;a href="https://picower.mit.edu/news/findings-weaken-notion-size-equals-strength-neural-connections" target="_blank"&gt;altered protein synthesis in the neuron&lt;/a&gt; and caused a physical shrinking of the dendritic “spine” structures housing synapses.&lt;/p&gt;&lt;p&gt;For Bear and Barnes, these studies raised the prospect that if they could pinpoint how NMDA receptors affect protein synthesis they might identify a new mechanism that could be manipulated therapeutically to address fragile X (and perhaps tuberous sclerosis) pathology and symptoms. That would be an important advance to complement &lt;a href="https://picower.mit.edu/discoveries/molecular-approach-autism" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;ongoing work&lt;/a&gt; Bear’s lab has done to correct fragile X protein synthesis levels via another receptor called mGluR5.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Receptor dissection&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In the new study, Bear and Barnes’ team decided to use the non-ionic effect on spine shrinkage as a readout to dissect how NMDARs signal protein synthesis for synaptic plasticity in hippocampus neurons. They hypothesized that the dichotomy of ionic effects on synaptic function and non-ionic effects on spine structure might derive from the presence of two distinct components of NMDA receptors: “subunits” called GluN2A and GluN2B. To test that, they used genetic manipulations to knock out each of the subunits. When they did so, they found that knocking out “2A” or “2B” could eliminate LTD, but that only knocking out 2B affected spine size. Further experiments clarified that 2A and 2B are required for LTD, but that spine shrinkage solely depends on the 2B subunit.&lt;/p&gt;&lt;p&gt;The next task was to resolve how the 2B subunit signals spine shrinkage. A promising possibility was a part of the subunit called the “carboxyterminal domain,” or CTD. So, in a new experiment Bear and Barnes took advantage of a mouse that had been genetically engineered by researchers at the University of Edinburgh so that the 2A and 2B CTDs could be swapped with one another. A telling result was that when the 2B subunit lacked its proper CTD, the effect on spine structure disappeared. The result affirmed that the 2B subunit signals spine shrinkage via its CTD.&lt;/p&gt;&lt;p&gt;Another consequence of replacing the CTD of the 2B subunit was an increase in bulk protein synthesis that resembled findings in fragile X.&amp;nbsp;Conversely, augmenting the non-ionic signaling through the 2B subunit suppressed bulk protein synthesis, reminiscent of Tsc.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Treating fragile X&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Putting the pieces together, the findings indicated that augmenting signaling through the 2B subunit might, like introducing the mutation causing Tsc, rescue aspects of fragile X.&lt;/p&gt;&lt;p&gt;Indeed, when the scientists swapped in the 2B subunit CTD of NMDA receptor in fragile X model mice they found correction of not only the excessive bulk protein synthesis, but also altered synaptic plasticity, and increased electrical excitability that are hallmarks of the disease. To see if a treatment that targets NMDA receptors might be effective in fragile X, they tried an experimental drug called Glyx-13. This drug binds to the 2B subunit of NMDA receptors to augment signaling. The researchers found that this treatment can also normalize protein synthesis and reduced sound-induced seizures in the fragile X mice.&lt;/p&gt;&lt;p&gt;The team now hypothesizes, based on &lt;a href="https://www.jneurosci.org/content/30/46/15616" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;another prior study&lt;/a&gt; in the lab, that the beneficial effect to fragile X mice of the 2B subunit’s CTD signaling is that it shifts the balance of protein synthesis away from an all-too-efficient translation of short messenger RNAs (which leads to excessive bulk protein synthesis) toward a lower-efficiency translation of longer messenger RNAs.&lt;/p&gt;&lt;p&gt;Bear says he does not know what the prospects are for Glyx-13 as a clinical drug, but he noted that there are some drugs in clinical development that specifically target the 2B subunit of NMDA receptors.&lt;/p&gt;&lt;p&gt;In addition to Bear and Barnes, the study’s other authors are Aurore Thomazeau, Peter Finnie, Max Heinreich, Arnold Heynen, Noboru Komiyama, Seth Grant, Frank Menniti, and Emily Osterweil.&lt;/p&gt;&lt;p&gt;The FRAXA Foundation, The Picower Institute for Learning and Memory, The Freedom Together Foundation, and the National Institutes of Health funded the study.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202502/dendrites-micrograph.jpg?itok=5EAWVlt4" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Observations of the small protrusions that line the dendrites of neurons, called spines, provided a critical readout of the function of the cells' NMDA receptors in the new study, as well as in a precursor to the research back in 2020. This is a two-photon microscope image, which is approaching the limits of optical imaging (hence its blurriness). ]]></media:description>
              <media:credit> Image: Stepanie Barnes/MIT Bear Lab</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/autism">Autism</category>
      <category domain="https://news.mit.edu/topic/proteins">Proteins</category>
      <category domain="https://news.mit.edu/topic/drug-discovery">Drug discovery</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Designing better ways to deliver drugs</title>
  <link>https://news.mit.edu/2025/better-way-deliver-drugs-louis-deridder-0304</link>
  <description><![CDATA[Graduate student and MathWorks Fellow Louis DeRidder is developing a device to make chemotherapy dosing more accurate for individual patients.]]></description>
  <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/better-way-deliver-drugs-louis-deridder-0304</guid>
        <dc:creator>Michaela Jarvis | School of Engineering</dc:creator>
  <content:encoded>&lt;p&gt;When Louis DeRidder was 12 years old, he had a medical emergency that nearly cost him his life. The terrifying experience gave him a close-up look at medical care and made him eager to learn more.&lt;/p&gt;&lt;p&gt;“You can’t always pinpoint exactly what gets you interested in something, but that was a transformative moment,” says DeRidder.&lt;/p&gt;&lt;p&gt;In high school, he grabbed the chance to participate in a medicine-focused program, spending about half of his days during his senior year in high school learning about medical science and shadowing doctors.&lt;/p&gt;&lt;p&gt;DeRidder was hooked. He became fascinated by the technologies that make treatments possible and was particularly interested in how drugs are delivered to the brain, a curiosity that sparked a lifelong passion.&lt;/p&gt;&lt;p&gt;“Here I was, a 17-year-old in high school, and a decade later, that problem still fascinates me,” he says. “That’s what eventually got me into the drug delivery field.”&lt;/p&gt;&lt;p&gt;DeRidder’s interests led him to transfer half-way through his undergraduate studies to Johns Hopkins University, where he performed research he had proposed in a Goldwater Scholarship proposal. The research focused on the development of a nanoparticle-drug conjugate to deliver a drug to brain cells in order to transform them from a pro-inflammatory to an anti-inflammatory phenotype. Such a technology could be valuable in the treatment of neurodegenerative diseases, including Alzheimer’s and Parkinson’s.&lt;/p&gt;&lt;p&gt;In 2019, DeRidder entered the joint Harvard-MIT Health Sciences and Technology program, where he has embarked on a somewhat different type of drug delivery project — developing a device that measures the concentration of a chemotherapy drug in the blood while it is being administered and adjusts the infusion rate so the concentration is optimal for the patient. The system is known as CLAUDIA, or Closed-Loop AUtomated Drug Infusion RegulAtor, and can allow for the personalization of drug dosing for a variety of different drugs.&lt;/p&gt;&lt;p&gt;The project stemmed from discussions with his faculty advisors — Robert Langer, the David H. Koch Institute Professor, and Giovanni Traverso, the Karl Van Tassel Career Development Professor and a gastroenterologist at Brigham and Women’s Hospital. They explained to him that chemotherapy dosing is based on a formula developed in 1916 that estimates a patient’s body surface area. The formula doesn’t consider important influences such as differences in body composition and metabolism, or circadian fluctuations that can affect how a drug interacts with a patient.&lt;/p&gt;&lt;p&gt;“Once my advisors presented the reality of how chemotherapies are dosed,” DeRidder says, “I thought, ‘This is insane. How is this the clinical reality?’”&lt;/p&gt;&lt;p&gt;He and his advisors agreed this was a great project for his PhD.&lt;/p&gt;&lt;p&gt;“After they gave me the problem statement, we began to brainstorm ways that we could develop a medical device to improve the lives of patients” DeRidder says, adding, “I love starting with a blank piece of paper and then brainstorming to work out the best solution.”&lt;/p&gt;&lt;p&gt;Almost from the start, DeRidder’s research process involved MATLAB and Simulink, developed by the mathematical computer software company MathWorks.&lt;/p&gt;&lt;p&gt;“MathWorks and Simulink are key to what we do,” DeRidder says. “They enable us to model the drug pharmacokinetics — how the body distributes and metabolizes the drug. We also model the components of our system with their software. That was especially critical for us in the very early days, because it let us know whether it was even possible to control the concentration of the drug. And since then, we’ve continuously improved the control algorithm, using these simulations. You simulate hundreds of different experiments before performing any experiments in the lab.”&lt;/p&gt;&lt;p&gt;With his innovative use of the MATLAB and Simulink tools, DeRidder was awarded MathWorks fellowships both last year and this year. He has also received a National Science Foundation Graduate Research Fellowship.&lt;/p&gt;&lt;p&gt;“The fellowships have been critical to our development of the CLAUDIA drug-delivery system,” DeRidder says, adding that he has “had the pleasure of working with a great team of students and researchers in the lab.”&lt;/p&gt;&lt;p&gt;He says he would like to move CLAUDIA toward clinical use, where he thinks it could have significant impact. “Whatever I can do to help push it toward the clinic, including potentially helping to start a company to help commercialize the system, I’m definitely interested in doing it.”&lt;/p&gt;&lt;p&gt;In addition to developing CLAUDIA, DeRidder is working on developing new nanoparticles to deliver therapeutic nucleic acids. The project involves synthesizing new nucleic acid molecules, as well as developing the new polymeric and lipid nanoparticles to deliver the nucleic acids to targeted tissue and cells.&lt;/p&gt;&lt;p&gt;DeRidder says he likes working on technologies at different scales, from medical devices to molecules — all with the potential to improve the practice of medicine.&lt;/p&gt;&lt;p&gt;Meanwhile, he finds time in his busy schedule to do community service. For the past three years, he has spent time helping the homeless on Boston streets.&lt;/p&gt;&lt;p&gt;“It’s easy to lose track of the concrete, simple ways that we can serve our communities when we’re doing research,” DeRidder says, “which is why I have often sought out ways to serve people I come across every day, whether it is a student I mentor in lab, serving the homeless, or helping out the stranger you meet in the store who is having a bad day.”&lt;/p&gt;&lt;p&gt;Ultimately, DeRidder says, he’ll head back to work that also recalls his early exposure to the medical field in high school, where he interacted with a lot of people with different types of dementia and other neurological diseases at a local nursing home.&lt;/p&gt;&lt;p&gt;“My long-term plan includes working on developing devices and molecular therapies to treat neurological diseases, in addition to continuing to work on cancer,” he says. “Really, I’d say that early experience had a big impact on me.”&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202502/mit-mathworks-Louis-DeRidder.JPG?itok=h_qn18Dz" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Louis DeRidder is a PhD student in the Harvard-MIT Health Science and Technology Program.]]></media:description>
              <media:credit>Photo: Gretchen Ertl</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/harvard-mit-health-sciences-and-technology">Harvard-MIT Health Sciences and Technology</category>
      <category domain="https://news.mit.edu/topic/health">Health sciences and technology</category>
      <category domain="https://news.mit.edu/topic/medicine">Medicine</category>
      <category domain="https://news.mit.edu/topic/nanotech">Nanoscience and nanotechnology</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/drug-delivery">Drug delivery</category>
      <category domain="https://news.mit.edu/topic/chemotherapy">Chemotherapy</category>
      <category domain="https://news.mit.edu/topic/cancer-research">Cancer</category>
      <category domain="https://news.mit.edu/topic/alzheimers">Alzheimer's</category>
      <category domain="https://news.mit.edu/topic/parkinsons">Parkinson's</category>
      <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/profile">Profile</category>
      <category domain="https://news.mit.edu/topic/innovation">Innovation and Entrepreneurship (I&amp;E)</category>
      <category domain="https://news.mit.edu/topic/graduate">Graduate, postdoctoral</category>
    </item>
<item>
  <title>Seeing more in expansion microscopy</title>
  <link>https://news.mit.edu/2025/seeing-more-expansion-microscopy-0303</link>
  <description><![CDATA[New methods light up lipid membranes and let researchers see sets of proteins inside cells with high resolution.]]></description>
  <pubDate>Mon, 03 Mar 2025 16:30:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/seeing-more-expansion-microscopy-0303</guid>
        <dc:creator>Jennifer Michalowski | McGovern Institute for Brain Research</dc:creator>
  <content:encoded>&lt;p&gt;In biology, seeing can lead to understanding, and researchers in Professor &lt;a href="https://mcgovern.mit.edu/profile/ed-boyden/"&gt;Edward Boyden&lt;/a&gt;’s lab at the McGovern Institute for Brain Research are committed to bringing life into sharper focus. With a pair of new methods, they are expanding the capabilities of expansion microscopy — a high-resolution imaging technique the group introduced in 2015 — so researchers everywhere can see more when they look at cells and tissues under a light microscope.&lt;/p&gt;&lt;p&gt;“We want to see everything, so we’re always trying to improve it,” says Boyden, the Y. Eva Tan Professor in Neurotechnology at MIT. “A snapshot of all life, down to its fundamental building blocks, is really the goal.” Boyden is also a Howard Hughes Medical Institute investigator and a member of the Yang Tan Collective at MIT.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With new ways of staining their samples and processing images, users of expansion microscopy can now see vivid outlines of the shapes of cells in their images and pinpoint the locations of many different proteins inside a single tissue sample with resolution that far exceeds that of conventional light microscopy. These advances, both reported in open-access form in the journal &lt;em&gt;Nature Communications&lt;/em&gt;, enable new ways of tracing the slender projections of neurons and visualizing spatial relationships between molecules that contribute to health and disease.&lt;/p&gt;&lt;p&gt;Expansion microscopy uses a water-absorbing hydrogel to physically expand biological tissues. After a tissue sample has been permeated by the hydrogel, it is hydrated. The hydrogel swells as it absorbs water, preserving the relative locations of molecules in the tissue as it gently pulls them away from one another. As a result, crowded cellular components appear separate and distinct when the expanded tissue is viewed under a light microscope. The approach, which can be performed using standard laboratory equipment, has made super-resolution imaging accessible to most research teams.&lt;/p&gt;&lt;p&gt;Since first developing expansion microscopy, Boyden and his team have continued to enhance the method — increasing its resolution, simplifying the procedure, devising new features, and integrating it with other tools.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Visualizing cell membranes&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One of the team’s latest advances is a method called ultrastructural membrane expansion microscopy (umExM), which they described in the Feb. 12 issue of &lt;a href="https://www.nature.com/articles/s41467-025-56641-z"&gt;&lt;em&gt;Nature Communications.&lt;/em&gt; &lt;/a&gt;With it, biologists can use expansion microscopy to visualize the thin membranes that form the boundaries of cells and enclose the organelles inside them. These membranes, built mostly of molecules called lipids, have been notoriously difficult to densely label in intact tissues for imaging with light microscopy. Now, researchers can use umExM to study cellular ultrastructure and organization within tissues.&lt;/p&gt;&lt;p&gt;Tay Shin SM ’20, PhD ’23, a former graduate student in Boyden’s lab and a J. Douglas Tan Fellow in the Tan-Yang Center for Autism Research at MIT, led the development of umExM. “Our goal was very simple at first: Let’s label membranes in intact tissue, much like how an electron microscope uses osmium tetroxide to label membranes to visualize the membranes in tissue,” he says. “It turns out that it’s extremely hard to achieve this.”&lt;/p&gt;&lt;p&gt;The team first needed to design a label that would make the membranes in tissue samples visible under a light microscope. “We almost had to start from scratch,” Shin says. “We really had to think about the fundamental characteristics of the probe that is going to label the plasma membrane, and then think about how to incorporate them into expansion microscopy.” That meant engineering a molecule that would associate with the lipids that make up the membrane and link it to both the hydrogel used to expand the tissue sample and a fluorescent molecule for visibility.&lt;/p&gt;&lt;p&gt;After optimizing the expansion microscopy protocol for membrane visualization and extensively testing and improving potential probes, Shin found success one late night in the lab. He placed an expanded tissue sample on a microscope and saw sharp outlines of cells.&lt;/p&gt;&lt;p&gt;Because of the high resolution enabled by expansion, the method allowed Boyden’s team to identify even the tiny dendrites that protrude from neurons and clearly see the long extensions of their slender axons. That kind of clarity could help researchers follow individual neurons’ paths within the densely interconnected networks of the brain, the researchers say.&lt;/p&gt;&lt;p&gt;Boyden calls tracing these neural processes “a top priority of our time in brain science.” Such tracing has traditionally relied heavily on electron microscopy, which requires specialized skills and expensive equipment. Shin says that because expansion microscopy uses a standard light microscope, it is far more accessible to laboratories worldwide.&lt;/p&gt;&lt;p&gt;Shin and Boyden point out that users of expansion microscopy can learn even more about their samples when they pair the new ability to reveal lipid membranes with fluorescent labels that show where specific proteins are located. “That’s important, because proteins do a lot of the work of the cell, but you want to know where they are with respect to the cell’s structure,” Boyden says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;One sample, many proteins&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To that end, researchers no longer have to choose just a few proteins to see when they use expansion microscopy. With a new method called multiplexed expansion revealing (multiExR), users can now label and see more than 20 different proteins in a single sample. Biologists can use the method to visualize sets of proteins, see how they are organized with respect to one another, and generate new hypotheses about how they might interact.&lt;/p&gt;&lt;p&gt;A key to that new method, &lt;a href="https://www.nature.com/articles/s41467-024-53729-w" target="_blank"&gt;reported Nov. 9, 2024, in &lt;em&gt;Nature Communications&lt;/em&gt;&lt;/a&gt;, is the ability to repeatedly link fluorescently labeled antibodies to specific proteins in an expanded tissue sample, image them, then strip these away and use a new set of antibodies to reveal a new set of proteins. Postdoc Jinyoung Kang fine-tuned each step of this process, assuring tissue samples stayed intact and the labeled proteins produced bright signals in each round of imaging.&lt;/p&gt;&lt;p&gt;After capturing many images of a single sample, Boyden’s team faced another challenge: how to ensure those images were in perfect alignment so they could be overlaid with one another, producing a final picture that showed the precise positions of all of the proteins that had been labeled and visualized one by one.&lt;/p&gt;&lt;p&gt;Expansion microscopy lets biologists visualize some of cells’ tiniest features — but to find the same features over and over again during multiple rounds of imaging, Boyden’s team first needed to home in on a larger structure. “These fields of view are really tiny, and you’re trying to find this really tiny field of view in a gel that’s actually become quite large once you’ve expanded it,” explains Margaret Schroeder, a graduate student in Boyden’s lab who, with Kang, led the development of multiExR.&lt;/p&gt;&lt;p&gt;To navigate to the right spot every time, the team decided to label the blood vessels that pass through each tissue sample and use these as a guide. To enable precise alignment, certain fine details also needed to consistently appear in every image; for this, the team labeled several structural proteins. With these reference points and customized imaging processing software, the team was able to integrate all of their images of a sample into one, revealing how proteins that had been visualized separately were arranged relative to one another.&lt;/p&gt;&lt;p&gt;The team used multiExR to look at amyloid plaques — the aberrant protein clusters that notoriously develop in brains affected by Alzheimer’s disease. “We could look inside those amyloid plaques and ask, what’s inside of them? And because we can stain for many different proteins, we could do a high-throughput exploration,” Boyden says. The team chose 23 different proteins to view in their images. The approach revealed some surprises, such as the presence of certain neurotransmitter receptors (AMPARs). “Here’s one of the most famous receptors in all of neuroscience, and there it is, hiding out in one of the most famous molecular hallmarks of pathology in neuroscience,” says Boyden. It’s unclear what role, if any, the receptors play in Alzheimer’s disease — but the finding illustrates how the ability to see more inside cells can expose unexpected aspects of biology and raise new questions for research.&lt;/p&gt;&lt;p&gt;Funding for this work came from MIT, Lisa Yang and Y. Eva Tan, John Doerr, the Open Philanthropy Project, the Howard Hughes Medical Institute, the U.S. Army, Cancer Research U.K., the New York Stem Cell Foundation, the U.S. National Institutes of Health, Lore McGovern, Good Ventures, Schmidt Futures, Samsung, MathWorks, the Collamore-Rogers Fellowship, the U.S. National Science Foundation, Alana Foundation USA, the Halis Family Foundation, Lester A. Gimpelson, Donald and Glenda Mattes, David B. Emmes, Thomas A. Stocky, Avni U. Shah, Kathleen Octavio, Good Ventures/Open Philanthropy, and the European Union’s Horizon 2020 program.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202502/mit-expansion-microscopy.jpg?itok=DaE6iZwm" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Composite image of several synaptic, beta-amyloid, and other cell type marker proteins in the ~18x expanded brain of wild-type (gray) and 5xFAD Alzheimer’s disease model mice (pink) captured using multiExR. Each color represents a different protein. ]]></media:description>
              <media:credit>Image courtesy of the Boyden Lab.</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/microscopy">Microscopy</category>
      <category domain="https://news.mit.edu/topic/hydrogels">Hydrogels</category>
      <category domain="https://news.mit.edu/topic/imaging">Imaging</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/cells">Cells</category>
      <category domain="https://news.mit.edu/topic/proteins">Proteins</category>
      <category domain="https://news.mit.edu/topic/alzheimers">Alzheimer's</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>An ancient RNA-guided system could simplify delivery of gene editing therapies</title>
  <link>https://news.mit.edu/2025/ancient-rna-guided-system-could-simplify-delivery-gene-editing-therapies-0227</link>
  <description><![CDATA[The programmable proteins are compact, modular, and can be directed to modify DNA in human cells. ]]></description>
  <pubDate>Thu, 27 Feb 2025 17:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/ancient-rna-guided-system-could-simplify-delivery-gene-editing-therapies-0227</guid>
        <dc:creator>Jennifer Michalowski | McGovern Institute for Brain Research</dc:creator>
  <content:encoded>&lt;p&gt;A vast search of natural diversity has led scientists at MIT’s McGovern Institute for Brain Research and the Broad Institute of MIT and Harvard to uncover ancient systems with potential to expand the genome editing toolbox.&amp;nbsp;&lt;/p&gt;&lt;p&gt;These systems, which the researchers call TIGR (Tandem Interspaced Guide RNA) systems, use RNA to guide them to specific sites on DNA. TIGR systems can be reprogrammed to target any DNA sequence of interest, and they have distinct functional modules that can act on the targeted DNA. In addition to its modularity, TIGR is very compact compared to other RNA-guided systems, like CRISPR, which is a major advantage for delivering it in a therapeutic context.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;These findings are &lt;a href="https://www.science.org/doi/10.1126/science.adv9789" target="_blank"&gt;reported online Feb. 27 in the journal &lt;em&gt;Science&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;“This is a very versatile RNA-guided system with a lot of diverse functionalities,” says Feng Zhang, the James and Patricia Poitras Professor of Neuroscience at MIT, who led the research. The TIGR-associated (Tas) proteins that Zhang’s team found share a characteristic RNA-binding component that interacts with an RNA guide that directs it to a specific site in the genome. Some cut the DNA at that site, using an adjacent DNA-cutting segment of the protein. That modularity could facilitate tool development, allowing researchers to swap useful new features into natural Tas proteins.&lt;/p&gt;&lt;p&gt;“Nature is pretty incredible,” says Zhang, who&amp;nbsp;is also an investigator at the McGovern Institute and the Howard Hughes Medical Institute, a core member of the Broad Institute, a professor of brain and cognitive sciences and biological engineering at MIT, and co-director of the K. Lisa Yang and Hock E. Tan Center for Molecular Therapeutics at MIT.&amp;nbsp;“It’s got a tremendous amount of diversity, and we have been exploring that natural diversity to find new biological mechanisms and harnessing them for different applications to manipulate biological processes,” he says. Previously, Zhang’s team adapted bacterial CRISPR systems into gene editing tools that have transformed modern biology. His team has also found a variety of programmable proteins, both from CRISPR systems and beyond.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In their new work, to find novel programmable systems, the team began by zeroing in a structural feature of the CRISPR-Cas9 protein that binds to the enzyme’s RNA guide. That is a key feature that has made Cas9 such a powerful tool: “Being RNA-guided makes it relatively easy to reprogram, because we know how RNA binds to other DNA or other RNA,” Zhang explains. His team searched hundreds of millions of biological proteins with known or predicted structures, looking for any that shared a similar domain. To find more distantly related proteins, they used an iterative process: from Cas9, they identified a protein called IS110, which had previously been shown by others to bind RNA. They then zeroed in on the structural features of IS110 that enable RNA binding and repeated their search.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At this point, the search had turned up so many distantly related proteins that they team turned to artificial intelligence to make sense of the list. “When you are doing iterative, deep mining, the resulting hits&amp;nbsp;can be so diverse that they are difficult to analyze&amp;nbsp;using standard phylogenetic methods, which rely on conserved sequence,” explains Guilhem Faure, a computational biologist in Zhang’s lab. With a protein large language model, the team was able to cluster the proteins they had found into groups according to their likely evolutionary relationships. One group set apart from the rest, and its members were particularly intriguing because they were encoded by genes with regularly spaced repetitive sequences reminiscent of an essential component of CRISPR systems. These were the TIGR-Tas systems.&lt;/p&gt;&lt;p&gt;Zhang’s team discovered more than 20,000 different Tas proteins, mostly occurring in bacteria-infecting viruses. Sequences within each gene’s repetitive region — its TIGR arrays — encode an RNA guide that interacts with the RNA-binding part of the protein. In some, the RNA-binding region is adjacent to a DNA-cutting part of the protein. Others appear to bind to other proteins, which suggests they might help direct those proteins to DNA targets. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Zhang and his team experimented with dozens of Tas proteins, demonstrating that some can be programmed to make targeted cuts to DNA in human cells. As they think about developing TIGR-Tas systems into programmable tools, the researchers are encouraged by features that could make those tools particularly flexible and precise.&lt;/p&gt;&lt;p&gt;They note that CRISPR systems can only be directed to segments of DNA that are flanked by short motifs known as PAMs (protospacer adjacent motifs). TIGR Tas proteins, in contrast, have no such requirement. “This means theoretically, any site in the&amp;nbsp;genome should be targetable,” says scientific advisor Rhiannon Macrae. The team’s experiments also show that TIGR systems have what Faure calls a “dual-guide system,” interacting with both strands of the DNA double helix to home in on their target sequences, which should ensure they act only where they are directed by their RNA guide. What’s more, Tas proteins are compact — a quarter of the size Cas9, on average — making them easier to deliver, which could overcome a major obstacle to therapeutic deployment of gene editing tools.&amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;Excited by their discovery, Zhang’s team is now investigating the natural role of TIGR systems in viruses, as well as how they can be adapted for research or therapeutics. They have determined the molecular structure of one of the Tas proteins they found to work in human cells, and will use that information to guide their efforts to make it more efficient. Additionally, they note connections between TIGR-Tas systems and certain RNA-processing proteins in human cells. “I think there’s more there to study in terms of what some of those relationships may be, and it may help us better understand how&amp;nbsp;these systems are used in humans,” Zhang says.&lt;/p&gt;&lt;p&gt;This work was supported by the Helen Hay Whitney Foundation, Howard Hughes Medical Institute, K. Lisa Yang and Hock E. Tan Center for Molecular Therapeutics, Broad Institute Programmable Therapeutics Gift Donors, Pershing Square Foundation, William Ackman, Neri Oxman, the Phillips family, J. and P. Poitras, and the BT Charitable Foundation.&amp;nbsp;&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202502/tas-protein.jpg?itok=N6O9MiSh" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[The Tas protein uses an RNA guide to recognize a specific target DNA sequence. ]]></media:description>
              <media:credit>Image: Max Wilkinson</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/genetics">Genetics</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/rna">RNA</category>
      <category domain="https://news.mit.edu/topic/dna">DNA</category>
      <category domain="https://news.mit.edu/topic/proteins">Proteins</category>
      <category domain="https://news.mit.edu/topic/genetic-engineering">Genetic engineering</category>
      <category domain="https://news.mit.edu/topic/crispr">CRISPR</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/broad-institute">Broad Institute</category>
      <category domain="https://news.mit.edu/topic/howard-hughes-medical-institute-hhmi">Howard Hughes Medical Institute (HHMI)</category>
    </item>
<item>
  <title>Study: Even after learning the right idea, humans and animals still seem to test other approaches</title>
  <link>https://news.mit.edu/2025/even-after-learning-right-idea-humans-animals-still-test-other-approaches-0221</link>
  <description><![CDATA[New research adds evidence that learning a successful strategy for approaching a task doesn’t prevent further exploration, even if doing so reduces performance.]]></description>
  <pubDate>Fri, 21 Feb 2025 15:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/even-after-learning-right-idea-humans-animals-still-test-other-approaches-0221</guid>
        <dc:creator>David Orenstein | The Picower Institute for Learning and Memory</dc:creator>
  <content:encoded>&lt;p&gt;Maybe it’s a life hack or a liability, or a little of both. A surprising result in a new MIT study may suggest that people and animals alike share an inherent propensity to keep updating their approach to a task even when they have already learned how they should approach it, and even if the deviations sometimes lead to unnecessary error.&lt;/p&gt;&lt;p&gt;The behavior of “exploring” when one could just be “exploiting” could make sense for at least two reasons, says Mriganka Sur, senior author of the study published Feb. 18 in &lt;em&gt;Current Biology&lt;/em&gt;. Just because a task’s rules seem set one moment doesn’t mean they’ll stay that way in this uncertain world, so altering behavior from the optimal condition every so often could help reveal needed adjustments. Moreover, trying new things when you already know what you like is a way of finding out whether there might be something even better out there than the good thing you’ve got going on right now.&lt;/p&gt;&lt;p&gt;“If the goal is to maximize reward, you should never deviate once you have found the perfect solution, yet you keep exploring,” says Sur, the Paul and Lilah Newton Professor in The Picower Institute for Learning and Memory and the Department of Brain and Cognitive Sciences at MIT. “Why? It’s like food. We all like certain foods, but we still keep trying different foods because you never know, there might be something you could discover.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Predicting timing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Former research technician Tudor Dragoi, now a graduate student at Boston University, led the study in which he and fellow members of the Sur Lab explored how humans and marmosets, a small primate, make predictions about event timing.&lt;/p&gt;&lt;p&gt;Three humans and two marmosets were given a simple task. They’d see an image on a screen for some amount of time — the amount of time varied from one trial to the next within a limited range — and they simply had to hit a button (marmosets poked a tablet while humans clicked a mouse) when the image disappeared. Success was defined as reacting as quickly as possible to the image’s disappearance without hitting the button too soon. Marmosets received a juice reward on successful trials.&lt;/p&gt;&lt;p&gt;Though marmosets needed more training time than humans, the subjects all settled into the same reasonable pattern of behavior regarding the task. The longer the image stayed on the screen, the faster their reaction time to its disappearance. This behavior follows the “hazard model” of prediction in which, if the image can only last for so long, the longer it’s still there, the more likely it must be to disappear very soon. The subjects learned this and overall, with more experience, their reaction times became faster.&lt;/p&gt;&lt;p&gt;But as the experiment continued, Sur and Dragoi’s team noticed something surprising was also going on. Mathematical modeling of the reaction time data revealed that both the humans and marmosets were letting the results of the immediate previous trial influence what they did on the next trial, even though they had already learned what to do. If the image was only on the screen briefly in one trial, on the next round subjects would decrease reaction time a bit (presumably expecting a shorter image duration again) whereas if the image lingered, they’d increase reaction time (presumably because they figured they’d have a longer wait).&lt;/p&gt;&lt;p&gt;Those results add to ones from &lt;a href="https://picower.mit.edu/news/study-decodes-surprising-approach-mice-take-learning" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;a similar study&lt;/a&gt; Sur’s lab published in 2023, in which they found that even after mice learned the rules of a different cognitive task, they’d arbitrarily deviate from the winning strategy every so often. In that study, like this one, learning the successful strategy didn’t prevent subjects from continuing to test alternatives, even if it meant sacrificing reward.&lt;/p&gt;&lt;p&gt;“The persistence of behavioral changes even after task learning may reflect exploration as a strategy for seeking and setting on an optimal internal model of the environment,” the scientists wrote in the new study.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Relevance for autism&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The similarity of the human and marmoset behaviors is an important finding as well, Sur says. That’s because &lt;a href="https://www.pnas.org/doi/10.1073/pnas.1416797111" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;differences in making predictions&lt;/a&gt; about one’s environment is posited to be a salient characteristic of autism spectrum disorders. Because marmosets are small, are inherently social, and are more cognitively complex than mice, work has begun in some labs to establish marmoset autism models, but a key component was establishing that they model autism-related behaviors well. By demonstrating that marmosets model neurotypical human behavior regarding predictions, the study therefore adds weight to the emerging idea that marmosets can indeed provide informative models for autism studies.&lt;/p&gt;&lt;p&gt;In addition to Dragoi and Sur, other authors of the paper are Hiroki Sugihara, Nhat Le, Elie Adam, Jitendra Sharma, Guoping Feng, and Robert Desimone.&lt;/p&gt;&lt;p&gt;The Simons Foundation Autism Research Initiative supported the research through the &lt;a href="https://scsb.mit.edu/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Simons Center for the Social Brain&lt;/a&gt; at MIT.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202502/blocks-with-arrows.jpg?itok=R3tdTMei" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Researchers studying how humans and animals make predictions about timing found a surprising result. After learning the optimal approach to the task, they still let their behavior be swayed by recent results. The study suggests that even with a clear "path" to follow to optimally accomplish a task, people and animals will still sometimes choose to explore, even if that might mean reduced performance. ]]></media:description>
              <media:credit>Image: AdobeStock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/learning">Learning</category>
      <category domain="https://news.mit.edu/topic/memory">Memory</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/psychology">Psychology</category>
      <category domain="https://news.mit.edu/topic/autism">Autism</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Mapping mRNA through its life cycle within a cell</title>
  <link>https://news.mit.edu/2025/mapping-mrna-through-its-life-cycle-xiao-wang-0211</link>
  <description><![CDATA[Xiao Wang’s studies of how and where RNA is translated could lead to the development of better RNA therapeutics and vaccines.]]></description>
  <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/mapping-mrna-through-its-life-cycle-xiao-wang-0211</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;When Xiao Wang applied to faculty jobs, many of the institutions where she interviewed thought her research proposal — to study the life cycle of RNA in cells and how it influences normal development and disease — was too broad.&lt;/p&gt;&lt;p&gt;However, that was not the case when she interviewed at MIT, where her future colleagues embraced her ideas and encouraged her to be even more bold.&lt;/p&gt;&lt;p&gt;“What I’m doing now is even broader, even bolder than what I initially proposed,” says Wang, who holds joint appointments in the Department of Chemistry and the Broad Institute of MIT and Harvard. “I got great support from all my colleagues in my department and at Broad so that I could get the resources to conduct what I wanted to do. It’s also a demonstration of how brave the students are. There is a really innovative culture and environment here, so the students are not scared by taking on something that might sound weird or unrealistic.”&lt;/p&gt;&lt;p&gt;Wang’s work on RNA brings together students from chemistry, biology, computer science,&amp;nbsp;neuroscience, and other fields. In her lab, research is focused on developing tools that pinpoint where in a given cell different types of messenger RNA are translated into proteins — information that can offer insight into how cells control their fate and what goes wrong in disease, especially in the brain.&lt;/p&gt;&lt;p&gt;“The joint position between MIT Chemistry and the Broad Institute was very attractive to me because I was trained as a chemist, and I would like to teach and recruit students from chemistry. But meanwhile, I also wanted to get exposure to biomedical topics and have collaborators outside chemistry. I can collaborate with biologists, doctors, as well as computational scientists who analyze all these daunting data,” she says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Imaging RNA&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Wang began her career at MIT in 2019, just before the Covid-19 pandemic began. Until that point, she hardly knew anyone in the Boston area, but she found a warm welcome.&lt;/p&gt;&lt;p&gt;“I wasn’t trained at MIT, and I had never lived in Boston before. At first, I had very small social circles, just with my colleagues and my students, but amazingly, even during the pandemic, I never felt socially isolated. I just felt so plugged in already even though it’s very a close, small circle,” she says.&lt;/p&gt;&lt;p&gt;Growing up in China, Wang became interested in science in middle school, when she was chosen to participate in China’s National Olympiad in math and chemistry. That gave her the chance to learn college-level course material, and she ended up winning a gold medal in the nationwide chemistry competition.&lt;/p&gt;&lt;p&gt;“That exposure was enough to draw me into initially mathematics, but later on more into chemistry. That’s how I got interested in a more science-oriented major and then career path,” Wang says.&lt;/p&gt;&lt;p&gt;At Peking University, she majored in chemistry and molecular engineering.&amp;nbsp;There, she worked with Professor Jian Pei, who gave her the opportunity to work independently on her own research project.&lt;/p&gt;&lt;p&gt;“I really like to do research because every day you have a hypothesis, you have a design, and you make it happen. It’s like playing a video game: You have this roughly daily feedback loop. Sometimes it’s a reward, sometimes it’s not. I feel it’s more interesting than taking a class, so I think that made me decide I should apply for graduate school,” she says.&lt;/p&gt;&lt;p&gt;As a graduate student at the University of Chicago, she became interested in RNA while doing a rotation in the lab of Chuan He, a professor of chemistry. He was studying chemical modifications that affect the function of messenger RNA — the molecules that carry protein-building instructions from DNA to ribosomes, where proteins are assembled.&lt;/p&gt;&lt;p&gt;Wang ended up joining He’s&amp;nbsp;lab, where she studied a common mRNA modification known as m6A, which influences how efficiently mRNA is translated into protein and how fast it gets degraded in the cell. She also&amp;nbsp;began to explore how mRNA modifications affect embryonic development. As a model for these studies, she was using zebrafish, which have transparent embryos that develop from fertilized eggs into free-swimming larvae within two days. That got her interested in developing methods that could reveal where different types of RNA were being expressed, by imaging the entire organism.&lt;/p&gt;&lt;p&gt;Such an approach, she soon realized, could also be useful for studying the brain. As a postdoc at Stanford University,&amp;nbsp;she started to develop RNA imaging methods,&amp;nbsp;working with Professor Karl Deisseroth. There are existing techniques for identifying mRNA molecules that are expressed in individual cells, but those don’t offer information about exactly where in the cells different types of mRNA are located. She began developing a technique called STARmap that could accomplish this type of “spatial transcriptomics.”&lt;/p&gt;&lt;p&gt;Using this technique, researchers first use formaldehyde to crosslink all of the mRNA molecules in place. Then, the tissue is washed with fluorescent DNA probes that are complementary to the target mRNA sequences. These probes can then be imaged and sequenced, revealing the locations of each mRNA sequence within a cell. This allows for the visualization of mRNA molecules that encode thousands of different genes within single cells.&lt;/p&gt;&lt;p&gt;“I was leveraging my background in the chemistry of RNA to develop this RNA-centered brain mapping technology, which allows you to use RNA expression profiles to define brain cell types and also visualize their spatial architecture,” Wang says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tracking the RNA life cycle&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Members of Wang’s lab are now working on expanding the capability of the STARmap technique so that it can be used to analyze brain function and brain wiring.&amp;nbsp;They are also developing tools that will allow them to map the entire life cycle of mRNA molecules, from synthesis to translation to degradation, and track how these molecules are transported within a cell during their lifetime.&lt;/p&gt;&lt;p&gt;One of these tools, known as&amp;nbsp;&lt;a href="https://news.mit.edu/2023/scientists-pinpoint-where-thousands-individual-proteins-are-made-0714" target="_blank"&gt;RIBOmap&lt;/a&gt;, pinpoints the locations of mRNA molecules as they are being translated at ribosomes. Another tool allows the researchers to measure how quickly mRNA is degraded after being transcribed.&lt;/p&gt;&lt;p&gt;“We are trying to develop a toolkit that will let us visualize every step of the RNA life cycle inside cells and tissues,” Wang says. “These are newer generations of tool development centered around these RNA biological questions.”&lt;/p&gt;&lt;p&gt;One of these central questions is how different cell types control their RNA life cycles differently, and how that affects their differentiation. Differences in RNA control may also be a factor in diseases such as Alzheimer’s. In a&amp;nbsp;&lt;a href="https://news.mit.edu/2023/researchers-map-brain-cell-changes-alzheimers-disease-0202" target="_blank"&gt;2023 study&lt;/a&gt;, Wang and MIT Professor Morgan Sheng used a version of STARmap to discover how cells called microglia become more inflammatory as amyloid-beta plaques form in the brain. Wang’s lab is also pursuing studies of how differences in mRNA translation might affect schizophrenia and other neurological disorders.&lt;/p&gt;&lt;p&gt;“The reason we think there will be a lot of interesting biology to discover is because the formation of neural circuits is through synapses, and synapse formation and learning and memory are strongly associated with localized RNA translation, which involves multiple steps including RNA transport and recycling,” she says.&lt;/p&gt;&lt;p&gt;In addition to investigating those biological questions, Wang is also working on ways to boost the efficiency of mRNA therapeutics and vaccines&amp;nbsp;by changing their chemical modifications or their&amp;nbsp;topological&amp;nbsp;structure.&lt;/p&gt;&lt;p&gt;“Our goal is to create a toolbox and RNA synthesis strategy where we can precisely tune the chemical modification on every particle of RNA,” Wang says. “We want to establish how those modifications will influence how fast mRNA can produce protein, and in which cell types they could be used to more efficiently produce protein.”&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202502/MIT-Wang-Xiao-01-press.jpg?itok=l_MZn_WD" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[“I really like to do research because every day you have a hypothesis, you have a design, and you make it happen,” says MIT Associate Professor Xiao Wang.]]></media:description>
              <media:credit>Photo: Jodi Hilton</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/faculty">Faculty</category>
      <category domain="https://news.mit.edu/topic/rna">RNA</category>
      <category domain="https://news.mit.edu/topic/chemistry-0">Chemistry</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/genetics">Genetics</category>
      <category domain="https://news.mit.edu/topic/disease">Disease</category>
      <category domain="https://news.mit.edu/topic/broad-institute">Broad Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>MIT method enables ultrafast protein labeling of tens of millions of densely packed cells</title>
  <link>https://news.mit.edu/2025/mit-method-enables-protein-labeling-tens-millions-densely-packed-cells-0206</link>
  <description><![CDATA[Tissue processing advance can label proteins at the level of individual cells across large samples just as fast and uniformly as in dissociated single cells.]]></description>
  <pubDate>Thu, 06 Feb 2025 16:40:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/mit-method-enables-protein-labeling-tens-millions-densely-packed-cells-0206</guid>
        <dc:creator>David Orenstein | The Picower Institute for Learning and Memory</dc:creator>
  <content:encoded>&lt;p&gt;A new technology developed at MIT enables scientists to label proteins across millions of individual cells in fully intact 3D tissues with unprecedented speed, uniformity, and versatility. Using the technology, the team was able to richly label large tissue samples in a single day. In their &lt;a href="https://www.nature.com/articles/s41587-024-02533-4" target="_blank"&gt;new study in &lt;em&gt;Nature Biotechnology&lt;/em&gt;&lt;/a&gt;&lt;em&gt;,&lt;/em&gt; they also demonstrate that the ability to label proteins with antibodies at the single-cell level across large tissue samples can reveal insights left hidden by other widely used labeling methods.&lt;/p&gt;&lt;p&gt;Profiling the proteins that cells are making is a staple of studies in biology, neuroscience, and related fields because the proteins a cell is expressing at a given moment can reflect the functions the cell is trying to perform or its response to its circumstances, such as disease or treatment. As much as microscopy and labeling technologies have advanced, enabling innumerable discoveries, scientists have still lacked a reliable and practical way of tracking protein expression at the level of millions of densely packed individual cells in whole, 3D intact tissues. Often confined to thin tissue sections under slides, scientists therefore haven’t had tools to thoroughly appreciate cellular protein expression in the whole, connected systems in which it occurs.&lt;/p&gt;&lt;p&gt;“Conventionally, investigating the molecules within cells requires dissociating tissue into single cells or slicing it into thin sections, as light and chemicals required for analysis cannot penetrate deep into tissues. Our lab developed technologies such as &lt;a href="https://picower.mit.edu/innovations-inventions/clarity"&gt;CLARITY&lt;/a&gt; and &lt;a href="https://picower.mit.edu/innovations-inventions/shield"&gt;SHIELD&lt;/a&gt;, which enable investigation of whole organs by rendering them transparent, but we now needed a way to chemically label whole organs to gain useful scientific insights,” says study senior author &lt;a href="https://picower.mit.edu/node/40"&gt;Kwanghun Chung&lt;/a&gt;, associate professor in The Picower Institute for Learning and Memory, the departments of Chemical Engineering and Brain and Cognitive Sciences, and the Institute for Medical Engineering and Science at MIT. “If cells within a tissue are not uniformly processed, they cannot be quantitatively compared. In conventional protein labeling, it can take weeks for these molecules to diffuse into intact organs, making uniform chemical processing of organ-scale tissues virtually impossible and extremely slow.”&lt;/p&gt;&lt;p&gt;The new approach, called “CuRVE,” represents a major advance — years in the making — toward that goal by demonstrating a fundamentally new approach to uniformly processing large and dense tissues whole. In the study, the researchers explain how they overcame the technical barriers via an implementation of CuRVE called “eFLASH,” and provide copious vivid demonstrations of the technology, including how it yielded new neuroscience insights.&lt;/p&gt;&lt;p&gt;“This is a significant leap, especially in terms of the actual performance of the technology,” says co-lead author Dae Hee Yun PhD '24, a recent MIT graduate student who is now a senior application engineer at LifeCanvas Technologies, a startup company Chung founded to disseminate the tools his lab invents. The paper’s other lead author is Young-Gyun Park, a former MIT postdoc who’s now an assistant professor at KAIST in South Korea.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Clever chemistry&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The fundamental reason why large, 3D tissue samples are hard to label uniformly is that antibodies seep into tissue very slowly, but are quick to bind to their target proteins. The practical effect of this speed mismatch is that simply soaking a brain in a bath of antibodies will mean that proteins are intensely well labeled on the outer edge of the tissue, but virtually none of the antibodies will find cells and proteins deeper inside.&lt;/p&gt;&lt;p&gt;To improve labeling, the team conceived of a way — the conceptual essence of CuRVE — to resolve the speed mismatch. The strategy was to continuously control the pace of antibody binding while at the same time speeding up antibody permeation throughout the tissue. To figure out how this could work and to optimize the approach, they built and ran a sophisticated computational simulation that enabled them to test different settings and parameters, including different binding rates and tissue densities and compositions.&lt;/p&gt;&lt;p&gt;Then they set out to implement their approach in real tissues. Their starting point was a previous technology, called “&lt;a href="https://picower.mit.edu/innovations-inventions/switch"&gt;SWITCH&lt;/a&gt;,” in which Chung’s lab devised a way of temporarily turning off antibody binding, letting the antibodies permeate the tissue, and then turning binding back on. As well as it worked, Yun says, the team realized there could be substantial improvements if antibody binding speed could be controlled constantly, but the chemicals used in SWITCH were too harsh for such ongoing treatment. So the team screened a library of similar chemicals to find one that could more subtly and continuously throttle antibody binding speed. They found that deoxycholic acid was an ideal candidate. Using that chemical, the team could not only modulate antibody binding by varying the chemical’s concentration, but also by varying the labeling bath’s pH (or acidity).&lt;/p&gt;&lt;p&gt;Meanwhile, to speed up antibody movement through tissues, the team used another prior technology invented in the Chung Lab: stochastic electrotransport. That technology accelerates the dispersion of antibodies through tissue by applying electric fields.&lt;/p&gt;&lt;p&gt;Implementing this eFLASH system of accelerated dispersion with continuously modifiable binding speed produced the wide variety of labeling successes demonstrated in the paper. In all, the team reported using more than 60 different antibodies to label proteins in cells across large tissue samples.&lt;/p&gt;&lt;p&gt;Notably, each of these specimens was labeled within a day, an “ultra-fast” speed for whole, intact organs, the authors say. Moreover, different preparations did not require new optimization steps.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Valuable visualizations&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Among the ways the team put eFLASH to the test was by comparing their labeling to another often-used method: genetically engineering cells to fluoresce when the gene for a protein of interest is being transcribed. The genetic method doesn’t require dispersing antibodies throughout tissue, but it can be prone to discrepancies because reporting gene transcription and actual protein production are not exactly the same thing. Yun added that while antibody labeling reliably and immediately reports on the presence of a target protein, the genetic method can be much less immediate and persistent, still fluorescing even when the actual protein is no longer present.&lt;/p&gt;&lt;p&gt;In the study the team employed both kinds of labeling simultaneously in samples. Visualizing the labels that way, they saw many examples in which antibody labeling and genetic labeling differed widely. In some areas of mouse brains, they found that two-thirds of the neurons expressing PV (a protein prominent in certain inhibitory neurons) according to antibody labeling, did not show any genetically-based fluorescence. In another example, only a tiny fraction of cells that reported expression via the genetic method of a protein called ChAT also reported it via antibody labeling. In other words, there were cases where genetic labeling both severely underreported or overreported protein expression compared to antibody labeling.&lt;/p&gt;&lt;p&gt;The researchers don’t mean to impugn the clear value of using the genetic reporting methods, but instead suggest that also using organ-wide antibody labeling, as eFLASH allows, can help put that data in a richer, more complete context. “Our discovery of large regionalized loss of PV-immunoreactive neurons in healthy adult mice and with high individual variability emphasizes the importance of holistic and unbiased phenotyping,” the authors write.&lt;/p&gt;&lt;p&gt;Or as Yun puts it, the two different kinds of labeling are “two different tools for the job.”&lt;/p&gt;&lt;p&gt;In addition to Yun, Park, and Chung, the paper’s other authors are Jae Hun Cho, Lee Kamentsky, Nicholas Evans, Nicholas DiNapoli, Katherine Xie, Seo Woo Choi, Alexandre Albanese, Yuxuan Tian, Chang Ho Sohn, Qiangge Zhang, Minyoung Kim, Justin Swaney, Webster Guan, Juhyuk Park, Gabi Drummond, Heejin Choi, Luzdary Ruelas, and Guoping Feng.&lt;/p&gt;&lt;p&gt;Funding for the study came from the Burroughs Wellcome Fund, the Searle Scholars Program, a Packard Award in Science and Engineering, a NARSAD Young Investigator Award, the McKnight Foundation, the Freedom Together Foundation, The Picower Institute for Learning and Memory, the NCSOFT Cultural Foundation, and the National Institutes of Health.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/mouse-brain-proteins.jpg?itok=a1xVGK2F" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[In a new study, researchers demonstrate a technology that allows scientists to visualize proteins in large tissue samples. Here, a mouse brain hemisphere is stained with various cell type markers: neurons overall (cyan), and cells specifically involved with neurotransmitters dopamine (yellow) and acetylcholine (magenta).]]></media:description>
              <media:credit>Image courtesy of the Chung Lab.</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/imaging">Imaging</category>
      <category domain="https://news.mit.edu/topic/proteins">Proteins</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/chemical-engineering">Chemical engineering</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0">Institute for Medical Engineering and Science (IMES)</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/nsf">National Science Foundation (NSF)</category>
    </item>
<item>
  <title>Evelina Fedorenko receives Troland Award from National Academy of Sciences</title>
  <link>https://news.mit.edu/2025/evelina-fedorenko-receives-troland-award-0129</link>
  <description><![CDATA[Cognitive neuroscientist is recognized for her groundbreaking discoveries about the brain’s language system.]]></description>
  <pubDate>Wed, 29 Jan 2025 16:25:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/evelina-fedorenko-receives-troland-award-0129</guid>
        <dc:creator>Julie Pryor | McGovern Institute for Brain Research</dc:creator>
  <content:encoded>&lt;p&gt;The National Academy of Sciences (NAS) recently &lt;a href="https://www.nasonline.org/award/troland-research-award/" target="_blank"&gt;announced&lt;/a&gt; that MIT Associate Professor &lt;a href="https://mcgovern.mit.edu/profile/ev-fedorenko/"&gt;Evelina Fedorenko&lt;/a&gt; will receive a 2025 Troland Research Award for her groundbreaking contributions toward understanding the language network in the human brain.&lt;/p&gt;&lt;p&gt;The Troland Research Award is given annually to recognize unusual achievement by early-career researchers within the broad spectrum of experimental psychology.&lt;/p&gt;&lt;p&gt;Fedorenko, an associate professor of brain and cognitive sciences and a McGovern Institute for Brain Research investigator, is interested in how minds and brains create language. Her lab is unpacking the internal architecture of the brain’s language system and exploring the relationship between language and various cognitive, perceptual, and motor systems. Her novel methods combine precise measures of an individual’s brain organization with innovative computational modeling to make fundamental discoveries about the computations that underlie the uniquely human ability for language.&lt;/p&gt;&lt;p&gt;Fedorenko has shown that the language network is selective for language processing over diverse non-linguistic processes that have been argued to share computational demands with language, such as math, music, and social reasoning. Her work has also demonstrated that syntactic processing is not localized to a particular region within the language network, and every brain region that responds to syntactic processing is at least as sensitive to word meanings.&lt;/p&gt;&lt;p&gt;She has also shown that representations from neural network language models, such as ChatGPT, are similar to those in the human language brain areas. Fedorenko also highlighted that although language models can master linguistic rules and patterns, they are less effective at using language in real-world situations. In the human brain, that kind of functional competence is distinct from formal language competence, she says, requiring not just language-processing circuits but also brain areas that store knowledge of the world, reason, and interpret social interactions. Contrary to a prominent view that language is essential for thinking, Fedorenko argues that language is not the medium of thought and is primarily a tool for communication.&lt;/p&gt;&lt;p&gt;Ultimately, Fedorenko’s cutting-edge work is uncovering the computations and representations that fuel language processing in the brain. She will receive the Troland Award this April, during the annual meeting of the NAS in Washington.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/mit-evelina-fedorenko.jpg?itok=9tHdw92q" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[MIT cognitive neuroscientist Evelina Fedorenko received the 2025 Troland Research Award from the National Academy of Sciences. ]]></media:description>
              <media:credit>Photo: Alexandra Sokhina </media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/faculty">Faculty</category>
      <category domain="https://news.mit.edu/topic/language">Language</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Professor Emeritus Gerald Schneider, discoverer of the “two visual systems,” dies at 84</title>
  <link>https://news.mit.edu/2025/professor-emeritus-gerald-schneider-dies-0127</link>
  <description><![CDATA[An MIT affiliate for some 60 years, Schneider was an authority on the relationships between brain structure and behavior.]]></description>
  <pubDate>Mon, 27 Jan 2025 16:30:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/professor-emeritus-gerald-schneider-dies-0127</guid>
        <dc:creator>Department of Brain and Cognitive Sciences</dc:creator>
  <content:encoded>&lt;p dir="ltr"&gt;Gerald E. Schneider, a professor emeritus of psychology and member of the MIT community for over 60 years, passed away on Dec. 11, 2024. He was 84.&lt;/p&gt;&lt;p dir="ltr"&gt;Schneider was an authority on the relationships between brain structure and behavior, concentrating on neuronal development, regeneration or altered growth after brain injury, and the behavioral consequences of altered connections in the brain.&lt;/p&gt;&lt;p dir="ltr"&gt;Using the Syrian golden hamster as his test subject of choice, Schneider made numerous contributions to the advancement of neuroscience. He laid out the concept of two visual systems — one for locating objects and one for the identification of objects —&amp;nbsp;&lt;a href="https://www.science.org/doi/epdf/10.1126/science.163.3870.895" target="_blank" rel="noopener noreferrer"&gt;in a 1969 issue of&amp;nbsp;&lt;em&gt;Science&lt;/em&gt;&lt;/a&gt;,&amp;nbsp;a milestone in the study of brain-behavior relationships. In 1973, he described a “&lt;a href="https://karger.com/bbe/article/8/1-2/73/326597/Early-Lesions-of-Superior-Colliculus-Factors" target="_blank" rel="noopener noreferrer"&gt;pruning effect&lt;/a&gt;” in the optic tract axons of adult hamsters who had brain lesions early in life. In 2006, his lab reported a previously undiscovered nanobiomedical technology for tissue repair and restoration in&amp;nbsp;&lt;em&gt;Biological Sciences&lt;/em&gt;.&amp;nbsp;The &lt;a href="https://www.pnas.org/doi/full/10.1073/pnas.0600559103" target="_blank" rel="noopener noreferrer"&gt;paper showed&lt;/a&gt; how a designed self-assembling peptide nanofiber scaffold could create a permissive environment for axons, not only to regenerate through the site of an acute injury in the optic tract of hamsters, but also to knit the brain tissue together.&lt;/p&gt;&lt;p dir="ltr"&gt;His work shaped the research and thinking of numerous colleagues and trainees. Mriganka Sur, the Newton Professor of Neuroscience and former Department of Brain and Cognitive Sciences (BCS) department head, recalls how Schneider’s paper, “Is it really better to have your brain lesion early? A revision of the ‘Kennard Principle,’” published in 1979 in the journal&amp;nbsp;&lt;em&gt;Neuropsychologia&lt;/em&gt;, influenced his work on rewiring retinal projections to the auditory thalamus, which was used to derive principles of functional plasticity in the cortex.&lt;/p&gt;&lt;p dir="ltr"&gt;“Jerry was an extremely innovative thinker. His hypothesis of two visual systems — for detailed spatial processing and for movement processing — based on his analysis of visual pathways in hamsters presaged and inspired later work on form and motion pathways in the primate brain,” Sur says. “His description of conservation of axonal arbor during development laid the foundation for later ideas about homeostatic mechanisms that co-regulate neuronal plasticity.”&lt;/p&gt;&lt;p dir="ltr"&gt;Institute Professor Ann Graybiel was a colleague of Schneider’s for over five decades. She recalls early in her career being asked by Schneider to help make a map of the superior colliculus.&lt;/p&gt;&lt;p dir="ltr"&gt;“I took it as an honor to be asked, and I worked very hard on this, with great excitement. It was my first such mapping, to be followed by much more in the future,” Graybiel recalls. “Jerry was fascinated by animal behavior, and from early on he made many discoveries using hamsters as his main animals of choice. He found that they could play. He found that they could operate in ways that seemed very sophisticated. And, yes, he mapped out pathways in their brains.”&lt;/p&gt;&lt;p dir="ltr"&gt;Schneider was raised in Wheaton, Illinois, and graduated from Wheaton College in 1962 with a degree in physics. He was recruited to MIT by Hans-Lukas Teuber, one of the founders of the Department of Psychology, which eventually became the Department of Brain and Cognitive Sciences. Walle Nauta, another founder of the department, taught Schneider neuroanatomy.&amp;nbsp;The pair were deeply influential in shaping his interests in neuroscience and his research.&lt;/p&gt;&lt;p dir="ltr"&gt;“He admired them both very much and was very attached to them,” his daughter, Nimisha Schneider, says. “He was an interdisciplinary scholar and he liked that aspect of neuroscience, and he was fascinated by the mysteries of the human brain.”&lt;/p&gt;&lt;p dir="ltr"&gt;Shortly after completing his PhD in psychology in 1966, he was hired as an assistant professor in 1967. He was named an associate professor in 1970, received tenure in 1975, and was appointed a full professor in 1977.&lt;/p&gt;&lt;p dir="ltr"&gt;After his retirement in 2017, Schneider remained involved with the Department of BCS. Professor Pawan Sinha brought Schneider to campus for what would be his last on-campus engagement, as part of the “SilverMinds Series,” an initiative in the Sinha Lab to engage with scientists now in their “silver years.”&lt;/p&gt;&lt;p dir="ltr"&gt;Schneider’s research made an indelible impact on Sinha, beginning as a graduate student when he was inspired by Schneider’s work linking brain structure and function. His work on nerve regeneration, which merged fundamental science and real-world impact, served as a “North Star” that guided Sinha’s own work as he established his lab as a junior faculty member.&lt;/p&gt;&lt;p dir="ltr"&gt;“Even through the sadness of his loss, I am grateful for the inspiring example he has left for us of a life that so seamlessly combined brilliance, kindness, modesty, and tenacity,” Sinha says. “He will be missed.”&lt;/p&gt;&lt;p dir="ltr"&gt;Schneider’s life centered around his research and teaching, but he also had many other skills and hobbies. Early in his life, he enjoyed painting, and as he grew older he was drawn to poetry. He was also skilled in carpentry and making furniture. He built the original hamster cages for his lab himself, along with numerous pieces of home furniture and shelving. He enjoyed nature anywhere it could be found, from the bees in his backyard to hiking and visiting state and national parks.&lt;/p&gt;&lt;p dir="ltr"&gt;He was a Type 1 diabetic, and at the time of his death, he was nearing the completion of a book on the effects of hypoglycemia on the brain, which his family hopes to have published in the future. He was also the author of “Brain Structure and Its Origins,” published in 2014 by MIT Press.&lt;/p&gt;&lt;p dir="ltr"&gt;He is survived by his wife, Aiping; his children, Cybele, Aniket, and Nimisha; and step-daughter Anna. He was predeceased by a daughter, Brenna. He is also survived by eight grandchildren and 10 great-grandchildren. A memorial in his honor was held on Jan. 11 at Saint James Episcopal Church in Cambridge.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/schneider-mit-a1.jpg?itok=3688Sa8h" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Gerald Schneider]]></media:description>
              <media:credit>Photo courtesy of Aiping Schneider.</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/obituaries">Obituaries</category>
      <category domain="https://news.mit.edu/topic/faculty">Faculty</category>
      <category domain="https://news.mit.edu/topic/vision">Vision</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Modeling complex behavior with a simple organism</title>
  <link>https://news.mit.edu/2025/modeling-complex-behavior-steven-flavell-0121</link>
  <description><![CDATA[By studying the roundworm C. elegans, neuroscientist Steven Flavell explores how neural circuits give rise to behavior.]]></description>
  <pubDate>Tue, 21 Jan 2025 00:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/modeling-complex-behavior-steven-flavell-0121</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;The roundworm &lt;em&gt;C. elegans&lt;/em&gt; is a simple animal whose nervous system has exactly 302 neurons. Each of the connections between those neurons has been comprehensively mapped, allowing researchers to study how they work together to generate the animal’s different behaviors.&lt;/p&gt;&lt;p&gt;Steven Flavell, an MIT associate professor of brain and cognitive sciences and investigator with The Picower Institute for Learning and Memory at MIT and the Howard Hughes Medical Institute, uses the worm as a model to study motivated behaviors such as feeding and navigation, in hopes of shedding light on the fundamental mechanisms that may also determine how similar behaviors are controlled in other animals.&lt;/p&gt;&lt;p&gt;In recent studies, Flavell’s lab has uncovered neural mechanisms underlying adaptive changes in the worms’ feeding behavior, and his lab has also mapped how the activity of each neuron in the animal’s nervous system affects the worms’ different behaviors.&lt;/p&gt;&lt;p&gt;Such studies could help researchers gain insight into how brain activity generates behavior in humans. “It is our aim to identify molecular and neural circuit mechanisms that may generalize across organisms,” he says, noting that many fundamental biological discoveries, including those related to programmed cell death, microRNA, and RNA interference, were first made in &lt;em&gt;C. elegans&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;“Our lab has mostly studied motivated state-dependent behaviors, like feeding and navigation. The machinery that’s being used to control these states in &lt;em&gt;C. elegans&lt;/em&gt; — for example, neuromodulators — are actually the same as in humans. These pathways are evolutionarily ancient,” he says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Drawn to the lab&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Born in London to an English father and a Dutch mother, Flavell came to the United States in 1982 at the age of 2, when his father became chief scientific officer at Biogen. The family lived in Sudbury, Massachusetts, and his mother worked as a computer programmer and math teacher. His father later became a professor of immunology at Yale University.&lt;/p&gt;&lt;p&gt;Though Flavell grew up in a science family, he thought about majoring in English when he arrived at Oberlin College. A musician as well, Flavell took jazz guitar classes at Oberlin’s conservatory, and he also plays the piano and the saxophone. However, taking classes in psychology and physiology led him to discover that the field that most captivated him was neuroscience.&lt;/p&gt;&lt;p&gt;“I was immediately sold on neuroscience. It combined the rigor of the biological sciences with deep questions from psychology,” he says.&lt;/p&gt;&lt;p&gt;While in college, Flavell worked on a summer research project related to Alzheimer’s disease, in a lab at Case Western Reserve University. He then continued the project, which involved analyzing post-mortem Alzheimer’s tissue, during his senior year at Oberlin.&lt;/p&gt;&lt;p&gt;“My earliest research revolved around mechanisms of disease. While my research interests have evolved since then, my earliest research experiences were the ones that really got me hooked on working at the bench: running experiments, looking at brand new results, and trying to understand what they mean,” he says.&lt;/p&gt;&lt;p&gt;By the end of college, Flavell was a self-described lab rat: “I just love being in the lab.” He applied to graduate school and ended up going to Harvard Medical School for a PhD in neuroscience. Working with Michael Greenberg, Flavell studied how sensory experience and resulting neural activity shapes brain development. In particular, he focused on a family of gene regulators called MEF2, which play important roles in neuronal development and synaptic plasticity.&lt;/p&gt;&lt;p&gt;All of that work was done using mouse models, but Flavell transitioned to studying &lt;em&gt;C. elegans&lt;/em&gt; during a postdoctoral fellowship working with Cori Bargmann at Rockefeller University. He was interested in studying how neural circuits control behavior, which seemed to be more feasible in simpler animal models.&lt;/p&gt;&lt;p&gt;“Studying how neurons across the brain govern behavior felt like it would be nearly intractable in a large brain — to understand all the nuts and bolts of how neurons interact with each other and ultimately generate behavior seemed daunting,” he says. “But I quickly became excited about studying this in &lt;em&gt;C. elegans&lt;/em&gt; because at the time it was still the only animal with a full blueprint of its brain: a map of every brain cell and how they are all wired up together.”&lt;/p&gt;&lt;p&gt;That wiring diagram includes about 7,000 synapses in the entire nervous system. By comparison, a single human neuron may form more than 10,000 synapses. “Relative to those larger systems, the &lt;em&gt;C. elegans&lt;/em&gt; nervous system is mind-bogglingly simple,” Flavell says.&lt;/p&gt;&lt;p&gt;Despite their much simpler organization, roundworms can execute complex behaviors such as feeding, locomotion, and egg-laying. They even sleep, form memories, and find suitable mating partners. The neuromodulators and cellular machinery that give rise to those behaviors are similar to those found in humans and other mammals.&lt;/p&gt;&lt;p&gt;“C. elegans has a fairly well-defined, smallish set of behaviors, which makes it attractive for research. You can really measure almost everything that the animal is doing and study it,” Flavell says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How behavior arises&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Early in his career, Flavell’s work on &lt;em&gt;C. elegans&lt;/em&gt; revealed the neural mechanisms that underlie the animal’s stable behavioral states. When worms are foraging for food, they alternate between stably exploring the environment and pausing to feed. “The transition rates between those states really depend on all these cues in the environment. How good is the food environment? How hungry are they? Are there smells indicating a better nearby food source? The animal integrates all of those things and then adjusts their foraging strategy,” Flavell says.&lt;/p&gt;&lt;p&gt;These stable behavioral states are controlled by neuromodulators like serotonin. By studying serotonergic regulation of the worm’s behavioral states, Flavell’s lab has been able to uncover how this important system is organized. In a &lt;a href="https://news.mit.edu/2023/study-reveals-serotonins-effects-0522" target="_blank"&gt;recent study&lt;/a&gt;, Flavell and his colleagues published an “atlas” of the &lt;em&gt;C. elegans&lt;/em&gt; serotonin system. They identified every neuron that produces serotonin, every neuron that has serotonin receptors, and how brain activity and behavior change across the animal as serotonin is released.&lt;/p&gt;&lt;p&gt;“Our studies of how the serotonin system works to control behavior have already revealed basic aspects of serotonin signaling that we think ought to generalize all the way up to mammals,” Flavell says. “By studying the way that the brain implements these long-lasting states, we can tap into these basic features of neuronal function. With the resolution that you can get studying specific &lt;em&gt;C. elegans&lt;/em&gt; neurons and the way that they implement behavior, we can uncover fundamental features of the way that neurons act.”&lt;/p&gt;&lt;p&gt;In parallel, Flavell’s lab has also been mapping out how neurons across the &lt;em&gt;C. elegans&lt;/em&gt; brain control different aspects of behavior. In a&amp;nbsp;&lt;a href="https://news.mit.edu/2023/cracking-code-relates-brain-behavior-simple-animal-0823" target="_blank"&gt;2023 study&lt;/a&gt;,&amp;nbsp;Flavell’s lab mapped how changes in brain-wide activity relate to behavior. His lab uses special microscopes that can move along with the worms as they explore, allowing them to simultaneously track every behavior and measure the activity of every neuron in the brain. Using these data, the researchers created computational models that can accurately capture the relationship between brain activity and behavior.&lt;/p&gt;&lt;p&gt;This type of research requires expertise in many areas, Flavell says. When looking for faculty jobs, he hoped to find a place where he could collaborate with researchers working in different fields of neuroscience, as well as scientists and engineers from other departments.&lt;/p&gt;&lt;p&gt;“Being at MIT has allowed my lab to be much more multidisciplinary than it could have been elsewhere,” he says. “My lab members have had undergrad degrees in physics, math, computer science, biology, neuroscience, and we use tools from all of those disciplines. We engineer microscopes, we build computational models, we come up with molecular tricks to perturb neurons in the &lt;em&gt;C. elegans&lt;/em&gt; nervous system. And I think being able to deploy all those kinds of tools leads to exciting research outcomes.”&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/MIT-steven-flavell-01-press.jpg?itok=rDIs_9sD" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[MIT Associate Professor Steven Flavell uses the worm C. elegans as a model to study behaviors such as feeding and navigation, in hopes of shedding light on how these behaviors are controlled in other animals, including humans.]]></media:description>
              <media:credit>Photo: Bryce Vickmark</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/faculty">Faculty</category>
      <category domain="https://news.mit.edu/topic/profile">Profile</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/animals">Animals</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Three MIT students named 2026 Schwarzman Scholars</title>
  <link>https://news.mit.edu/2025/mit-students-named-schwarzman-scholars-0115</link>
  <description><![CDATA[Yutao Gong, Brandon Man, and Andrii Zahorodnii will spend 2025-26 at Tsinghua University in China studying global affairs.]]></description>
  <pubDate>Wed, 15 Jan 2025 14:45:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/mit-students-named-schwarzman-scholars-0115</guid>
        <dc:creator>Julia Mongo | Office of Distinguished Fellowships</dc:creator>
  <content:encoded>&lt;p&gt;Three MIT students — Yutao Gong, Brandon Man, and Andrii Zahorodnii — have been awarded 2025 Schwarzman Scholarships and will join the program’s 10th cohort to pursue a master’s degree in global affairs at Tsinghua University in Beijing, China.&lt;/p&gt;&lt;p&gt;The MIT students were selected from a pool of over 5,000 applicants. This year’s class of 150 scholars represents 38 countries and 105 universities from around the world.&lt;/p&gt;&lt;p&gt;The Schwarzman Scholars program aims to develop leadership skills and deepen understanding of China’s changing role in the world. The fully funded one-year master’s program at Tsinghua University emphasizes leadership, global affairs, and China. Scholars also gain exposure to China through mentoring, internships, and experiential learning.&lt;/p&gt;&lt;p&gt;MIT’s Schwarzman Scholar applicants receive guidance and mentorship from the distinguished fellowships team in Career Advising and Professional Development and the Presidential Committee on Distinguished Fellowships.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Yutao Gong&lt;/strong&gt; will graduate this spring from the Leaders for Global Operations program at the MIT Sloan School of Management, earning a dual MBA and a MS degree in civil and environmental engineering with a focus on manufacturing and operations. Gong, who hails from Shanghai, China, has academic, work, and social engagement experiences in China, the United States, Jordan, and Denmark. She was previously a consultant at Boston Consulting Group working on manufacturing, agriculture, sustainability, and renewable energy-related projects, and spent two years in Chicago and one year in Greater China as a global ambassador. Gong graduated magna cum laude from Duke University with double majors in environmental science and statistics, where she organized the Duke China-U.S. Summit.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Brandon Man&lt;/strong&gt;, from Canada and Hong Kong, is a master’s student in the Department of Mechanical Engineering at MIT, where he studies generative artificial intelligence (genAI) for engineering design. Previously, he graduated from Cornell University magna cum laude with honors in computer science. With a wealth of experience in robotics — from assistive robots to next-generation spacesuits for NASA to Tencent’s robot dog, Max — he is now a co-founder of Sequestor, a genAI-powered data aggregation platform that enables carbon credit investors to perform faster due diligence. His goal is to bridge the best practices of the Eastern and Western tech worlds.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Andrii Zahorodnii&lt;/strong&gt;, from Ukraine, will graduate this spring with a bachelor of science and a master of engineering degree in computer science and cognitive sciences. An engineer as well as a neuroscientist, he has conducted research at MIT with Professor Guangyu Robert Yang’s MetaConscious Group and the Fiete Lab. Zahorodnii is passionate about using AI to uncover insights into human cognition, leading to more-informed, empathetic, and effective global decision-making and policy. Besides driving the exchange of ideas as a TEDxMIT organizer, he strives to empower and inspire future leaders internationally and in Ukraine through the Ukraine Leadership and Technology Academy he founded.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/MIT-Schwarzman-Scholars.jpg?itok=7yJASGdU" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Left to right: Yutao Gong, Brandon Man, and Andrii Zahorodnii]]></media:description>
              <media:credit>Photos courtesy of the Schwarzman Scholars.</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/students">Students</category>
      <category domain="https://news.mit.edu/topic/undergraduate">Undergraduate</category>
      <category domain="https://news.mit.edu/topic/graduate">Graduate, postdoctoral</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/civil-engineering">Civil and environmental engineering</category>
      <category domain="https://news.mit.edu/topic/mechanical-engineering">Mechanical engineering</category>
      <category domain="https://news.mit.edu/topic/leaders-global-operations-lgo">Leaders for Global Operations (LGO)</category>
      <category domain="https://news.mit.edu/topic/leadership">Leadership</category>
      <category domain="https://news.mit.edu/topic/business">Business and management</category>
      <category domain="https://news.mit.edu/topic/global">Global</category>
      <category domain="https://news.mit.edu/topic/china">China</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/mit-sloan-school-management">MIT Sloan School of Management</category>
    </item>
<item>
  <title>How one brain circuit encodes memories of both places and events</title>
  <link>https://news.mit.edu/2025/how-one-brain-circuit-encodes-memories-places-and-events-0115</link>
  <description><![CDATA[A new computational model explains how neurons linked to spatial navigation can also help store episodic memories.]]></description>
  <pubDate>Wed, 15 Jan 2025 11:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/how-one-brain-circuit-encodes-memories-places-and-events-0115</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;Nearly 50 years ago, neuroscientists discovered cells within the brain’s hippocampus that store memories of specific locations. These cells also play an important role in storing memories of events, known as episodic memories. While the mechanism of how place cells encode spatial memory has been well-characterized, it has remained a puzzle how they encode episodic memories.&lt;/p&gt;&lt;p&gt;A new model developed by MIT researchers explains how those place cells can be recruited to form episodic memories, even when there’s no spatial component. According to this model, place cells, along with grid cells found in the entorhinal cortex, act as a scaffold that can be used to anchor memories as a linked series.&lt;/p&gt;&lt;p&gt;“This model is a first-draft model of the entorhinal-hippocampal episodic memory circuit. It’s a foundation to build on to understand the nature of episodic memory. That’s the thing I’m really excited about,” says Ila Fiete, a professor of brain and cognitive sciences at MIT, a member of MIT’s McGovern Institute for Brain Research,&amp;nbsp;and the senior author of the new study.&lt;/p&gt;&lt;p&gt;The model accurately replicates several features of biological memory systems, including the large storage capacity, gradual degradation of older memories, and the ability of people who compete in memory competitions to store enormous amounts of information in “memory palaces.”&lt;/p&gt;&lt;p&gt;MIT Research Scientist Sarthak Chandra and Sugandha Sharma PhD ’24 are the lead authors of the study, which &lt;a href="https://www.nature.com/articles/s41586-024-08392-y" target="_blank"&gt;appears today in &lt;em&gt;Nature&lt;/em&gt;&lt;/a&gt;. Rishidev Chaudhuri, an assistant professor at the University of California at Davis, is also an author of the paper.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;An index of memories&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To encode spatial memory, place cells in the hippocampus work closely with grid cells — a special type of neuron that fires at many different locations, arranged geometrically in a regular pattern of repeating triangles. Together, a population of grid cells forms a lattice of triangles representing a physical space.&lt;/p&gt;&lt;p&gt;In addition to helping us recall places where we’ve been, these hippocampal-entorhinal circuits also help us navigate new locations. From human patients, it’s known that these circuits are also critical for forming episodic memories, which might have a spatial component but mainly consist of events, such as how you celebrated your last birthday or what you had for lunch yesterday.&lt;/p&gt;&lt;p&gt;“The same hippocampal and entorhinal circuits are used not just for spatial memory, but also for general episodic memory,” Fiete says. “The question you can ask is what is the connection between spatial and episodic memory that makes them live in the same circuit?”&lt;/p&gt;&lt;p&gt;Two hypotheses have been proposed to account for this overlap in function. One is that the circuit is specialized to store spatial memories because those types of memories — remembering where food was located or where predators were seen — are important to survival. Under this hypothesis, this circuit encodes episodic memories as a byproduct of spatial memory.&lt;/p&gt;&lt;p&gt;An alternative hypothesis suggests that the circuit is specialized to store episodic memories, but also encodes spatial memory because location is one aspect of many episodic memories.&lt;/p&gt;&lt;p&gt;In this work, Fiete and her colleagues proposed a third option: that the peculiar tiling structure of grid cells and their interactions with hippocampus are equally important for both types of memory — episodic and spatial. To develop their new model, they built on computational models that her lab has been developing over the past decade, which mimic how grid cells encode spatial information.&lt;/p&gt;&lt;p&gt;“We reached the point where I felt like we understood on some level the mechanisms of the grid cell circuit, so it felt like the time to try to understand the interactions between the grid cells and the larger circuit that includes the hippocampus,” Fiete says.&lt;/p&gt;&lt;p&gt;In the new model, the researchers hypothesized that grid cells interacting with hippocampal cells can act as a scaffold for storing either spatial or episodic memory. Each activation pattern within the grid defines a “well,” and these wells are spaced out at regular intervals. The wells don’t store the content of a specific memory, but each one acts as a pointer to a specific memory, which is stored in the synapses between the hippocampus and the sensory cortex.&lt;/p&gt;&lt;p&gt;When the memory is triggered later from fragmentary pieces, grid and hippocampal cell interactions drive the circuit state into the nearest well, and the state at the bottom of the well connects to the appropriate part of the sensory cortex to fill in the details of the memory. The sensory cortex is much larger than the hippocampus and can store vast amounts of memory.&lt;/p&gt;&lt;p&gt;“Conceptually, we can think about the hippocampus as a pointer network. It’s like an index that can be pattern-completed from a partial input, and that index then points toward sensory cortex, where those inputs were experienced in the first place,” Fiete says. “The scaffold doesn’t contain the content, it only contains this index of abstract scaffold states.”&lt;/p&gt;&lt;p&gt;Furthermore, events that occur in sequence can be linked together: Each well in the grid cell-hippocampal network efficiently stores the information that is needed to activate the next well, allowing memories to be recalled in the right order.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Modeling memory cliffs and palaces&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The researchers’ new model replicates several memory-related phenomena much more accurately than existing models that are based on Hopfield networks — a type of neural network that can store and recall patterns.&lt;/p&gt;&lt;p&gt;While Hopfield networks offer insight into how memories can be formed by strengthening connections between neurons, they don’t perfectly model how biological memory works. In Hopfield models, every memory is recalled in perfect detail until capacity is reached. At that point, no new memories can form, and worse, attempting to add more memories erases all prior ones. This “memory cliff” doesn’t accurately mimic what happens in the biological brain, which tends to gradually forget the details of older memories while new ones are continually added.&lt;/p&gt;&lt;p&gt;The new MIT model captures findings from decades of recordings of grid and hippocampal cells in rodents made as the animals explore and forage in various environments. It also helps to explain the underlying mechanisms for a memorization strategy known as a memory palace. One of the tasks in memory competitions is to memorize the shuffled sequence of cards in one or several card decks. They usually do this by assigning each card to a particular spot in a memory palace — a memory of a childhood home or other environment they know well. When they need to recall the cards, they mentally stroll through the house, visualizing&amp;nbsp;each card in its spot as they go along. Counterintuitively, adding the memory burden of associating cards with locations makes recall stronger and more reliable.&lt;/p&gt;&lt;p&gt;The MIT team’s computational model was able to perform such tasks very well, suggesting that memory palaces take advantage of the memory circuit’s own strategy of associating inputs with a scaffold in the hippocampus, but one level down: Long-acquired memories reconstructed in the larger sensory cortex can now be pressed into service as a scaffold for new memories. This allows for the storage and recall of many more items in a sequence than would otherwise be possible.&lt;/p&gt;&lt;p&gt;The researchers now plan to build on their model to explore how episodic memories could become converted to cortical “semantic” memory, or the memory of facts dissociated from the specific context in which they were acquired (for example, Paris is the capital of France), how episodes are defined, and how brain-like memory models could be integrated into modern machine learning.&lt;/p&gt;&lt;p&gt;The research was funded by the U.S. Office of Naval Research, the National Science Foundation under the Robust Intelligence program, the ARO-MURI award, the Simons Foundation, and the K. Lisa Yang ICoN Center.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/MIT-Memory-Circuit01-PRESS.jpg?itok=3aWRxFye" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[A new model developed by MIT researchers explains how those place cells can be recruited to form episodic memories, even when there’s no spatial component.]]></media:description>
              <media:credit>Credit: Christine Daniloff, MIT; iStock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>For healthy hearing, timing matters</title>
  <link>https://news.mit.edu/2025/for-healthy-hearing-timing-matters-0114</link>
  <description><![CDATA[Machine-learning models let neuroscientists study the impact of auditory processing on real-world hearing.]]></description>
  <pubDate>Tue, 14 Jan 2025 15:15:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/for-healthy-hearing-timing-matters-0114</guid>
        <dc:creator>Jennifer Michalowski | McGovern Institute for Brain Research</dc:creator>
  <content:encoded>&lt;p&gt;When sound waves reach the inner ear, neurons there pick up the vibrations and alert the brain. Encoded in their signals is a wealth of information that enables us to follow conversations, recognize familiar voices, appreciate music, and quickly locate a ringing phone or crying baby.&lt;/p&gt;&lt;p&gt;Neurons send signals by emitting spikes — brief changes in voltage that propagate along nerve fibers, also known as action potentials. Remarkably, auditory neurons can fire hundreds of spikes per second, and time their spikes with exquisite precision to match the oscillations of incoming sound waves.&lt;/p&gt;&lt;p&gt;With powerful new models of human hearing, scientists at MIT’s McGovern Institute for Brain Research have determined that this precise timing is vital for some of the most important ways we make sense of auditory information, including recognizing voices and localizing sounds.&lt;/p&gt;&lt;p&gt;The open-access findings, &lt;a href="https://www.nature.com/articles/s41467-024-54700-5" target="_blank"&gt;reported Dec. 4 in the journal &lt;em&gt;Nature Communications&lt;/em&gt;&lt;/a&gt;, show how machine learning can help neuroscientists understand how the brain uses auditory information in the real world. MIT professor and McGovern investigator &lt;a href="https://mcgovern.mit.edu/profile/josh-mcdermott/"&gt;Josh McDermott&lt;/a&gt;, who led the research, explains that his team’s models better-equip researchers to study the consequences of different types of hearing impairment and devise more effective interventions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Science of sound&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The nervous system’s auditory signals are timed so precisely, researchers have long suspected that timing is important to our perception of sound. Sound waves oscillate at rates that determine their pitch: Low-pitched sounds travel in slow waves, whereas high-pitched sound waves oscillate more frequently. The auditory nerve that relays information from sound-detecting hair cells in the ear to the brain generates electrical spikes that correspond to the frequency of these oscillations. “The action potentials in an auditory nerve get fired at very particular points in time relative to the peaks in the stimulus waveform,” explains McDermott, who is also associate head of the MIT Department of Brain and Cognitive Sciences.&lt;/p&gt;&lt;p&gt;This relationship, known as phase-locking, requires neurons to time their spikes with sub-millisecond precision. But scientists haven’t really known how informative these temporal patterns are to the brain. Beyond being scientifically intriguing, McDermott says, the question has important clinical implications: “If you want to design a prosthesis that provides electrical signals to the brain to reproduce the function of the ear, it’s arguably pretty important to know what kinds of information in the normal ear actually matter,” he says.&lt;/p&gt;&lt;p&gt;This has been difficult to study experimentally; animal models can’t offer much insight into how the human brain extracts structure in language or music, and the auditory nerve is inaccessible for study in humans. So McDermott and graduate student Mark Saddler PhD ’24 turned to artificial neural networks.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Artificial hearing&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Neuroscientists have long used computational models to explore how sensory information might be decoded by the brain, but until recent advances in computing power and machine learning methods, these models were limited to simulating simple tasks. “One of the problems with these prior models is that they’re often way too good,” says Saddler, who is now at the Technical University of Denmark. For example, a computational model tasked with identifying the higher pitch in a pair of simple tones is likely to perform better than people who are asked to do the same thing. “This is not the kind of task that we do every day in hearing,” Saddler points out. “The brain is not optimized to solve this very artificial task.” This mismatch limited the insights that could be drawn from this prior generation of models.&lt;/p&gt;&lt;p&gt;To better understand the brain, Saddler and McDermott wanted to challenge a hearing model to do things that people use their hearing for in the real world, like recognizing words and voices. That meant developing an artificial neural network to simulate the parts of the brain that receive input from the ear. The network was given input from some 32,000 simulated sound-detecting sensory neurons and then optimized for various real-world tasks.&lt;/p&gt;&lt;p&gt;The researchers showed that their model replicated human hearing well — better than any previous model of auditory behavior, McDermott says. In one test, the artificial neural network was asked to recognize words and voices within dozens of types of background noise, from the hum of an airplane cabin to enthusiastic applause. Under every condition, the model performed very similarly to humans.&lt;/p&gt;&lt;p&gt;When the team degraded the timing of the spikes in the simulated ear, however, their model could no longer match humans’ ability to recognize voices or identify the locations of sounds. For example, while McDermott’s team had previously shown that people use pitch to help them identify people’s voices, the model revealed that that this ability is lost without precisely timed signals. “You need quite precise spike timing in order to both account for human behavior and to perform well on the task,” Saddler says. That suggests that the brain uses precisely timed auditory signals because they aid these practical aspects of hearing.&lt;/p&gt;&lt;p&gt;The team’s findings demonstrate how artificial neural networks can help neuroscientists understand how the information extracted by the ear influences our perception of the world, both when hearing is intact and when it is impaired. “The ability to link patterns of firing in the auditory nerve with behavior opens a lot of doors,” McDermott says.&lt;/p&gt;&lt;p&gt;“Now that we have these models that link neural responses in the ear to auditory behavior, we can ask, ‘If we simulate different types of hearing loss, what effect is that going to have on our auditory abilities?’” McDermott says. “That will help us better diagnose hearing loss, and we think there are also extensions of that to help us design better hearing aids or cochlear implants.” For example, he says, “The cochlear implant is limited in various ways — it can do some things and not others. What’s the best way to set up that cochlear implant to enable you to mediate behaviors? You can, in principle, use the models to tell you that.”&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202412/sound-waves.jpg?itok=EuA2z1nr" medium="image" type="image/jpeg" width="390" height="260">
                  <media:credit>Image: iStock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/hearing2">Hearing</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/machine-learning">Machine learning</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/computer-modeling">Computer modeling</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Study suggests how the brain, with sleep, learns meaningful maps of spaces</title>
  <link>https://news.mit.edu/2025/study-suggests-how-brain-with-sleep-learns-meaningful-maps-spaces-0110</link>
  <description><![CDATA[Place cells are known to encode individual locations, but research finds stitching together a “cognitive map” of a whole environment requires a broader ensemble of cells, aided by sleep, over several days.]]></description>
  <pubDate>Fri, 10 Jan 2025 16:50:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/study-suggests-how-brain-with-sleep-learns-meaningful-maps-spaces-0110</guid>
        <dc:creator>David Orenstein | The Picower Institute for Learning and Memory</dc:creator>
  <content:encoded>&lt;p&gt;On the first day of your vacation in a new city, your explorations expose you to innumerable individual places. While the memories of these spots (like a beautiful garden on a quiet side street) feel immediately indelible, it might be days before you have enough intuition about the neighborhood to direct a newer tourist to that same site and then maybe to the café you discovered nearby. A new study of mice by MIT neuroscientists at The Picower Insitute for Learning and Memory provides new evidence for how the brain forms cohesive cognitive maps of whole spaces and highlights the critical importance of sleep for the process.&lt;/p&gt;&lt;p&gt;Scientists have known for decades that the brain devotes neurons in a region called the hippocampus to remembering specific locations. So-called “place cells” reliably activate when an animal is at the location the neuron is tuned to remember. But more useful than having markers of specific spaces is having a mental model of how they all relate in a continuous overall geography. Though such “cognitive maps” were formally theorized in 1948, neuroscientists have remained unsure of how the brain constructs them. The new &lt;a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(24)01379-2" target="_blank"&gt;study in the December edition of &lt;em&gt;Cell Reports&lt;/em&gt;&lt;/a&gt; finds that the capability may depend upon subtle but meaningful changes over days in the activity of cells that are only weakly attuned to individual locations, but that increase the robustness and refinement of the hippocampus’s encoding of the whole space. With sleep, the study’s analyses indicate, these “weakly spatial” cells increasingly enrich neural network activity in the hippocampus to link together these places into a cognitive map.&lt;/p&gt;&lt;p&gt;“On Day 1, the brain doesn’t represent the space very well,” says lead author Wei Guo, a research scientist in the lab of senior author &lt;a href="https://picower.mit.edu/node/49"&gt;Matthew Wilson&lt;/a&gt;, the Sherman Fairchild Professor in The Picower Institute and MIT’s departments of Biology and Brain and Cognitive Sciences. “Neurons represent individual locations, but together they don’t form a map. But on Day 5 they form a map. If you want a map, you need all these neurons to work together in a coordinated ensemble.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mice mapping mazes&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To conduct the study, Guo and Wilson, along with labmates Jie “Jack” Zhang and Jonathan Newman, introduced mice to simple mazes of varying shapes and let them explore them freely for about 30 minutes a day for several days. Importantly, the mice were not directed to learn anything specific through the offer of any rewards. They just wandered. Previous studies have shown that mice naturally demonstrate “latent learning” of spaces from this kind of unrewarded experience after several days.&lt;/p&gt;&lt;p&gt;To understand how latent learning takes hold, Guo and his colleagues visually monitored hundreds of neurons in the CA1 area of the hippocampus by engineering cells to flash when a buildup of calcium ions made them electrically active. They not only recorded the neurons’ flashes when the mice were actively exploring, but also while they were sleeping. Wilson’s lab has shown that animals “&lt;a href="https://picower.mit.edu/discoveries/importance-memory-replay-and-sleep"&gt;replay&lt;/a&gt;” their previous journeys during sleep, essentially refining their memories by dreaming about their experiences.&lt;/p&gt;&lt;p&gt;Analysis of the recordings showed that the activity of the place cells developed immediately and remained strong and unchanged over several days of exploration.&amp;nbsp;But this activity alone wouldn’t explain how latent learning or a cognitive map evolves over several days. So unlike in many other studies where scientists focus solely on the strong and clear activity of place cells, Guo extended his analysis to the more subtle and mysterious activity of cells that were not so strongly spatially tuned.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Using an emerging technique called “manifold learning” he was able to discern that many of the “weakly spatial” cells gradually correlated their activity not with locations, but with activity patterns among other neurons in the network. As this was happening, Guo’s analyses showed, the network encoded a cognitive map of the maze that increasingly resembled the literal, physical space.&lt;/p&gt;&lt;p&gt;“Although not responding to specific locations like strongly spatial cells, weakly spatial cells specialize in responding to ‘‘mental locations,’’ i.e., specific ensemble firing patterns of other cells,” the study authors wrote. “If a weakly spatial cell’s mental field encompasses two subsets of strongly spatial cells that encode distinct locations, this weakly spatial cell can serve as a bridge between these locations.”&lt;/p&gt;&lt;p&gt;In other words, the activity of the weakly spatial cells likely stitches together the individual locations represented by the place cells into a mental map.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The need for sleep&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Studies by Wilson’s lab and many others have shown that memories are consolidated, refined, and processed by neural activity, such as replay, that occurs during sleep and rest. Guo and Wilson’s team therefore sought to test whether sleep was necessary for the contribution of weakly spatial cells to latent learning of cognitive maps.&lt;/p&gt;&lt;p&gt;To do this they let some mice explore a new maze twice during the same day with a three-hour siesta in between. Some of the mice were allowed to sleep but some were not. The ones that did showed a significant refinement of their mental map, but the ones that weren’t allowed to sleep showed no such improvement. Not only did the network encoding of the map improve, but also measures of the tuning of individual cells during showed that sleep helped cells become better attuned both to places and to patterns of network activity, so-called “mental places” or “fields.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mental map meaning&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The “cognitive maps” the mice encoded over several days were not literal, precise maps of the mazes, Guo notes. Instead they were more like schematics. Their value is that they provide the brain with a topology that can be explored mentally, without having to be in the physical space. For instance, once you’ve formed your cognitive map of the neighborhood around your hotel, you can plan the next morning’s excursion (e.g., you could imagine grabbing a croissant at the bakery you observed a few blocks west and then picture eating it on one of those benches you noticed in the park along the river).&lt;/p&gt;&lt;p&gt;Indeed, Wilson hypothesized that the weakly spatial cells’ activity may be overlaying salient non-spatial information that brings additional meaning to the maps (i.e., the idea of a bakery is not spatial, even if it’s closely linked to a specific location). The study, however, included no landmarks within the mazes and did not test any specific behaviors among the mice. But now that the study has identified that weakly spatial cells contribute meaningfully to mapping, Wilson said future studies can investigate what kind of information they may be incorporating into the animals’ sense of their environments. We seem to intuitively regard the spaces we inhabit as more than just sets of discrete locations.&lt;/p&gt;&lt;p&gt;“In this study we focused on animals behaving naturally and demonstrated that during freely exploratory behavior and subsequent sleep, in the absence of reinforcement, substantial neural plastic changes at the ensemble level still occur,” the authors concluded. “This form of implicit and unsupervised learning constitutes a crucial facet of human learning and intelligence, warranting further in-depth investigations.”&lt;/p&gt;&lt;p&gt;The Freedom Together Foundation, The Picower Institute, and the National Institutes of Health funded the study.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202412/latent-learning-map.jpg?itok=Xm21czIN" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Researchers sought to discern how a cognitive map of a sideways T-shaped maze coalesced in the minds of mice. An edited panel from a figure in the study shows how neural representations of the cognitive map evolved over five sessions. Each dot is a point in time and each color corresponds to a location in the actual maze (see smaller T's). Over time, the cognitive map better resembles the actual maze geometry.]]></media:description>
              <media:credit>Image: Wei Guo/Wilson Lab</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/memory">Memory</category>
      <category domain="https://news.mit.edu/topic/learning">Learning</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Teaching AI to communicate sounds like humans do</title>
  <link>https://news.mit.edu/2025/teaching-ai-communicate-sounds-humans-do-0109</link>
  <description><![CDATA[Inspired by the human vocal tract, a new AI model can produce and understand vocal imitations of everyday sounds. The method could help build new sonic interfaces for entertainment and education.]]></description>
  <pubDate>Thu, 09 Jan 2025 00:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/teaching-ai-communicate-sounds-humans-do-0109</guid>
        <dc:creator>Alex Shipps | MIT CSAIL</dc:creator>
  <content:encoded>&lt;p&gt;Whether you’re describing the sound of your faulty car engine or meowing like your neighbor’s cat, imitating sounds with your voice can be a helpful way to relay a concept when words don’t do the trick.&lt;/p&gt;&lt;p&gt;Vocal imitation is the sonic equivalent of doodling a quick picture to communicate something you saw — except that instead of using a pencil to illustrate an image, you use your vocal tract to express a sound. This might seem difficult, but it’s something we all do intuitively: To experience it for yourself, try using your voice to mirror the sound of an ambulance siren, a crow, or a bell being struck.&lt;/p&gt;&lt;p&gt;Inspired by the cognitive science of how we communicate, MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) researchers have developed an AI system that can produce human-like vocal imitations with no training, and without ever having "heard" a human vocal impression before.&lt;/p&gt;&lt;p&gt;To achieve this, the researchers engineered their system to produce and interpret sounds much like we do. They started by building a model of the human vocal tract that simulates how vibrations from the voice box are shaped by the throat, tongue, and lips. Then, they used a cognitively-inspired AI algorithm to control this vocal tract model and make it produce imitations, taking into consideration the context-specific ways that humans choose to communicate sound.&lt;/p&gt;&lt;p&gt;The model can effectively take many sounds from the world and generate a human-like imitation of them — including noises like leaves rustling, a snake’s hiss, and an approaching ambulance siren. Their model can also be run in reverse to guess real-world sounds from human vocal imitations, similar to how some computer vision systems can retrieve high-quality images based on sketches. For instance, the model can correctly distinguish the sound of a human imitating a cat’s “meow” versus its “hiss.”&lt;/p&gt;&lt;p&gt;In the future, this model could potentially lead to more intuitive “imitation-based” interfaces for sound designers, more human-like AI characters in virtual reality, and even methods to help students learn new languages.&lt;/p&gt;&lt;p&gt;The co-lead authors — MIT CSAIL PhD students Kartik Chandra SM ’23 and Karima Ma, and undergraduate researcher Matthew Caren — note that computer graphics researchers have long recognized that realism is rarely the ultimate goal of visual expression. For example, an abstract painting or a child’s crayon doodle can be just as expressive as a photograph.&lt;/p&gt;&lt;p&gt;“Over the past few decades, advances in sketching algorithms have led to new tools for artists, advances in AI and computer vision, and even a deeper understanding of human cognition,” notes Chandra. “In the same way that a sketch is an abstract, non-photorealistic representation of an image, our method captures the abstract, non-phono&lt;em&gt;-&lt;/em&gt;realistic ways humans express the sounds they hear. This teaches us about the process of auditory abstraction.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The art of imitation, in three parts&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The team developed three increasingly nuanced versions of the model to compare to human vocal imitations. First, they created a baseline model that simply aimed to generate imitations that were as similar to real-world sounds as possible — but this model didn’t match human behavior very well.&lt;/p&gt;&lt;p&gt;The researchers then designed a second “communicative” model. According to Caren, this model considers what’s distinctive about a sound to a listener. For instance, you’d likely imitate the sound of a motorboat by mimicking the rumble of its engine, since that’s its most distinctive auditory feature, even if it’s not the loudest aspect of the sound (compared to, say, the water splashing). This second model created imitations that were better than the baseline, but the team wanted to improve it even more.&lt;br&gt;&lt;br&gt;To take their method a step further, the researchers added a final layer of reasoning to the model. “Vocal imitations can sound different based on the amount of effort you put into them. It costs time and energy to produce sounds that are perfectly accurate,” says Chandra. The researchers’ full model accounts for this by trying to avoid utterances that are very rapid, loud, or high- or low-pitched, which people are less likely to use in a conversation. The result: more human-like imitations that closely match many of the decisions that humans make when imitating the same sounds.&lt;/p&gt;&lt;p&gt;After building this model, the team conducted a behavioral experiment to see whether the AI- or human-generated vocal imitations were perceived as better by human judges. Notably, participants in the experiment favored the AI model 25 percent of the time in general, and as much as 75 percent for an imitation of a motorboat and 50 percent for an imitation of a gunshot.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Toward more expressive sound technology&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Passionate about technology for music and art, Caren envisions that this model could help artists better communicate sounds to computational systems and assist filmmakers and other content creators with generating AI sounds that are more nuanced to a specific context. It could also enable a musician to rapidly search a sound database by imitating a noise that is difficult to describe in, say, a text prompt.&lt;/p&gt;&lt;p&gt;In the meantime, Caren, Chandra, and Ma are looking at the implications of their model in other domains, including the development of language, how infants learn to talk, and even imitation behaviors in birds like parrots and songbirds.&lt;/p&gt;&lt;p&gt;The team still has work to do with the current iteration of their model: It struggles with some consonants, like “z,” which led to inaccurate impressions of some sounds, like bees buzzing. They also can’t yet replicate how humans imitate speech, music, or sounds that are imitated differently across different languages, like a heartbeat.&lt;/p&gt;&lt;p&gt;Stanford University linguistics professor Robert Hawkins says that language is full of onomatopoeia and words that mimic but don’t fully replicate the things they describe, like the “meow” sound that very inexactly approximates the sound that cats make. “The processes that get us from the sound of a real cat to a word like ‘meow’ reveal a lot about the intricate interplay between physiology, social reasoning, and communication in the evolution of language,” says Hawkins, who wasn’t involved in the CSAIL research. “This model presents an exciting step toward formalizing and testing theories of those processes, demonstrating that both physical constraints from the human vocal tract and social pressures from communication are needed to explain the distribution of vocal imitations.”&lt;/p&gt;&lt;p&gt;Caren, Chandra, and Ma wrote the paper with two other CSAIL affiliates: Jonathan Ragan-Kelley, MIT Department of Electrical Engineering and Computer Science associate professor, and Joshua Tenenbaum, MIT Brain and Cognitive Sciences professor and Center for Brains, Minds, and Machines member. Their work was supported, in part, by the Hertz Foundation and the National Science Foundation. It was presented at SIGGRAPH Asia in early December.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202412/csail-sketching.jpg?itok=vEC5X6UN" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[A new model can take many sounds from the world and generate a human-like imitation of them, like a snake’s hiss and an approaching ambulance siren. The system can also be run in reverse to guess real-world sounds from human vocal imitations.]]></media:description>
              <media:credit>Image: Alex Shipps/MIT CSAIL, with visual elements from Pixabay</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">MIT Schwarzman College of Computing</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">Electrical engineering and computer science (EECS)</category>
      <category domain="https://news.mit.edu/topic/center-brains-minds-and-machines">Center for Brains Minds and Machines</category>
      <category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">Computer Science and Artificial Intelligence Laboratory (CSAIL)</category>
      <category domain="https://news.mit.edu/topic/computers">Computer science and technology</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/machine-learning">Machine learning</category>
      <category domain="https://news.mit.edu/topic/algorithms">Algorithms</category>
      <category domain="https://news.mit.edu/topic/human-computer-interaction">Human-computer interaction</category>
      <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/music2">Music</category>
    </item>
<item>
  <title>Personal interests can influence how children’s brains respond to language</title>
  <link>https://news.mit.edu/2025/personal-interests-can-influence-how-childrens-brains-respond-language-0107</link>
  <description><![CDATA[McGovern Institute neuroscientists use children’s interests to probe language in the brain.]]></description>
  <pubDate>Tue, 07 Jan 2025 16:15:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/personal-interests-can-influence-how-childrens-brains-respond-language-0107</guid>
        <dc:creator>Rubina Veerakone | McGovern Institute for Brain Research</dc:creator>
  <content:encoded>&lt;p&gt;A recent study from the McGovern Institute for Brain Research shows how interests can modulate language processing in children’s brains and paves the way for personalized brain research.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://direct.mit.edu/imag/article/doi/10.1162/imag_a_00339/124868/Personalized-neuroimaging-reveals-the-impact-of?searchresult=1" target="_blank"&gt;paper&lt;/a&gt;, which appears in &lt;em&gt;Imaging Neuroscience&lt;/em&gt;, was conducted in the lab of MIT professor and McGovern Institute investigator &lt;a href="https://mcgovern.mit.edu/profile/john-gabrieli/"&gt;John Gabrieli&lt;/a&gt;, and led by senior author Anila D’Mello, a recent McGovern postdoc who is now an assistant professor at the University of Texas Southwestern Medical Center and the University of Texas at Dallas.&lt;/p&gt;&lt;p&gt;“Traditional studies give subjects identical stimuli to avoid confounding the results,” says Gabrieli, who is the Grover Hermann Professor of Health Sciences and Technology and a professor of brain and cognitive sciences at MIT. “However, our research tailored stimuli to each child’s interest, eliciting stronger — and more consistent — activity patterns in the brain’s language regions across individuals.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Funded by the Hock E. Tan and K. Lisa Yang Center for Autism Research in MIT’s Yang Tan Collective, this work unveils a new paradigm that challenges current methods and shows how personalization can be a powerful strategy in neuroscience. The paper’s co-first authors are Halie Olson, a postdoc at the McGovern Institute, and Kristina Johnson PhD '21, an assistant professor at Northeastern University and former doctoral student at the MIT Media Lab. “Our research integrates participants’ lived experiences into the study design,” says Johnson. “This approach not only enhances the validity of our findings, but also captures the diversity of individual perspectives, often overlooked in traditional research.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Taking interest into account&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When it comes to language, our interests are like operators behind the switchboard. They guide what we talk about and who we talk to. Research suggests that interests are also potent motivators and can help improve language skills. For instance, children score higher on reading tests when the material covers topics that are interesting to them.&lt;/p&gt;&lt;p&gt;But neuroscience has shied away from using personal interests to study the brain, especially in the realm of language. This is mainly because interests, which vary between people, could throw a wrench into experimental control — a core principle that drives scientists to limit factors that can muddle the results.&lt;/p&gt;&lt;p&gt;Gabrieli, D’Mello, Olson, and Johnson ventured into this unexplored territory. The team wondered if tailoring language stimuli to children’s interests might lead to higher responses in language regions of the brain. “Our study is unique in its approach to control the kind of brain activity our experiments yield, rather than control the stimuli we give subjects,” says D’Mello. “This stands in stark contrast to most neuroimaging studies that control the stimuli but might introduce differences in each subject’s level of interest in the material.”&lt;/p&gt;&lt;p&gt;In their recent study, the authors recruited a cohort of 20 children to investigate how personal interests affected the way the brain processes language. Caregivers described their child’s interests to the researchers, spanning baseball, train lines, “Minecraft,” and musicals. During the study, children listened to audio stories tuned to their unique interests. They were also presented with audio stories about nature (this was not an interest among the children) for comparison. To capture brain activity patterns, the team used functional magnetic resonance imaging (fMRI), which measures changes in blood flow caused by underlying neural activity.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;New insights into the brain&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“We found that, when children listened to stories about topics they were really interested in, they showed stronger neural responses in language areas than when they listened to generic stories that weren’t tailored to their interests,” says Olson. “Not only does this tell us how interests affect the brain, but it also shows that personalizing our experimental stimuli can have a profound&amp;nbsp;impact on neuroimaging results.”&lt;/p&gt;&lt;p&gt;The researchers noticed a particularly striking result. “Even though the children listened to completely different stories, their brain activation patterns were&amp;nbsp;more&lt;em&gt;&amp;nbsp;&lt;/em&gt;overlapping with their peers when they listened to idiosyncratic stories compared to when they listened to the same generic stories about nature,” says D’Mello. This, she notes, points to how interests can boost both the magnitude and consistency of signals in language regions across subjects without changing how these areas communicate with each other.&lt;/p&gt;&lt;p&gt;Gabrieli noted another finding: “In addition to the stronger engagement of language regions for content of interest, there was also stronger activation in brain regions associated with reward and also with self-reflection.” Personal interests are individually relevant and can be rewarding, potentially driving higher activation in these regions during personalized stories.&lt;/p&gt;&lt;p&gt;These personalized paradigms might be particularly well-suited to studies of the brain in unique or neurodivergent populations. Indeed, the team is already applying these methods to study language in the brains of autistic children.&lt;/p&gt;&lt;p&gt;This study breaks new ground in neuroscience and serves as a prototype for future work that personalizes research to unearth further knowledge of the brain. In doing so, scientists can compile a more complete understanding of the type of information that is processed by specific brain circuits and more fully grasp complex functions such as language.&amp;nbsp;&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202412/mit-researchers-olson-johnson-dmello.jpg?itok=K2EeK5Zb" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Researchers Halie Olson (left), Kristina Johnson (center), and Anila D’Mello ]]></media:description>
              <media:credit>Photo: Caitlin Cunningham</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/language">Language</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/health">Health sciences and technology</category>
      <category domain="https://news.mit.edu/topic/autism">Autism</category>
      <category domain="https://news.mit.edu/topic/media-lab-0">Media Lab</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>MIT affiliates awarded 2024 National Medals of Science, Technology</title>
  <link>https://news.mit.edu/2025/mit-affiliates-awarded-national-medals-science-technology-0103</link>
  <description><![CDATA[Four professors and an additional alumnus honored with nation’s highest awards for scientists and engineers; Moderna, with deep MIT roots, also recognized.]]></description>
  <pubDate>Fri, 03 Jan 2025 22:20:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2025/mit-affiliates-awarded-national-medals-science-technology-0103</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;Four MIT faculty members are among 23 world-class researchers who have been awarded the nation’s highest honors for scientists and innovators, the White House &lt;a href="https://www.whitehouse.gov/briefing-room/statements-releases/2025/01/03/president-biden-honors-nations-leading-scientists-technologists-and-innovators/" target="_blank"&gt;announced today&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Angela Belcher and Emery Brown were each presented with the National Medal of Science at a ceremony this afternoon, and Paula Hammond ’84, PhD ’93, and Feng Zhang were awarded the National Medal of Technology and Innovation.&lt;/p&gt;&lt;p&gt;Belcher, the James Mason Crafts Professor of Biological Engineering and Materials Science and Engineering and a member of the Koch Institute for Integrative Cancer Research, was honored for her work designing novel&amp;nbsp;materials for applications that include solar cells, batteries, and medical imaging.&lt;/p&gt;&lt;p&gt;Brown, the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience, was recognized for work that has revealed how anesthesia affects the brain. Brown is also a member of MIT’s Picower Institute for Learning and Memory and Institute for Medical Engineering and Science (IMES).&lt;/p&gt;&lt;p&gt;Hammond, an MIT Institute Professor, vice provost for faculty, and member of the Koch Institute, was honored for developing methods for assembling thin films that can be used for drug delivery, wound healing, and many other applications.&lt;/p&gt;&lt;p&gt;Zhang, the James and Patricia Poitras Professor of Neuroscience at MIT and a professor of brain and cognitive sciences and biological engineering, was recognized for his work developing molecular tools, including the CRISPR genome-editing system, that have the potential to diagnose and treat disease. Zhang is also an investigator at the McGovern Institute for Brain Research and a core member of the Broad Institute of MIT and Harvard.&lt;/p&gt;&lt;p&gt;Two additional MIT alumni also accepted awards:&amp;nbsp;R. Lawrence “Larry” Edwards ’76, a graduate of the Department of Earth, Atmospheric and Planetary Sciences and of the Department of Architecture, who is now a professor at the University of Minnesota, received a National Medal of Science for his work in geochemistry. And Noubar Afeyan PhD ’87, a graduate of the Department of Chemical Engineering and current member of the MIT Corporation, accepted one of two National Medals of Technology and Innovation awarded to an organization. These awards went to the biotechnology companies Moderna, which Afeyan co-founded along with Institute Professor Robert Langer, and Pfizer, for their development of vaccines for Covid-19.&lt;/p&gt;&lt;p&gt;This year, the White House awarded the National Medal of Science to 14 recipients and named nine individual awardees of the National Medal of Technology and Innovation, along with two organizations. To date, nearly 100 MIT affiliates have won one of these two honors.&lt;/p&gt;&lt;p&gt;“Emery Brown is at the forefront of the Institute’s collaborations among neuroscience, medicine, and patient care. His research has shifted the paradigm for brain monitoring during general anesthesia for surgery. His pioneering approach based on neural oscillations, as opposed to solely monitoring vital signs, promises to revolutionize how anesthesia medications are delivered to patients,” says Nergis Mavalvala, dean of MIT’s School of Science. “Feng Zhang is one of the preeminent researchers in CRISPR technologies that have accelerated the pace of science and engineering, blending entrepreneurship and scientific discovery. These new molecular technologies can modify the cell’s genetic information, engineer vehicles to deliver these tools into the correct cells, and scale to restore organ function. Zhang will apply these life-altering innovations to diseases such as neurodegeneration, immune disorders, and aging.”&lt;/p&gt;&lt;p&gt;Hammond and Belcher are frequent collaborators, and each of them has had significant impact on the fields of nanotechnology and nanomedicine.&lt;/p&gt;&lt;p&gt;“Angela Belcher and Paula Hammond have made tremendous contributions to science and engineering, and I’m thrilled for each of them to receive this well-deserved recognition,” says Anantha Chandrakasan, dean of the School of Engineering and chief innovation and strategy officer at MIT. “By harnessing the processes of nature, Angela’s innovations have impacted fields from energy to the environment to medicine. Her non-invasive imaging system has improved outcomes for patients diagnosed with many types of cancer. Paula’s pioneering research in nanotechnology helped transform the ways in which we deliver and administer drugs within the body — through her technique, therapeutics can be customized and sent directly to specifically targeted cells, including cancer cells.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Growing materials with viruses&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Belcher, who joined the MIT faculty in 2002 and served as head of the Department of Biological Engineering from 2019 to 2023, initially heard that she was being considered for the National Medal of Science in September, and in mid-December, found out she had won.&lt;/p&gt;&lt;p&gt;“It was quite shocking and just a huge honor. It’s an honor to be considered, and then to get the email and the call that I actually was receiving it was humbling,” she says.&lt;/p&gt;&lt;p&gt;Belcher, who earned a bachelor’s degree in creative studies and a PhD in inorganic chemistry from the University of California at Santa Barbara, has focused much of her research on developing ways to use biological systems, such as viruses, to grow materials.&lt;/p&gt;&lt;p&gt;“Since graduate school, I’ve been fascinated with trying to understand how nature makes materials and then applying those processes, whether directly through biological molecules, or through evolving biological molecules or biological organisms, to make materials that are of technological importance,” she says.&lt;/p&gt;&lt;p&gt;Early in her career, she developed a technique for generating materials by engineering viruses to self-assemble into nanoscale scaffolds that can be coated with inorganic materials to form functional devices such as&amp;nbsp;&lt;a href="https://news.mit.edu/2013/better-batteries-through-biology-1113"&gt;batteries&lt;/a&gt;, semiconductors,&amp;nbsp;&lt;a href="https://news.mit.edu/2011/solar-virus-0425"&gt;solar cells&lt;/a&gt;, and catalysts. This approach allows for exquisite control over the electronic, optical, and magnetic properties of the material.&lt;/p&gt;&lt;p&gt;In the late 2000s, then-MIT president Susan Hockfield asked Belcher to join the newly formed Koch Institute, whose mission is to bring together scientists and engineers to seek new ways to diagnose and treat cancer. Not knowing much about cancer biology, Belcher was hesitant at first, but she ended up moving her lab to the Koch Institute and applying her work to the new challenge.&lt;/p&gt;&lt;p&gt;One of her first projects, on which she collaborated with Hammond, was a method for using shortwave infrared light to image cancer cells. This technology, eventually commercialized by a company called Cision Vision, is now being used in hospitals to image lymph nodes during cancer surgery, helping them to determine if a tumor has spread.&lt;/p&gt;&lt;p&gt;Belcher is now focused on finding technologies to detect other cancers, especially ovarian cancer, which is difficult to diagnose in early stages, as well as developing cancer vaccines.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Unlocking the mysteries of anesthesia&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Brown, who has been on the MIT faculty since 2005, said he was “overjoyed” when he found out he would receive the National Medal of Science.&lt;/p&gt;&lt;p&gt;“I’m extremely excited and quite honored to receive such an award, because it is one of the pinnacles of recognition in the scientific field in the United States,” he says.&lt;/p&gt;&lt;p&gt;Much of Brown’s work has focused on achieving a better understanding of what happens in the human brain under anesthesia. Trained as an anesthesiologist, Brown earned his MD from Harvard Medical School and a PhD in statistics from Harvard University.&lt;/p&gt;&lt;p&gt;Since 1992, he has been a member of the Harvard Medical School faculty and a practicing anesthesiologist at Massachusetts General Hospital. Early in his research career, he worked on developing methods to characterize the properties of the human circadian clock. These included characterizing the clock’s phase response curve to light, accurately measuring its intrinsic period, and measuring the impact of physiologically designed schedules on shift worker performance. Later, he became interested in developing signal processing methods to characterize how neurons represent signals and stimuli in their ensemble activity.&lt;/p&gt;&lt;p&gt;In collaboration with Matt Wilson, an MIT professor of neuroscience, Brown devised algorithms to decode the position of an animal in its environment by reading the activity of a small group of place cell neurons in the animal’s brain. Other applications of these methods included characterizing learning, controlling brain-machine interfaces, and controlling brain states such as medically induced coma.&lt;/p&gt;&lt;p&gt;“I was practicing anesthesia at the time, and as I saw more and more of what the neuroscientists were doing, it occurred to me we could use their paradigms to study anesthesia, and we should, because we weren’t doing that,” he says. “Anesthesia was not being looked at as a neuroscience subdiscipline. It was looked at as a subdiscipline of pharmacology.”&lt;/p&gt;&lt;p&gt;Over the past two decades, Brown’s work has revealed how anesthesia drugs induce unconsciousness in the brain, along with other altered arousal states. Anesthesia drugs such as propofol dramatically&amp;nbsp;&lt;a href="https://news.mit.edu/2023/study-finds-tracking-brain-waves-could-reduce-post-complications-0717"&gt;alter the brain’s intrinsic oscillations.&lt;/a&gt; These oscillations can be seen with electroencephalography (EEG).&amp;nbsp;During the awake state, these oscillations usually have high frequency and low amplitude, but as anesthetic drugs are given, they shift generally to low frequency, high amplitude. Working with MIT professors Earl Miller and Ila Fiete, as well as collaborators at Massachusetts General Hospital and Boston University, Brown has shown that these changes&amp;nbsp;&lt;a href="https://news.mit.edu/2024/study-reveals-how-anesthesia-drug-induces-unconsciousnes-0715"&gt;disrupt normal communication&lt;/a&gt; between different brain regions, leading to loss of consciousness.&lt;/p&gt;&lt;p&gt;Brown has also shown that these EEG oscillations can be used to monitor whether a patient is too deeply unconscious, and he has developed a closed-loop anesthesia delivery system that can maintain a patient’s anesthesia state at precisely desired levels. Brown and colleagues have also developed methods to accelerate recovery from anesthesia. More precise control and accelerated recovery could help to prevent the cognitive impairments that often affect patients after they emerge from anesthesia. Accelerating recovery from anesthesia has also suggested ways to accelerate recovery from coma.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building multifunctional materials&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Hammond, who earned both her bachelor’s degree and PhD in chemical engineering from MIT, has been a member of the faculty since 1995 and was named an Institute Professor in 2021. She was also the 2023-24 recipient of MIT’s Killian Award, the highest honor that the faculty bestows.&lt;/p&gt;&lt;p&gt;Early in her career, Hammond developed a novel technique for generating functional thin-film materials by stacking layers of charged polymeric materials. This approach can be used to build polymers with highly controlled architectures by alternately exposing a surface to positively and negatively charged particles.&lt;/p&gt;&lt;p&gt;She initially used this layer-by-layer assembly technique to build ultrathin batteries and fuel cell electrodes, before turning her attention to biomedical applications. To adapt the films for drug delivery, she came up with ways to incorporate drug molecules into the layers of the film. These molecules are then released when the particles reach their targets.&lt;/p&gt;&lt;p&gt;“We began to look at bioactive materials and how we could sandwich them into these layers and use that as a way to deliver the drug in a very controlled fashion, at the right time and in the right place,” she says. “We are using the layering as a way to modify the surface of a nanoparticle so that there is a very high and selective affinity for the cancer cells we’re targeting.”&lt;/p&gt;&lt;p&gt;Using this technique, she has created&amp;nbsp;&lt;a href="https://news.mit.edu/2022/how-different-cancer-cells-respond-drug-delivering-nanoparticles-0721"&gt;drug-delivery nanoparticles&lt;/a&gt; that are coated with molecules that specifically target cancer cells, with a particular focus on ovarian cancer. These particles can be tailored to carry chemotherapy drugs such as cisplatin, immunotherapy agents, or nucleic acids such as messenger RNA.&lt;/p&gt;&lt;p&gt;Working with colleagues around MIT, she has also developed materials that can be used to promote wound healing,&amp;nbsp;&lt;a href="https://news.mit.edu/2023/two-component-system-halt-internal-bleeding-0425"&gt;blood clotting&lt;/a&gt;, and tissue regeneration.&lt;/p&gt;&lt;p&gt;“What we have found is that these layers are very versatile. They can coat a very broad range of substrates, and those substrates can be anything from a bone implant, which can be quite large, down to a nanoparticle, which is 100 nanometers,” she says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Designing molecular tools&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Zhang, who earned his undergraduate degree from Harvard University in 2004, has contributed to the development of multiple molecular tools to accelerate the understanding of human disease. While a graduate student at Stanford University, from which he received his PhD in 2009, Zhang worked in the lab of Professor Karl Deisseroth. There, he worked on a protein called channelrhodopsin, which he and Deisseroth believed held potential for engineering mammalian cells to respond to light.&lt;/p&gt;&lt;p&gt;The resulting technique, known as optogenetics, is now used widely used in neuroscience and other fields. By engineering neurons to express light-sensitive proteins such as channelrhodopsin, researchers can either stimulate or silence the cells’ electrical impulses by shining different wavelengths of light on them. This has allowed for detailed study of the roles of specific populations of neurons in the brain, and the mapping of neural circuits that control a variety of behaviors.&lt;/p&gt;&lt;p&gt;In 2011, about a month after joining the MIT faculty, Zhang attended a talk by Harvard Medical School Professor Michael Gilmore, who studies the pathogenic bacterium &lt;em&gt;Enteroccocus&lt;/em&gt;. The scientist mentioned that these bacteria protect themselves from viruses with DNA-cutting enzymes known as nucleases, which are part of a defense system known as CRISPR.&lt;/p&gt;&lt;p&gt;“I had no idea what CRISPR was, but I was interested in nucleases,” Zhang told &lt;em&gt;MIT News&lt;/em&gt; in 2016. “I went to look up CRISPR, and that’s when I realized you might be able to engineer it for use for genome editing.”&lt;/p&gt;&lt;p&gt;In January 2013, Zhang and members of his lab reported that they had successfully used CRISPR to &lt;a href="https://news.mit.edu/2013/editing-the-genome-with-high-precision-0103"&gt;edit genes&lt;/a&gt; in mammalian cells. The CRISPR system includes a nuclease called Cas9, which can be directed to cut a specific genetic target by RNA molecules known as guide strands.&lt;/p&gt;&lt;p&gt;Since then, scientists in fields from medicine to plant biology have used CRISPR to study gene function and investigate the possibility of correcting faulty genes that cause disease. More recently, Zhang’s lab has devised many enhancements to the original CRISPR system, such as making the targeting more precise and preventing unintended cuts in the wrong locations.&lt;/p&gt;&lt;p&gt;The National Medal of Science was established in 1959 and is administered for the White House by the National Science Foundation. The medal recognizes individuals who have made outstanding contributions to science and engineering.&lt;/p&gt;&lt;p&gt;The National Medal of Technology and Innovation was established in 1980 and is administered for the White House by the U.S. Department of Commerce’s Patent and Trademark Office. The award recognizes those who have made lasting contributions to America’s competitiveness and quality of life and helped strengthen the nation’s technological workforce.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202501/MIT-National-02-press_1.jpg?itok=c7x0NPQC" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[MIT represent: Arati Prabhakar (left), head of the White House Office of Science and Technology Policy, presented National Medals to (left to right) Professor Angela Belcher, Institute Professor Paula Hammond, MIT Corporation member Noubar Afeyan PhD '87 on behalf of Moderna, Professor Feng Zhang, and Professor Emery Brown. Not pictured: Richard Lawrence Edwards ’76. ]]></media:description>
              <media:credit>Photo courtesy of Angie Belcher.</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/faculty">Faculty</category>
      <category domain="https://news.mit.edu/topic/alumni">Alumni/ae</category>
      <category domain="https://news.mit.edu/topic/startups">Startups</category>
      <category domain="https://news.mit.edu/topic/chemical-engineering">Chemical engineering</category>
      <category domain="https://news.mit.edu/topic/biological-engineering">Biological engineering</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/materialsscienceandengineering">Materials science and engineering</category>
      <category domain="https://news.mit.edu/topic/covid-19">Covid-19</category>
      <category domain="https://news.mit.edu/topic/anesthesia">Anesthesia</category>
      <category domain="https://news.mit.edu/topic/cancer-research">Cancer</category>
      <category domain="https://news.mit.edu/topic/crispr">CRISPR</category>
      <category domain="https://news.mit.edu/topic/eaps">EAPS</category>
      <category domain="https://news.mit.edu/topic/architecture">Architecture</category>
      <category domain="https://news.mit.edu/topic/innovation">Innovation and Entrepreneurship (I&amp;E)</category>
      <category domain="https://news.mit.edu/topic/nanotech">Nanoscience and nanotechnology</category>
      <category domain="https://news.mit.edu/topic/koch-institute-0">Koch Institute</category>
      <category domain="https://news.mit.edu/topic/broad-institute">Broad Institute</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/harvard-mit-health-sciences-and-technology">Harvard-MIT Health Sciences and Technology</category>
      <category domain="https://news.mit.edu/topic/institute-medical-engineering-and-science-imes-0">Institute for Medical Engineering and Science (IMES)</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-architecture-and-planning">School of Architecture and Planning</category>
      <category domain="https://news.mit.edu/topic/president-biden">President Biden</category>
    </item>
<item>
  <title>MIT welcomes Frida Polli as its next visiting innovation scholar</title>
  <link>https://news.mit.edu/2024/mit-welcomes-frida-polli-visiting-innovation-scholar-1219</link>
  <description><![CDATA[The neuroscientist turned entrepreneur will be hosted by the MIT Schwarzman College of Computing and focus on advancing the intersection of behavioral science and AI across MIT.]]></description>
  <pubDate>Thu, 19 Dec 2024 15:40:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/mit-welcomes-frida-polli-visiting-innovation-scholar-1219</guid>
        <dc:creator>Terri Park | MIT Schwarzman College of Computing</dc:creator>
  <content:encoded>&lt;p&gt;Frida Polli, a neuroscientist, entrepreneur, investor, and inventor known for her leading-edge contributions at the crossroads of behavioral science and artificial intelligence, is MIT’s new visiting innovation scholar for the 2024-25 academic year. She is the first visiting innovation scholar to be housed within the MIT Schwarzman College of Computing.&lt;/p&gt;&lt;p&gt;Polli began her career in academic neuroscience with a focus on multimodal brain imaging related to health and disease. She was a fellow at the Psychiatric Neuroimaging Group at Mass General Brigham and Harvard Medical School. She then joined the Department of Brain and Cognitive Sciences at MIT as a postdoc, where she worked with John Gabrieli, the Grover Hermann Professor of Health Sciences and Technology and a professor of brain and cognitive sciences.&lt;/p&gt;&lt;p&gt;Her research has won many awards, including a Young Investigator Award from the Brain and Behavior Research Foundation. She authored over 30 peer-reviewed articles, with notable publications in the &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;, the &lt;em&gt;Journal of Neuroscience&lt;/em&gt;, and &lt;em&gt;Brain&lt;/em&gt;. She transitioned from academia to entrepreneurship by completing her MBA at the Harvard Business School (HBS) as a Robert Kaplan Life Science Fellow. During this time, she also won the Life Sciences Track and the Audience Choice Award in the 2010 MIT $100K Entrepreneurship competition as a member of Aukera Therapeutics.&lt;/p&gt;&lt;p&gt;After HBS, Polli launched pymetrics, which harnessed advancements in cognitive science and machine learning to develop analytics-driven decision-making and performance enhancement software for the human capital sector. She holds multiple patents for the technology developed at pymetrics, which she co-founded in 2012 and led as CEO until her successful exit in 2022.&amp;nbsp;Pymetrics was a World Economic Forum’s Technology Pioneer and Global Innovator, an Inc. 5000’s Fastest-Growing company, and Forbes Artificial Intelligence 50 company.&amp;nbsp;Polli and pymetrics also played a pivotal role in passing the first-in-the-nation algorithmic bias law — New York’s Automated Employment Decision Tool law — which went into effect in July 2023.&lt;/p&gt;&lt;p&gt;Making her return to MIT as a visiting innovation scholar, Polli is collaborating closely with Sendhil Mullainathan, the Peter de Florez Professor in the departments of Electrical Engineering and Computer Science and Economics, and a principal investigator in the Laboratory for Information and Decision Systems. With Mullainathan, she is working to bring together a broad array of faculty, students, and postdocs across MIT to address concrete problems where &lt;a href="https://tot.mit.edu/" target="_blank"&gt;humans and algorithms intersect&lt;/a&gt;, to develop a new subdomain of computer science specific to behavioral science, and to train the next generation of scientists to be bilingual in these two fields.&lt;/p&gt;&lt;p&gt;“Sometimes you get lucky, and sometimes you get unreasonably lucky. Frida has thrived in each of the facets we’re looking to have impact in — academia, civil society, and the marketplace. She combines a startup mentality with an abiding interest in positive social impact, while capable of ensuring the kind of intellectual rigor MIT demands. It’s an exceptionally rare combination, one we are unreasonably lucky to have,” says Mullainathan.&lt;/p&gt;&lt;p&gt;“People are increasingly interacting with algorithms, often with poor results, because most algorithms are not built with human interplay in mind,” says Polli. “We will focus on designing algorithms that will work synergistically with people. Only such algorithms can help us address large societal challenges in education, health care, poverty, et cetera.”&lt;/p&gt;&lt;p&gt;Polli was recognized as one of &lt;em&gt;Inc.'s&lt;/em&gt; Top 100 Female Founders in 2019, followed by being named to &lt;em&gt;Entrepreneur's&lt;/em&gt; Top 100 Powerful Women in 2020, and to the 2024 list of 100 Brilliant Women in AI Ethics. Her work has been highlighted by major outlets including &lt;em&gt;The New York Times&lt;/em&gt;, &lt;em&gt;The Wall Street Journal&lt;/em&gt;, &lt;em&gt;The Financial Times&lt;/em&gt;, &lt;em&gt;The Economist&lt;/em&gt;, &lt;em&gt;Fortune&lt;/em&gt;, &lt;em&gt;Harvard Business Review&lt;/em&gt;, &lt;em&gt;Fast Company&lt;/em&gt;, &lt;em&gt;Bloomberg&lt;/em&gt;, and &lt;em&gt;Inc.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Beyond her role at pymetrics, she founded Alethia AI in 2023, an organization focused on promoting transparency in technology, and in 2024, she launched Rosalind Ventures, dedicated to investing in women founders in science and health care. She is also an advisor at the Buck Institute’s Center for Healthy Aging in Women.&lt;/p&gt;&lt;p&gt;"I'm delighted to welcome Dr. Polli back to MIT. As a bilingual expert in both behavioral science and AI, she is a natural fit for the college. Her entrepreneurial background makes her a terrific inaugural visiting innovation scholar,” says Dan Huttenlocher, dean of the MIT Schwarzman College of Computing and the Henry Ellis Warren Professor of Electrical Engineering and Computer Science.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/Frida-Polli.jpg?itok=J01bJpJx" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[As a visiting innovation scholar, Frida Polli is collaborating with MIT Professor Sendhil Mullainathan to advance the intersection of behavioral science and artificial intelligence.]]></media:description>
              <media:credit>Photo: Chris J. Ratcliffe/Bloomberg via Getty Images</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/economics">Economics</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/industry">Industry</category>
      <category domain="https://news.mit.edu/topic/innovation">Innovation and Entrepreneurship (I&amp;E)</category>
      <category domain="https://news.mit.edu/topic/startups">Startups</category>
      <category domain="https://news.mit.edu/topic/technology-society">Technology and society</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/human-computer-interaction">Human-computer interaction</category>
      <category domain="https://news.mit.edu/topic/women-stem">Women in STEM</category>
      <category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">Electrical engineering and computer science (EECS)</category>
      <category domain="https://news.mit.edu/topic/lids">Laboratory for Information and Decision Systems (LIDS)</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">MIT Schwarzman College of Computing</category>
      <category domain="https://news.mit.edu/topic/school-humanities-arts-and-social-sciences">School of Humanities Arts and Social Sciences</category>
    </item>
<item>
  <title>New autism research projects represent a broad range of approaches to achieving a shared goal</title>
  <link>https://news.mit.edu/2024/new-autism-research-projects-represent-broad-range-approaches-achieving-shared-goal-1218</link>
  <description><![CDATA[At a symposium of the Simons Center for the Social Brain, six speakers described a diversity of recently launched studies aimed at improving understanding of the autistic brain.]]></description>
  <pubDate>Wed, 18 Dec 2024 11:20:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/new-autism-research-projects-represent-broad-range-approaches-achieving-shared-goal-1218</guid>
        <dc:creator>David Orenstein | The Picower Institute for Learning and Memory</dc:creator>
  <content:encoded>&lt;p&gt;From studies of the connections between neurons to interactions between the nervous and immune systems to the complex ways in which people understand not just language, but also the unspoken nuances of conversation, new research projects at MIT supported by the &lt;a href="https://scsb.mit.edu/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Simons Center for the Social Brain&lt;/a&gt; are bringing a rich diversity of perspectives to advancing the field’s understanding of autism.&lt;/p&gt;&lt;p&gt;As six speakers lined up to describe their projects at a Simons Center symposium Nov. 15, MIT &lt;a href="https://science.mit.edu/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;School of Science&lt;/a&gt; dean Nergis Mavalvala articulated what they were all striving for: “Ultimately, we want to seek understanding — not just the type that tells us how physiological differences in the inner workings of the brain produce differences in behavior and cognition, but also the kind of understanding that improves inclusion and quality of life for people living with autism spectrum disorders.”&lt;/p&gt;&lt;p&gt;Simons Center director &lt;a href="https://www.surlab.org/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Mriganka Sur&lt;/a&gt;, Newton Professor of Neuroscience in The Picower Institute for Learning and Memory and Department of Brain and Cognitive Sciences (BCS), said that even though the field still lacks mechanism-based treatments or reliable biomarkers for autism spectrum disorders, he is optimistic about the discoveries and new research MIT has been able to contribute. MIT research has led to five clinical trials so far, and he praised the potential for future discovery, for instance in the projects showcased at the symposium.&lt;/p&gt;&lt;p&gt;“We are, I believe, at a frontier — at a moment where a lot of basic science is coming together with the vision that we could use that science for the betterment of people,” Sur said.&lt;/p&gt;&lt;p&gt;The Simons Center funds that basic science research in two main ways that each encourage collaboration, Sur said: large-scale projects led by faculty members across several labs, and fellowships for postdocs who are mentored by two faculty members, thereby bringing together two labs. The symposium featured talks and panel discussions by faculty and fellows leading new research.&lt;/p&gt;&lt;div&gt;In her remarks, Associate Professor &lt;a href="https://picower.mit.edu/gloria-choi"&gt;Gloria Choi&lt;/a&gt; of The Picower Institute and BCS department described her collaboration’s efforts to explore the possibility of developing an autism therapy using the immune system. Previous research in mice by Choi and collaborator Jun Huh of Harvard Medical School has shown that injection of the immune system signaling molecule IL-17a into a particular region of the brain’s cortex can reduce neural hyperactivity and resulting differences in social and repetitive behaviors seen in autism model mice compared to non-autism models. Now Choi’s team is working on various ways to induce the immune system to target the cytokine to the brain by less invasive means than direct injection. One way under investigation, for example, is increasing the population of immune cells that produce IL-17a in the meningeal membranes that surround the brain.&lt;/div&gt;&lt;p&gt;In a different vein, Associate Professor &lt;a href="https://www.evlab.mit.edu/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Ev Fedorenko&lt;/a&gt; of The McGovern Institute for Brain Research and BCS is leading a seven-lab collaboration aimed at understanding the cognitive and neural infrastructure that enables people to engage in conversation, which involves not only the language spoken but also facial expressions, tone of voice, and social context. Critical to this effort, she said, is going beyond previous work that studied each related brain area in isolation to understand the capability as a unified whole. A key insight, she said, is that they are all nearby each other in the lateral temporal cortex.&lt;/p&gt;&lt;p&gt;“Going beyond these individual components we can start asking big questions like, what are the broad organizing principles of this part of the brain?,” Fedorenko said. “Why does it have this particular arrangement of areas, and how do these work together to exchange information to create the unified percept of another individual we’re interacting with?”&lt;/p&gt;&lt;p&gt;While Choi and Fedorenko are looking at factors that account for differences in social behavior in autism, Picower Professor &lt;a href="https://ekmillerlab.mit.edu/earl-miller/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Earl K. Miller&lt;/a&gt; of The Picower Institute and BCS is leading a project that focuses on another phenomenon: the feeling of sensory overload that many autistic people experience. Research in Miller’s lab has shown that the brain’s ability to make predictions about sensory stimuli, which is critical to filtering out mundane signals so attention can be focused on new ones, depends on a cortex-wide coordination of the activity of millions of neurons implemented by high frequency “gamma” brain waves and lower-frequency “beta” waves. Working with animal models and human volunteers at Boston Children’s Hospital (BCH), Miller said his team is testing the idea that there may be a key difference in these brain wave dynamics in the autistic brain that could be addressed with closed-loop brain wave stimulation technology.&lt;/p&gt;&lt;p&gt;Simons postdoc &lt;a href="https://scsb.mit.edu/funding/postdoctoral-fellows/lukas-vogelsang-ph-d/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Lukas Vogelsang&lt;/a&gt;, who is based in BCS Professor Pawan Sinha’s lab, is looking at potential differences in prediction between autistic and non-autistic individuals in a different way: through experiments with volunteers that aim to tease out how these differences are manifest in behavior. For instance, he’s finding that in at least one prediction task that requires participants to discern the probability of an event from provided cues, autistic people exhibit lower performance levels and undervalue the predictive significance of the cues, while non-autistic people slightly overvalue it. Vogelsang is co-advised by BCH researcher and Harvard Medical School Professor Charles Nelson.&lt;/p&gt;&lt;p&gt;Fundamentally, the broad-scale behaviors that emerge from coordinated brain-wide neural activity begins with the molecular details of how neurons connect with each other at circuit junctions called synapses. In her research based in The Picower Institute lab of Menicon Professor Troy Littleton, Simons postdoc &lt;a href="https://scsb.mit.edu/people/scsb-postdoctoral-fellows/chhavi-sood-ph-d/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Chhavi Sood&lt;/a&gt; is using the genetically manipulable model of the fruit fly to investigate how mutations in the autism-associated protein FMRP may alter the expression of molecular gates regulating ion exchange at the synapse , which would in turn affect how frequently and strongly a pre-synaptic neuron excites a post-synaptic one. The differences she is investigating may be a molecular mechanism underlying neural hyperexcitability in fragile X syndrome, a profound autism spectrum disorder.&lt;/p&gt;&lt;p&gt;In her talk, Simons postdoc &lt;a href="https://scsb.mit.edu/people/scsb-postdoctoral-fellows/lace-marie-riggs/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Lace Riggs&lt;/a&gt;, based in The McGovern Institute lab of Poitras Professor of Neuroscience Guoping Feng, emphasized how many autism-associated mutations in synaptic proteins promote pathological anxiety. She described her research that is aimed at discerning where in the brain’s neural circuitry that vulnerability might lie. In her ongoing work, Riggs is zeroing in on a novel thalamocortical circuit between the anteromedial nucleus of the thalamus and the cingulate cortex, which she found drives anxiogenic states. Riggs is co-supervised by Professor Fan Wang.&lt;/p&gt;&lt;p&gt;After the wide-ranging talks, supplemented by further discussion at the panels, the last word came via video conference from Kelsey Martin, executive vice president of the &lt;a href="https://www.sfari.org/" target="_blank" title="(opens in a new window)" data-extlink="" rel="noopener"&gt;Simons Foundation Autism Research Initiative&lt;/a&gt;. Martin emphasized that fundamental research, like that done at the Simons Center, is the key to developing future therapies and other means of supporting members of the autism community.&lt;/p&gt;&lt;p&gt;“We believe so strongly that understanding the basic mechanisms of autism is critical to being able to develop translational and clinical approaches that are going to impact the lives of autistic individuals and their families,” she said.&lt;/p&gt;&lt;p&gt;From studies of synapses to circuits to behavior, MIT researchers and their collaborators are striving for exactly that impact.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202412/mit-simons-center-panel.JPG?itok=GZlz1cVf" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Faculty members from MIT and other local institutions that participate in Simons Center research (pictured, left to right) Ev Fedorenko, Gloria Choi, Charles Nelson, Earl Miller, and moderator Mriganka Sur listen to a question from an audience member. ]]></media:description>
              <media:credit>Photo: David Orenstein/Picower Institute</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/special-events">Special events and guest speakers</category>
      <category domain="https://news.mit.edu/topic/biology">Biology</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/autism">Autism</category>
      <category domain="https://news.mit.edu/topic/anxiety">Anxiety</category>
      <category domain="https://news.mit.edu/topic/language">Language</category>
      <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/picower-institute-0">Picower Institute</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>How humans continuously adapt while walking stably</title>
  <link>https://news.mit.edu/2024/how-humans-continuously-adapt-while-walking-stably-1218</link>
  <description><![CDATA[Research could help improve motor rehabilitation programs and assistive robot control.<br>
]]></description>
  <pubDate>Wed, 18 Dec 2024 10:20:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/how-humans-continuously-adapt-while-walking-stably-1218</guid>
        <dc:creator>Department of Brain and Cognitive Sciences</dc:creator>
  <content:encoded>&lt;p&gt;Researchers have developed a model that explains how humans adapt continuously during complex tasks, like walking, while remaining stable.&lt;/p&gt;&lt;p&gt;The findings were detailed in a recent &lt;a href="https://www.nature.com/articles/s41467-024-53416-w?utm_source=rct_congratemailt&amp;amp;utm_medium=email&amp;amp;utm_campaign=oa_20241103&amp;amp;utm_content=10.1038/s41467-024-53416-w" target="_blank" rel="noopener noreferrer" tabindex="-1"&gt;paper published in the journal &lt;em&gt;Nature Communications&lt;/em&gt;&lt;/a&gt; authored by Nidhi Seethapathi, an assistant professor in MIT’s Department of Brain and Cognitive Sciences; Barrett C. Clark, a robotics software engineer at Bright Minds Inc.; and Manoj Srinivasan, an associate professor in the Department of Mechanical and Aerospace Engineering at Ohio State University.&lt;/p&gt;&lt;p&gt;In episodic tasks, like reaching for an object, errors during one episode do not affect the next episode. In tasks like locomotion, errors can have a cascade of short-term and long-term consequences to stability unless they are controlled. This makes the challenge of adapting locomotion in a new environment &amp;nbsp;more complex.&lt;/p&gt;&lt;p&gt;"Much of our prior theoretical understanding of adaptation has been limited to episodic tasks, such as reaching for an object in a novel environment," Seethapathi says. "This new theoretical model captures adaptation phenomena in continuous long-horizon tasks in multiple locomotor settings."&lt;/p&gt;&lt;p&gt;To build the model, the researchers identified general principles of locomotor adaptation across a variety of task settings, and &amp;nbsp;developed a unified modular and hierarchical model of locomotor adaptation, with each component having its own unique mathematical structure.&lt;/p&gt;&lt;p&gt;The resulting model successfully encapsulates how humans adapt their walking in novel settings such as on a split-belt treadmill with each foot at a different speed, wearing asymmetric leg weights, and wearing &amp;nbsp;an exoskeleton. The authors report that the model successfully reproduced human locomotor adaptation phenomena across novel settings in 10 prior studies and correctly predicted the adaptation behavior observed in two new experiments conducted as part of the study.&lt;/p&gt;&lt;p&gt;The model has potential applications in sensorimotor learning, rehabilitation, and wearable robotics.&lt;/p&gt;&lt;p&gt;"Having a model that can predict how a person will adapt to a new environment has immense utility for engineering better rehabilitation paradigms and wearable robot control," Seethapathi says. "You can think of a wearable robot itself as a new environment for the person to move in, and our model can be used to predict how a person will adapt for different robot settings. Understanding such human-robot adaptation is currently an experimentally intensive process, and our model &amp;nbsp;could help speed up the process by narrowing the search space."&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202412/walking.jpg?itok=Zany5XPV" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[A new model has potential applications in sensorimotor learning, rehabilitation, and wearable robotics. ]]></media:description>
          </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/wearables">Wearables</category>
      <category domain="https://news.mit.edu/topic/robotics">Robotics</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">MIT Schwarzman College of Computing</category>
    </item>
<item>
  <title>Revisiting reinforcement learning</title>
  <link>https://news.mit.edu/2024/revisiting-reinforcement-learning-1210</link>
  <description><![CDATA[A detailed new look at dopamine signaling suggests neuroscientists’ model of reinforcement learning may need to be revised.]]></description>
  <pubDate>Tue, 10 Dec 2024 15:40:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/revisiting-reinforcement-learning-1210</guid>
        <dc:creator>Jennifer Michalowski | McGovern Institute for Brain Research</dc:creator>
  <content:encoded>&lt;p&gt;Dopamine is a powerful signal in the brain, influencing our moods, motivations, movements, and more. The neurotransmitter is crucial for reward-based learning, a function that may be disrupted in a number of psychiatric conditions, from mood disorders to addiction.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Now, researchers led by MIT Institute Professor &lt;a href="https://mcgovern.mit.edu/profile/ann-graybiel/"&gt;Ann Graybiel&lt;/a&gt; have found surprising patterns of dopamine signaling that suggest neuroscientists may need to refine their model of how reinforcement learning occurs in the brain. The team’s findings were &lt;a href="https://www.nature.com/articles/s41467-024-53176-7"&gt;published recently in the journal &lt;em&gt;Nature Communications&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Dopamine plays a critical role in teaching people and other animals about the cues and behaviors that portend both positive and negative outcomes; the classic example of this type of learning is the dog that Ivan Pavlov trained to anticipate food at the sound of bell. Graybiel, who is also an investigator at MIT's McGovern Institute, explains that according to the standard model of reinforcement learning, when an animal is exposed to a cue paired with a reward, dopamine-producing cells initially fire in response to the reward. As animals learn the association between the cue and the reward, the timing of dopamine release shifts, so it becomes associated with the cue instead of the reward itself.&lt;/p&gt;&lt;p&gt;But with new tools enabling more detailed analyses of when and where dopamine is released in the brain, Graybiel’s team is finding that this model doesn’t completely hold up. The group started picking up clues that the field’s model of reinforcement learning was incomplete more than 10 years ago, when Mark Howe, a graduate student in the lab, noticed that the dopamine signals associated with reward were released not in a sudden burst the moment a reward was obtained, but instead before that, building gradually as a rat got closer to its treat. Dopamine might actually be communicating to the rest of the brain the proximity of the reward, they reasoned. “That didn't fit at all with the standard, canonical model,” Graybiel says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Dopamine dynamics&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As other neuroscientists considered how a model of reinforcement learning could take those findings into account, Graybiel and postdoc Min Jung Kim decided it was time to take a closer look at dopamine dynamics. “We thought: Let's go back to the most basic kind of experiment and start all over again,” she says.&lt;/p&gt;&lt;p&gt;That meant using sensitive new dopamine sensors to track the neurotransmitter’s release in the brains of mice as they learned to associated a blue light with a satisfying sip of water. The team focused its attention on the striatum, a region within the brain’s basal ganglia, where neurons use dopamine to influence neural circuits involved in a variety of processes, including reward-based learning&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;The researchers found that the timing of dopamine release varied in different parts of the striatum. But&amp;nbsp;nowhere did Graybiel’s team find a transition in dopamine release timing from the&amp;nbsp;time of the reward to the time to the cue — the key transition&amp;nbsp;predicted by the standard model of reinforcement learning model.&lt;/p&gt;&lt;p&gt;In the team’s simplest experiments, where every time a mouse saw a light it was paired with a reward, the lateral part of the striatum reliably released dopamine when animals were given their water. This strong response to the reward never diminished, even as the mice learned to expect the reward when they saw a light. In the medial part of the striatum, in contrast, dopamine was never released at the time of the reward. Cells there always fired when a mouse saw the light, even early in the learning process. This was puzzling, Graybiel says, because at the beginning of learning, dopamine would have been predicted to respond to the reward itself.&lt;/p&gt;&lt;p&gt;The patterns of dopamine release became even more unexpected when Graybiel’s team introduced a second light into its experimental setup. The new light, in a different position than the first, did not signal a reward. Mice watched as either light was given as the cue, one at a time, with water accompanying only the original cue.&lt;/p&gt;&lt;p&gt;In these experiments, when the mice saw the reward-associated light, dopamine release went up in the centromedial striatum and surprisingly, stayed up until the reward was delivered. In the lateral part of the region, dopamine also involved a sustained period where signaling plateaued.&lt;/p&gt;&lt;p&gt;Graybiel says she was surprised to see how much dopamine responses changed when the experimenters introduce the second light. The responses to the rewarded light were different when the other light could be shown in other trials, even though the mice saw only one light at a time. “There must be a cognitive aspect to this that comes into play,” she says. “The brain wants to hold onto the information that the cue has come on for a while.” Cells in the striatum seem to achieve this through the sustained dopamine release that continued during the brief delay between the light and the reward in the team’s experiments. Indeed, Graybiel says, while this kind of sustained dopamine release has not previously been linked to reinforcement learning, it is reminiscent of sustained signaling that has been tied to working memory in other parts of the brain.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Reinforcement learning, reconsidered&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Ultimately, Graybiel says, “many of our results didn't fit reinforcement learning models as traditionally — and by now canonically — considered.” That suggests neuroscientists’ understanding of this process will need to evolve as part of the field’s deepening understanding of the brain. “But this is just one step to help us all refine our understanding and to have reformulations of the models of how basal ganglia influence movement and thought and emotion. These reformulations will have to include surprises about the reinforcement learning system vis-á-vis these plateaus, but they could possibly give us insight into how a single experience can linger in this reinforcement-related part of our brains,” she says.&lt;/p&gt;&lt;p&gt;This study was funded by&amp;nbsp;the&amp;nbsp;National Institutes of Health, the William N. and Bernice E. Bumpus Foundation, the Saks Kavanaugh Foundation, the CHDI Foundation, Joan and Jim Schattinger, and Lisa Yang.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/dopamine.jpg?itok=S8zv2Plw" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Dopamine molecule]]></media:description>
              <media:credit>Image: iStock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/learning">Learning</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title> Study: Browsing negative content online makes mental health struggles worse</title>
  <link>https://news.mit.edu/2024/study-browsing-negative-content-online-makes-mental-health-struggles-worse-1205</link>
  <description><![CDATA[Researchers have developed a web plug-in to help those looking to protect their mental health make more informed decisions.]]></description>
  <pubDate>Thu, 05 Dec 2024 17:30:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/study-browsing-negative-content-online-makes-mental-health-struggles-worse-1205</guid>
        <dc:creator>Jarret Bencks | Department of Brain and Cognitive Sciences</dc:creator>
  <content:encoded>&lt;p&gt;People struggling with their mental health are more likely to browse negative content online, and in turn, that negative content makes their symptoms worse, according to a series of studies by researchers at MIT.&lt;br&gt;&lt;br&gt;The group behind the research has developed a &lt;a href="https://affectivebrain.com/?page_id=7596" target="_blank" rel="noopener noreferrer" tabindex="-1"&gt;web plug-in tool&lt;/a&gt; to help those looking to protect their mental health make more informed decisions about the content they view.&lt;br&gt;&lt;br&gt;The findings were outlined in an open-access paper by &lt;a href="https://bcs.mit.edu/directory/tali-sharot" tabindex="-1"&gt;Tali Sharot&lt;/a&gt;, an adjunct professor of cognitive neurosciences at MIT and professor at University College London, and Christopher A. Kelly, a former visiting PhD student who was a member of Sharot’s Affective Brain Lab when the studies were conducted, who is now a postdoc at Stanford University’s Institute for Human Centered AI. The findings were &lt;a href="https://www.nature.com/articles/s41562-024-02065-6" target="_blank"&gt;published Nov. 21 in the journal &lt;em&gt;Nature Human Behavior&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;br&gt;&lt;br&gt;“Our study shows a causal, bidirectional relationship between health and what you do online. We found that people who already have mental health symptoms are more likely to go online and more likely to browse for information that ends up being negative or fearful,” Sharot says. “After browsing this content, their symptoms become worse. It is a feedback loop.”&lt;br&gt;&lt;br&gt;The studies analyzed the web browsing habits of more than 1,000 participants by using natural language processing to calculate a negative score and a positive score for each web page visited, as well as scores for anger, fear, anticipation, trust, surprise, sadness, joy, and disgust. Participants also completed questionnaires to assess their mental health and indicated their mood directly before and after web-browsing sessions. The researchers found that participants expressed better moods after browsing less-negative web pages, and participants with worse pre-browsing moods tended to browse more-negative web pages.&lt;br&gt;&lt;br&gt;In a subsequent study, participants were asked to read information from two web pages randomly selected from either six negative webpages or six neutral pages. They then indicated their mood levels both before and after viewing the pages. An analysis found that participants exposed to negative web pages reported to be in a worse mood than those who viewed neutral pages, and then subsequently visited more-negative pages when asked to browse the internet for 10 minutes.&lt;br&gt;&lt;br&gt;“The results contribute to the ongoing debate regarding the relationship between mental health and online behavior,” the authors wrote. “Most research addressing this relationship has focused on the quantity of use, such as screen time or frequency of social media use, which has led to mixed conclusions. Here, instead, we focus on the type of content browsed and find that its affective properties are causally and bidirectionally related to mental health and mood.”&lt;br&gt;&lt;br&gt;To test whether intervention could alter web-browsing choices and improve mood, the researchers provided participants with search engine results pages with three search results for each of several queries. Some participants were provided labels for each search result on a scale of “feel better” to “feel worse.” Other participants were not provided with any labels. Those who were provided with labels were less likely to choose negative content and more likely to choose positive content. A followup study found that those who viewed more positive content reported a significantly better mood.&lt;br&gt;&lt;br&gt;Based on these findings, Sharot and Kelly created &lt;a href="https://affectivebrain.com/?page_id=7596" target="_blank" rel="noopener noreferrer" tabindex="-1"&gt;a downloadable plug-in tool&lt;/a&gt; called “Digital Diet” that offers scores for Google search results in three categories: emotion (whether people find the content positive or negative, on average), knowledge (to what extent information on a webpage helps people understand a topic, on average), and actionability (to what extent information on a webpage is useful on average). MIT electrical engineering and computer science graduate student Jonatan Fontanez '24, a former undergraduate researcher from MIT in Sharot’s lab, also contributed to the development of the tool. The tool was introduced publicly this week, along with the publication of the paper in &lt;em&gt;Nature Human Behavior&lt;/em&gt;.&lt;br&gt;&lt;br&gt;“People with worse mental health tend to seek out more-negative and fear-inducing content, which in turn exacerbates their symptoms, creating a vicious feedback loop,” Kelly says. “It is our hope that this tool can help them gain greater autonomy over what enters their minds and break negative cycles.”&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/social-media-study.jpg?itok=nYmTfmqH" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[New research analyzed the web browsing habits of more than 1,000 participants by using natural language processing to calculate a negative score and a positive score for each web page visited.]]></media:description>
              <media:credit>Image: Unsplash</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/mental-health">Mental health</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/internet">Internet</category>
      <category domain="https://news.mit.edu/topic/social-media">Social media</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/natural-language-processing">Natural language processing</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>3 Questions: Claire Wang on training the brain for memory sports </title>
  <link>https://news.mit.edu/2024/3-questions-claire-wang-training-brain-memory-sports-1121</link>
  <description><![CDATA[The MIT sophomore and award-winning memory champion explains what these competitions are all about and why you might want to build a “memory palace.”]]></description>
  <pubDate>Thu, 21 Nov 2024 00:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/3-questions-claire-wang-training-brain-memory-sports-1121</guid>
        <dc:creator>Zach Winn | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;&lt;em&gt;On Nov. 10, some of the country’s top memorizers converged on MIT’s Kresge Auditorium to compete in a “Tournament of Memory Champions” in front of a live audience.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;The competition was split into four events: long-term memory, words-to-remember, auditory memory, and double-deck of cards, in which competitors must memorize the exact order of two decks of cards. In between the events, MIT faculty who are experts in the science of memory provided short talks and demos about memory and how to improve it. Among the competitors was MIT’s own Claire Wang, a sophomore majoring in electrical engineering and computer science. Wang has competed in memory sports for years, a hobby that has taken her around the world to learn from some of the best memorists on the planet. At the tournament, she tied for first place in the words-to-remember competition.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;The event commemorated the 25th anniversary of the USA Memory Championship Organization (USAMC). USAMC sponsored the event in partnership with MIT’s McGovern Institute for Brain Research, the Department of Brain and Cognitive Sciences, the MIT Quest for Intelligence, and the company Lumosity.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;MIT News&lt;em&gt; sat down with Wang to learn more about her experience with memory competitions — and see if she had any advice for those of us with less-than-amazing memory skills.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;How did you come to get involved in memory competitions?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; When I was in middle school, I read the book “Moonwalking with Einstein,” which is about a journalist’s journey from average memory to being named memory champion in 2006. My parents were also obsessed with this TV show where people were memorizing decks of cards and performing other feats of memory. I had already known about the concept of “memory palaces,” so I was inspired to explore memory sports. Somehow, I convinced my parents to let me take a gap year after seventh grade, and I travelled the world going to competitions and learning from memory grandmasters. I got to know the community in that time and I got to build my memory system, which was really fun. I did a lot less of those competitions after that year and some subsequent competitions with the USA memory competition, but it’s still fun to have this ability.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;What was the Tournament of Memory Champions like?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; USAMC invited a lot of winners from previous years to compete, which was really cool. It was nice seeing a lot of people I haven’t seen in years. I didn’t compete in every event because I was too busy to do the long-term memory, which takes you two weeks of memorization work. But it was a really cool experience. I helped a bit with the brainstorming beforehand because I know one of the professors running it. We thought about how to give the talks and structure the event.&lt;/p&gt;&lt;p&gt;Then I competed in the words event, which is when they give you 300 words over 15 minutes, and the competitors have to recall each one in order in a round robin competition. You got two strikes. A lot of other competitions just make you write the words down. The round robin makes it more fun for people to watch. I tied with someone else — I made a dumb mistake — so I was kind of sad in hindsight, but being tied for first is still great.&lt;/p&gt;&lt;p&gt;Since I hadn't done this in a while (and I was coming back from a trip where I didn’t get much sleep), I was a bit nervous that my brain wouldn’t be able to remember anything, and I was pleasantly surprised I didn’t just blank on stage. Also, since I hadn’t done this in a while, a lot of my loci and memory palaces were forgotten, so I had to speed-review them before the competition. The words event doesn’t get easier over time — it’s just 300 random words (which could range from “disappointment” to “chair”) and you just have to remember the order.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;What is your approach to improving memory?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; The whole idea is that we memorize images, feelings, and emotions much better than numbers or random words. The way it works in practice is we make an ordered set of locations in a “memory palace.” The palace could be anything. It could be a campus or a classroom or a part of a room, but you imagine yourself walking through this space, so there’s a specific order to it, and in every location I place certain information. This is information related to what I’m trying to remember. I have pictures I associate with words and I have specific images I correlate with numbers. Once you have a correlated image system, all you need to remember is a story, and then when you recall, you translate that back to the original information.&lt;/p&gt;&lt;p&gt;Doing memory sports really helps you with visualization, and being able to visualize things faster and better helps you remember things better. You start remembering with spaced repetition that you can talk yourself through. Allowing things to have an emotional connection is also important, because you remember emotions better. Doing memory competitions made me want to study neuroscience and computer science at MIT.&lt;/p&gt;&lt;p&gt;The specific memory sports techniques are not as useful in everyday life as you’d think, because a lot of the information we learn is more operative and requires intuitive understanding, but I do think they help in some ways. First, sometimes you have to initially remember things before you can develop a strong intuition later. Also, since I have to get really good at telling a lot of stories over time, I have gotten great at visualization and manipulating objects in my mind, which helps a lot.&amp;nbsp;&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/MIT-3QMemoryTourn-01-press.jpg?itok=BbcYfOnU" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[“Doing memory competitions made me want to study neuroscience and computer science at MIT,” says Claire Wang, standing in the photo with other competitors. ]]></media:description>
              <media:credit>Image: Courtesy of McGovern Institute for Brain Research</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/students">Students</category>
      <category domain="https://news.mit.edu/topic/interview">Interview</category>
      <category domain="https://news.mit.edu/topic/undergraduate">Undergraduate</category>
      <category domain="https://news.mit.edu/topic/contests">Contests and academic competitions</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/quest-intelligence">Quest for Intelligence</category>
      <category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">Electrical engineering and computer science (EECS)</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Four from MIT named 2025 Rhodes Scholars</title>
  <link>https://news.mit.edu/2024/four-mit-named-2025-rhodes-scholars-1116</link>
  <description><![CDATA[Yiming Chen ’24, Wilhem Hector, Anushka Nair, and David Oluigbo will start postgraduate studies at Oxford next fall.]]></description>
  <pubDate>Sat, 16 Nov 2024 22:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/four-mit-named-2025-rhodes-scholars-1116</guid>
        <dc:creator>Julia Mongo | Distinguished Fellowships</dc:creator>
  <content:encoded>&lt;p&gt;Yiming Chen ’24, Wilhem Hector, Anushka Nair, and David Oluigbo&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;have been selected as 2025 Rhodes Scholars and will begin fully funded postgraduate studies at Oxford University in the U.K. next fall. In addition to MIT’s two U.S. Rhodes winners, Oluigbo and Nair, two affiliates were awarded international Rhodes Scholarships: Chen for Rhodes’ China constituency and Hector for the Global Rhodes Scholarship. Hector is the first Haitian citizen to be named a Rhodes Scholar.&lt;/p&gt;&lt;p&gt;The scholars were supported by Associate Dean Kim Benard and the Distinguished Fellowships team in Career Advising and Professional Development. They received additional mentorship and guidance from the Presidential Committee on Distinguished Fellowships.&lt;/p&gt;&lt;p&gt;“It is profoundly inspiring to work with our amazing students, who have accomplished so much at MIT&amp;nbsp;and, at the same time, thought deeply about how they can have an impact in solving the world's major challenges,” says Professor Nancy Kanwisher, who co-chairs the committee along with Professor Tom Levenson. “These students have worked hard to develop and articulate their vision and to learn to communicate it to others with passion, clarity, and confidence. We are thrilled but not surprised to see so many of them recognized this year as finalists and as winners.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Yiming Chen ’24&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Yiming Chen, from Beijing, China, and the Washington area, was named one of four Rhodes China Scholars on Sept 28. At Oxford, she will pursue graduate studies in engineering science, working toward her ongoing goal of advancing AI safety and reliability in clinical workflows.&lt;/p&gt;&lt;p&gt;Chen graduated from MIT in 2024 with a BS in mathematics and computer science and an MEng in computer science. She worked on several projects involving machine learning for health care, and focused her master’s research on medical imaging in the Medical Vision Group of the Computer Science and Artificial Intelligence Laboratory (CSAIL).&lt;/p&gt;&lt;p&gt;Collaborating with IBM Research, Chen developed a neural framework for clinical-grade lumen segmentation in intravascular ultrasound and presented her findings at the MICCAI Machine Learning in Medical Imaging conference. Additionally, she worked at Cleanlab, an MIT-founded startup, creating an open-source library to ensure the integrity of image datasets used in vision tasks.&lt;/p&gt;&lt;p&gt;Chen was a teaching assistant in the MIT math and electrical engineering and computer science departments, and received a teaching excellence award. She taught high school students at the Hampshire College Summer Studies in Math and was selected to participate in MISTI Global Teaching Labs in Italy.&lt;/p&gt;&lt;p&gt;Having studied the guzheng, a traditional Chinese instrument, since age 4, Chen served as president of the MIT Chinese Music Ensemble, explored Eastern and Western music synergies with the MIT Chamber Music Society, and performed at the United Nations. On campus, she was also active with Asymptones a capella,&amp;nbsp;MIT Ring Committee, Ribotones, Figure Skating Club, and the Undergraduate Association Innovation Committee.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wilhem Hector&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Wilhem Hector, a senior from Port-au-Prince, Haiti, majoring in mechanical engineering, was awarded a Global Rhodes Scholarship on Nov 1. The first Haitian national to be named a Rhodes Scholar, Hector will pursue at Oxford a master’s in energy systems followed by a master’s in education, focusing on digital and social change. His long-term goals are twofold: pioneering Haiti’s renewable energy infrastructure and expanding hands-on opportunities in the country‘s national curriculum.&lt;br&gt;&lt;br&gt;Hector developed his passion for energy through his research in the MIT Howland Lab, where he investigated the uncertainty of wind power production during active yaw control. He also helped launch the MIT Renewable Energy Clinic through his work on the sources of opposition to energy projects in the U.S. Beyond his research, Hector had notable contributions as an intern at Radia Inc. and DTU Wind Energy Systems, where he helped develop computational wind farm modeling and simulation techniques.&lt;br&gt;&lt;br&gt;Outside of MIT, he leads the Hector Foundation, a nonprofit providing educational opportunities to young people in Haiti. He has raised over $80,000 in the past five years to finance their initiatives, including the construction of Project Manus, Haiti’s first open-use engineering makerspace. Hector’s service endeavors have been supported by the MIT PKG Center, which awarded him the Davis Peace Prize, the PKG Fellowship for Social Impact, and the PKG Award for Public Service.&lt;br&gt;&lt;br&gt;Hector co-chairs both the Student Events Board and the Class of 2025 Senior Ball Committee and has served as the social chair for Chocolate City and the African Students Association.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Anushka Nair&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Anushka Nair, from Portland, Oregon, will graduate next spring with BS and MEng degrees in computer science and engineering with concentrations in economics and AI. She plans to pursue a DPhil in social data science at the Oxford Internet Institute. Nair aims to develop ethical AI technologies that address pressing societal challenges, beginning with combating misinformation.&lt;/p&gt;&lt;p&gt;For her master’s thesis under Professor David Rand, Nair is developing LLM-powered fact-checking tools to detect nuanced misinformation beyond human or automated capabilities. She also researches human-AI co-reasoning at the MIT Center for Collective Intelligence with Professor Thomas Malone. Previously, she conducted research on autonomous vehicle navigation at Stanford’s AI and Robotics Lab, energy microgrid load balancing at MIT’s Institute for Data, Systems, and Society, and worked with Professor Esther Duflo in economics.&lt;/p&gt;&lt;p&gt;Nair interned in the Executive Office of the Secretary General at the United Nations, where she integrated technology solutions and assisted with launching the High-Level Advisory Body on AI. She also interned in Tesla’s energy sector, contributing to Autobidder, an energy trading tool, and led the launch of a platform for monitoring distributed energy resources and renewable power plants. Her work has earned her recognition as a Social and Ethical Responsibilities of Computing Scholar and a U.S. Presidential Scholar.&lt;/p&gt;&lt;p&gt;Nair has served as President of the MIT Society of Women Engineers and MIT and Harvard Women in AI, spearheading outreach programs to mentor young women in STEM fields. She also served as president of MIT Honors Societies Eta Kappa Nu and Tau Beta Pi.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;David Oluigbo&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;David Oluigbo, from Washington, is a senior majoring in artificial intelligence and decision making and minoring in brain and cognitive sciences. At Oxford, he will undertake an MS in applied digital health followed by an MS in modeling for global health. Afterward, Oluigbo plans to attend medical school with the goal of becoming a physician-scientist who researches and applies AI to address medical challenges in low-income countries.&lt;/p&gt;&lt;p&gt;Since his first year at MIT, Oluigbo has conducted neural and brain research with Ev Fedorenko at the McGovern Institute for Brain Research and with Susanna Mierau’s Synapse and Network Development Group at Brigham and Women’s Hospital. His work with Mierau led to several publications and a poster presentation at the Federation of European Societies annual meeting.&lt;/p&gt;&lt;p&gt;In a summer internship at the National Institutes of Health Clinical Center, Oluigbo designed and trained machine-learning models on CT scans for automatic detection of neuroendocrine tumors, leading to first authorship on an International Society for Optics and Photonics conference proceeding paper, which he presented at the 2024 annual meeting. Oluigbo also did a summer internship with the Anyscale Learning for All Laboratory at the MIT Computer Science and Artificial Intelligence Laboratory.&lt;/p&gt;&lt;p&gt;Oluigbo is an EMT and systems administrator officer with MIT-EMS. He is a consultant for Code for Good, a representative on the MIT Schwarzman College of Computing Undergraduate Advisory Group, and holds executive roles with the Undergraduate Association, the MIT Brain and Cognitive Society, and the MIT Running Club.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/2024%20MIT%20Rhodes%20Composite.jpg?itok=x-ejB5on" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Top, left to right: Yiming Chen, Wilhem Hector. Bottom, left to right: Anushka Nair, David Oluigbo]]></media:description>
              <media:credit>Credits: Yiming Chen, Qudus Shittu (Hector), Ian MacLellan (Nair and Oluigbo)</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/education">Education, teaching, academics</category>
      <category domain="https://news.mit.edu/topic/alumni">Alumni/ae</category>
      <category domain="https://news.mit.edu/topic/students">Students</category>
      <category domain="https://news.mit.edu/topic/mathematics">Mathematics</category>
      <category domain="https://news.mit.edu/topic/computers">Computer science and technology</category>
      <category domain="https://news.mit.edu/topic/electrical-engineering-computer-science-eecs">Electrical engineering and computer science (EECS)</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">Computer Science and Artificial Intelligence Laboratory (CSAIL)</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/mechanical-engineering">Mechanical engineering</category>
      <category domain="https://news.mit.edu/topic/global">Global</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">MIT Schwarzman College of Computing</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/school-humanities-arts-and-social-sciences">School of Humanities Arts and Social Sciences</category>
      <category domain="https://news.mit.edu/topic/mit-sloan-school-management">MIT Sloan School of Management</category>
    </item>
<item>
  <title>When muscles work out, they help neurons to grow, a new study shows</title>
  <link>https://news.mit.edu/2024/when-muscles-work-out-they-help-neurons-grow-1112</link>
  <description><![CDATA[The findings suggest that biochemical and physical effects of exercise could help heal nerves.]]></description>
  <pubDate>Tue, 12 Nov 2024 03:05:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/when-muscles-work-out-they-help-neurons-grow-1112</guid>
        <dc:creator>Jennifer Chu | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;There’s no doubt that exercise does a body good. Regular activity not only strengthens muscles but can bolster our bones, blood vessels, and immune system.&lt;/p&gt;&lt;p&gt;Now, MIT engineers have found that exercise can also have benefits at the level of individual neurons. They observed that when muscles contract during exercise, they release a soup of biochemical signals called myokines. In the presence of these muscle-generated signals, neurons grew four times farther compared to neurons that were not exposed to myokines. These cellular-level experiments suggest that exercise can have a significant biochemical effect on nerve growth.&lt;/p&gt;&lt;p&gt;Surprisingly, the researchers also found that neurons respond not only to the biochemical signals of exercise but also to its physical impacts. The team observed that when neurons are repeatedly pulled back and forth, similarly to how muscles contract and expand during exercise, the neurons grow just as much as when they are exposed to a muscle’s myokines.&lt;/p&gt;&lt;p&gt;While previous studies have indicated a potential biochemical link between muscle activity and nerve growth, this study is the first to show that physical effects can be just as important, the researchers say.&amp;nbsp;The results, which are &lt;a href=" https://doi.org/10.1002/adhm.202403712" target="_blank"&gt;published today in the journal &lt;em&gt;Advanced Healthcare Materials&lt;/em&gt;&lt;/a&gt;, shed light on the connection between muscles and nerves during exercise, and could inform exercise-related therapies for repairing damaged and deteriorating nerves.&lt;/p&gt;&lt;p&gt;“Now that we know this muscle-nerve crosstalk exists, it can be useful for treating things like nerve injury, where communication between nerve and muscle is cut off,” says Ritu Raman, the Eugene Bell Career Development Assistant Professor of Mechanical Engineering at MIT. “Maybe if we stimulate the muscle, we could encourage the nerve to heal, and restore mobility to those who have&amp;nbsp;lost it due to traumatic injury or neurodegenerative diseases.”&lt;/p&gt;&lt;p&gt;Raman is the senior author of the new study, which includes Angel Bu, Ferdows Afghah, Nicolas Castro, Maheera Bawa, Sonika Kohli, Karina Shah, and Brandon Rios of MIT’s Department of Mechanical Engineering, and Vincent Butty of MIT’s Koch Institute for Integrative Cancer Research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Muscle talk&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In 2023, Raman and her colleagues&amp;nbsp;&lt;a href="https://news.mit.edu/2023/light-activated-muscle-grafts-show-promise-aiding-muscle-recovery-post-trauma-1030" target="_blank"&gt;reported&lt;/a&gt; that they could restore mobility in mice that had experienced a traumatic muscle injury, by first implanting muscle tissue at the site of injury, then exercising the new tissue by stimulating it repeatedly with light. Over time, they found that the exercised graft helped mice to regain their motor function, reaching activity levels comparable to those of healthy mice.&lt;/p&gt;&lt;p&gt;When the researchers analyzed the graft itself, it appeared that regular exercise stimulated the grafted muscle to produce certain biochemical signals that are known to promote nerve and blood vessel growth.&lt;/p&gt;&lt;p&gt;“That was interesting because we always think that nerves control muscle, but we don’t think of muscles talking back to nerves,” Raman says. “So, we started to think stimulating muscle was encouraging nerve growth. And people replied that maybe that’s the case, but there’s hundreds of other cell types in an animal, and it’s really hard to prove that the nerve is growing more because of the muscle, rather than the immune system or something else playing a role.”&lt;/p&gt;&lt;p&gt;In their new study, the team set out to determine whether exercising muscles has any direct effect on how nerves grow, by focusing solely on muscle and nerve tissue. The researchers grew mouse muscle cells into long fibers that then fused to form a small sheet of mature muscle tissue about the size of a quarter.&lt;/p&gt;&lt;p&gt;The team genetically modified the muscle to contract in response to light. With this modification, the team could flash a light repeatedly, causing the muscle to squeeze in response, in a way that mimicked the act of exercise. Raman previously developed a novel&amp;nbsp;&lt;a href="https://news.mit.edu/2023/wobbly-gel-mat-trains-muscle-cells-work-together-1020" target="_blank"&gt;gel mat&lt;/a&gt; on which to grow and exercise muscle tissue. The gel’s properties are such that it can support muscle tissue and prevent it from peeling away as the researchers stimulated the muscle to exercise.&lt;/p&gt;&lt;p&gt;The team then collected samples of the surrounding solution in which the muscle tissue was exercised, thinking that the solution should hold myokines, including growth factors, RNA, and a mix of other proteins.&lt;/p&gt;&lt;p&gt;“I would think of myokines as a biochemical soup of things that muscles secrete, some of which could be good for nerves and others that might have nothing to do with nerves,” Raman says. “Muscles are pretty much always secreting myokines, but when you exercise them, they make more.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“Exercise as medicine”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The team transferred the myokine solution to a separate dish containing motor neurons — nerves found in the spinal cord that control muscles involved in voluntary movement. The researchers grew the neurons from stem cells derived from mice. As with the muscle tissue, the neurons were grown on a similar gel mat. After the neurons were exposed to the myokine mixture, the team observed that they quickly began to grow, four times faster than neurons that did not receive the biochemical solution.&lt;/p&gt;&lt;p&gt;“They grow much farther and faster, and the effect is pretty immediate,” Raman notes.&lt;/p&gt;&lt;p&gt;For a closer look at how neurons changed in response to the exercise-induced myokines, the team ran a genetic analysis, extracting RNA from the neurons to see whether the myokines induced any change in the expression of certain neuronal genes.&lt;/p&gt;&lt;p&gt;“We saw that many of the genes up-regulated in the exercise-stimulated neurons was not only related to neuron growth, but also neuron maturation, how well they talk to muscles and other nerves, and how mature the axons are,” Raman says. “Exercise seems to impact not just neuron growth but also how mature and well-functioning they are.”&lt;/p&gt;&lt;p&gt;The results suggest that biochemical effects of exercise can promote neuron growth. Then the group wondered: Could exercise’s purely physical impacts have a similar benefit?&lt;/p&gt;&lt;p&gt;“Neurons are physically attached to muscles, so they are also stretching and moving with the muscle,” Raman says. “We also wanted to see, even in the absence of biochemical cues from muscle, could we stretch the neurons back and forth, mimicking the mechanical forces (of exercise), and could that have an impact on growth as well?”&lt;/p&gt;&lt;p&gt;To answer this, the researchers grew a different set of motor neurons on a gel mat that they embedded with tiny magnets. They then used an external magnet to jiggle the mat — and the neurons — back and forth. In this way, they “exercised” the neurons, for 30 minutes a day. To their surprise, they found that this mechanical exercise stimulated the neurons to grow just as much as the myokine-induced neurons, growing significantly farther than neurons that received no form of exercise.&lt;/p&gt;&lt;p&gt;“That’s a good sign because it tells us both biochemical and physical effects of exercise are equally important,” Raman says.&lt;/p&gt;&lt;p&gt;Now that the group has shown that exercising muscle can promote nerve growth at the cellular level, they plan to study how targeted muscle stimulation can be used to grow and heal damaged nerves, and restore mobility for people who are living with a neurodegenerative disease such as ALS.&lt;/p&gt;&lt;p&gt;“This is just our first step toward understanding and controlling exercise as medicine,” Raman says.&amp;nbsp;&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/MIT-Exercising-neurons-01-press_2.jpg?itok=OVuf26YP" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[In response to biochemical and physical cues of exercise, motor neurons (in purple) exhibit new growth (in green) faster than neurons that experience no exercise-induced cues. ]]></media:description>
              <media:credit>Credit: Angel Bu</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/biology">Biology</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/cells">Cells</category>
      <category domain="https://news.mit.edu/topic/biological-engineering">Biological engineering</category>
      <category domain="https://news.mit.edu/topic/health2">Health</category>
      <category domain="https://news.mit.edu/topic/medicine">Medicine</category>
      <category domain="https://news.mit.edu/topic/mechanical-engineering">Mechanical engineering</category>
      <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
    </item>
<item>
  <title>Neuroscientists create a comprehensive map of the cerebral cortex</title>
  <link>https://news.mit.edu/2024/neuroscientists-create-comprehensive-map-cerebral-cortex-1106</link>
  <description><![CDATA[Using fMRI, the research team identified 24 networks that perform specific functions within the brain’s cerebral cortex.]]></description>
  <pubDate>Wed, 06 Nov 2024 11:00:00 -0500</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/neuroscientists-create-comprehensive-map-cerebral-cortex-1106</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;By analyzing brain scans taken as people watched movie clips, MIT researchers have created the most comprehensive map yet of the functions of the brain’s cerebral cortex.&lt;/p&gt;&lt;p&gt;Using functional magnetic resonance imaging (fMRI) data, the research team identified 24 networks with different functions, which include processing language, social interactions, visual features, and other types of sensory input.&lt;/p&gt;&lt;p&gt;Many of these networks have been seen before but haven’t been precisely characterized using naturalistic conditions. While the new study mapped networks in subjects watching engaging movies, previous works have used a small number of specific tasks or examined correlations across the brain in subjects who were simply resting.&lt;/p&gt;&lt;p&gt;“There’s an emerging approach in neuroscience to look at brain networks under more naturalistic conditions. This is a new approach that reveals something different from conventional approaches in neuroimaging,” says Robert Desimone, director of MIT’s McGovern Institute for Brain Research. “It’s not going to give us all the answers, but it generates a lot of interesting ideas based on what we see going on in the movies that's related to these network maps that emerge.”&lt;/p&gt;&lt;p&gt;The researchers hope that their new map will serve as a starting point for further study of what each of these networks is doing in the brain.&lt;/p&gt;&lt;p&gt;Desimone and John Duncan, a program leader in the MRC Cognition and Brain Sciences Unit at Cambridge University, are the senior authors of the study, which &lt;a href="https://doi.org/10.1016/j.neuron.2024.10.005" target="_blank"&gt;appears today in &lt;em&gt;Neuron&lt;/em&gt;&lt;/a&gt;. Reza Rajimehr, a research scientist in the McGovern Institute and a former graduate student at Cambridge University, is the lead author of the paper.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Precise mapping&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The cerebral cortex of the brain contains regions devoted to processing different types of sensory information, including visual and auditory input. Over the past few decades, scientists have identified many networks that are involved in this kind of processing, often using fMRI to measure brain activity as subjects perform a single task such as looking at faces.&lt;/p&gt;&lt;p&gt;In other studies, researchers have scanned people’s brains as they do nothing, or let their minds wander. From those studies, researchers have identified networks such as the default mode network, a network of areas that is active during internally focused activities such as daydreaming.&lt;/p&gt;&lt;p&gt;“Up to now, most studies of networks were based on doing functional MRI in the resting-state condition. Based on those studies, we know some main networks in the cortex. Each of them is responsible for a specific cognitive function, and they have been highly influential in the neuroimaging field,” Rajimehr says.&lt;/p&gt;&lt;p&gt;However, during the resting state, many parts of the cortex may not be active at all. To gain a more comprehensive picture of what all these regions are doing, the MIT team analyzed data recorded while subjects performed a more natural task: watching a movie.&lt;/p&gt;&lt;p&gt;“By using a rich stimulus like a movie, we can drive many regions of the cortex very efficiently. For example, sensory regions will be active to process different features of the movie, and high-level areas will be active to extract semantic information and contextual information,” Rajimehr says. “By activating the brain in this way, now we can distinguish different areas or different networks based on their activation patterns.”&lt;/p&gt;&lt;p&gt;The data for this study was generated as part of the Human Connectome Project. Using a 7-Tesla MRI scanner, which offers higher resolution than a typical MRI scanner, brain activity was imaged in 176 people as they watched one hour of movie clips showing a variety of scenes.&lt;/p&gt;&lt;p&gt;The MIT team used a machine-learning algorithm to analyze the activity patterns of each brain region, allowing them to identify 24 networks with different activity patterns and functions.&lt;/p&gt;&lt;p&gt;Some of these networks are located in sensory areas such as the visual cortex or auditory cortex, as expected for regions with specific sensory functions. Other areas respond to features such as actions, language, or social interactions.&amp;nbsp;Many of these networks have been seen before, but this technique offers more precise definition of where the networks are located, the researchers say.&lt;/p&gt;&lt;p&gt;“Different regions are competing with each other for processing specific features, so when you map each function in isolation, you may get a slightly larger network because it is not getting constrained by other processes,” Rajimehr says. “But here, because all the areas are considered together, we are able to define more precise boundaries between different networks.”&lt;/p&gt;&lt;p&gt;The researchers also identified networks that hadn’t been seen before, including one in the prefrontal cortex, which appears to be highly responsive to visual scenes. This network was most active in response to pictures of scenes within the movie frames.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Executive control networks&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Three of the networks found in this study are involved in “executive control,” and were most active during transitions between different clips. The researchers also observed that these control networks appear to have a “push-pull” relationship with networks that process specific features such as faces or actions. When networks specific to a particular feature were very active, the executive control networks were mostly quiet, and vice versa.&lt;/p&gt;&lt;p&gt;“Whenever the activations in domain-specific areas are high, it looks like there is no need for the engagement of these high-level networks,” Rajimehr says. “But in situations where perhaps there is some ambiguity and complexity in the stimulus, and there is a need for the involvement of the executive control networks, then we see that these networks become highly active.”&lt;/p&gt;&lt;p&gt;Using a movie-watching paradigm, the researchers are now studying some of the networks they identified in more detail, to identify subregions involved in particular tasks. For example, within the social processing network, they have found regions that are specific to processing social information about faces and bodies. In a new network that analyzes visual scenes, they have identified regions involved in processing memory of places.&lt;/p&gt;&lt;p&gt;“This kind of experiment is really about generating hypotheses for how the cerebral cortex is functionally organized. Networks that emerge during movie watching now need to be followed up with more specific experiments to test the hypotheses. It’s giving us a new view into the operation of the entire cortex during a more naturalistic task than just sitting at rest,” Desimone says.&lt;/p&gt;&lt;p&gt;The research was funded by the McGovern Institute, the Cognitive Science and Technology Council of Iran, the MRC Cognition and Brain Sciences Unit at the University of Cambridge, and a Cambridge Trust scholarship.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202411/MIT-Network-Maps-01-press.jpg?itok=XP8_EYEo" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[By analyzing brain scans taken as people watched movie clips, MIT researchers have created the most comprehensive map yet of the functions of the brain’s cortex. ]]></media:description>
              <media:credit>Credit: Christine Daniloff, MIT; Shutterstock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>MIT Schwarzman College of Computing launches postdoctoral program to advance AI across disciplines</title>
  <link>https://news.mit.edu/2024/mit-schwarzman-college-computing-launches-postdoctoral-program-advance-ai-across-disciplines-1029</link>
  <description><![CDATA[The new Tayebati Postdoctoral Fellowship Program will support leading postdocs to bring cutting-edge AI to bear on research in scientific discovery or music.]]></description>
  <pubDate>Tue, 29 Oct 2024 15:40:00 -0400</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/mit-schwarzman-college-computing-launches-postdoctoral-program-advance-ai-across-disciplines-1029</guid>
        <dc:creator>Terri Park | MIT Schwarzman College of Computing</dc:creator>
  <content:encoded>&lt;p&gt;The MIT Stephen A. Schwarzman College of Computing has announced the launch of a new program to support postdocs conducting research at the intersection of artificial intelligence and particular disciplines.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://computing.mit.edu/tayebati-postdoctoral-fellowship-program/"&gt;Tayebati Postdoctoral Fellowship Program&lt;/a&gt; will focus on AI for addressing the most challenging problems in select scientific research areas, and on AI for music composition and performance. The program will welcome an inaugural cohort of up to six postdocs for a one-year term, with the possibility of renewal for a second term.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Supported by a $20 million gift from Parviz Tayebati, an entrepreneur and executive with a broad technical background and experience with startup companies, the program will empower top postdocs by providing an environment that facilitates their academic and professional development and enables them to pursue ambitious discoveries. “I am proud to support a fellowship program that champions interdisciplinary research and fosters collaboration across departments. My hope is that this gift will inspire a new generation of scholars whose research advances knowledge and nurtures innovation that transcends traditional boundaries,” says Tayebati.&lt;/p&gt;&lt;p&gt;"Artificial intelligence holds tremendous potential to accelerate breakthroughs in science and ignite human creativity," says Dan Huttenlocher, dean of the Schwarzman College of Computing and Henry Ellis Warren Professor of Electrical Engineering and Computer Science. “This new postdoc program is a remarkable opportunity to cultivate exceptional bilingual talent combining AI and another discipline. The program will offer fellows the chance to engage in research at the forefront of both AI and another field, collaborating with leading experts across disciplines. We are deeply thankful to Parviz for his foresight in supporting the development of researchers in this increasingly important area.”&lt;/p&gt;&lt;p&gt;Candidates accepted into the program will work on projects that encompass one of six disciplinary areas: biology/bioengineering, brain and cognitive sciences, chemistry/chemical engineering, materials science and engineering, music, and physics. Each fellow will have a faculty mentor in the disciplinary area as well as in AI.&lt;/p&gt;&lt;p&gt;The Tayebati Postdoctoral Fellowship Program is a key component of a larger focus of the MIT Schwarzman College of Computing aimed at fostering innovative research in computing. As part of this focus, the college has three postdoctoral programs, each of which provides training and mentorship to fellows, broadens their research horizons, and helps them develop expertise in computing, including its intersection with other disciplines.&lt;/p&gt;&lt;p&gt;Other programs include &lt;a href="https://computing.mit.edu/research/postdoctoral-fellows-programs/meteor-program/" target="_blank"&gt;MEnTorEd Opportunities in Research&lt;/a&gt; (METEOR), which was established by the Computer Science and Artificial Intelligence Laboratory in 2020. Recently expanded to span MIT through the college, the goal of METEOR is to support exceptional scholars in computer science and AI and to broaden participation in the field.&lt;/p&gt;&lt;p&gt;In addition, the Social and Ethical Responsibilities of Computing (SERC), a cross-cutting initiative of the MIT Schwarzman College of Computing, offers researchers exploring how computing is reshaping society the opportunity to participate as a &lt;a href="https://computing.mit.edu/cross-cutting/social-and-ethical-responsibilities-of-computing/serc-postdocs/" target="_blank"&gt;SERC postdoc&lt;/a&gt;. SERC postdocs engage in a number of activities throughout the year, including leading interdisciplinary teams of MIT undergraduate and graduate students, known as SERC Scholars, to work on research projects investigating such topics as generative AI and democracy, combating deepfakes, examining data ownership, and the societal impact of gamification, among others.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202410/mit-campus.jpg?itok=Bt3uHhlA" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[The MIT Schwarzman College of Computing has launched the Tayebati Postdoctoral Fellowship Program, which will support leading postdocs to bring cutting-edge AI to bear on research in scientific discovery or music.]]></media:description>
              <media:credit>Photo: Jake Belcher</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/funding">Funding</category>
      <category domain="https://news.mit.edu/topic/graduate">Graduate, postdoctoral</category>
      <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/biology">Biology</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/chemical-engineering">Chemical engineering</category>
      <category domain="https://news.mit.edu/topic/chemistry-0">Chemistry</category>
      <category domain="https://news.mit.edu/topic/dmse">DMSE</category>
      <category domain="https://news.mit.edu/topic/physics">Physics</category>
      <category domain="https://news.mit.edu/topic/computer-science-and-artificial-intelligence-laboratory-csail">Computer Science and Artificial Intelligence Laboratory (CSAIL)</category>
      <category domain="https://news.mit.edu/topic/artificial-intelligence2">Artificial intelligence</category>
      <category domain="https://news.mit.edu/topic/music2">Music</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-humanities-arts-and-social-sciences">School of Humanities Arts and Social Sciences</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/mit-schwarzman-college-computing">MIT Schwarzman College of Computing</category>
    </item>
<item>
  <title>Brain pathways that control dopamine release may influence motor control</title>
  <link>https://news.mit.edu/2024/brain-pathways-control-dopamine-release-may-influence-motor-control-1023</link>
  <description><![CDATA[The newly identified pathways appear to relay emotional information that helps to shape the motivation to take action. ]]></description>
  <pubDate>Wed, 23 Oct 2024 11:00:00 -0400</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/brain-pathways-control-dopamine-release-may-influence-motor-control-1023</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;Within the human brain, movement is influenced by a brain region called the striatum, which sends instructions to motor neurons in the brain. Those instructions are conveyed by two pathways, one that initiates movement (“go”) and one that suppresses it (“no-go”).&lt;/p&gt;&lt;p&gt;In a new study, MIT researchers have discovered an additional two pathways that arise in the striatum and appear to modulate the effects of the go and no-go pathways. These newly discovered pathways connect to dopamine-producing neurons in the brain — one stimulates dopamine release and the other inhibits it.&lt;/p&gt;&lt;p&gt;By controlling the amount of dopamine in the brain via clusters of neurons known as striosomes, these pathways appear to modify the instructions given by the go and no-go pathways. They may be especially involved in influencing decisions that have a strong emotional component, the researchers say.&lt;/p&gt;&lt;p&gt;“Among all the regions of the striatum, the striosomes alone turned out to be able to project to the dopamine-containing neurons, which we think has something to do with motivation, mood, and controlling movement,” says Ann Graybiel, an MIT Institute Professor, a member of MIT’s McGovern Institute for Brain Research, and the senior author of the new study.&lt;/p&gt;&lt;p&gt;Iakovos Lazaridis, a research scientist at the McGovern Institute, is the lead author of the paper, which &lt;a href="http://doi.org/10.1016/j.cub.2024.09.070"&gt;appears today in the journal &lt;em&gt;Current Biology&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;New pathways&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Graybiel has spent much of her career studying the striatum, a structure located deep within the brain that is involved in learning and decision-making, as well as control of movement.&lt;/p&gt;&lt;p&gt;Within the striatum, neurons are arranged in a labyrinth-like structure that includes striosomes, which Graybiel discovered in the 1970s. The classical go and no-go pathways arise from neurons that surround the striosomes, which are known collectively as the matrix. The matrix cells that give rise to these pathways receive input from sensory processing regions such as the visual cortex and auditory cortex. Then, they send go or no-go commands to neurons in the motor cortex.&lt;/p&gt;&lt;p&gt;However, the function of the striosomes, which are not part of those pathways, remained unknown. For many years, researchers in Graybiel’s lab have been trying to solve that mystery.&lt;/p&gt;&lt;p&gt;Their previous work revealed that striosomes receive much of their input from parts of the brain that process emotion. Within striosomes, there are two major types of neurons, classified as D1 and D2. In a &lt;a href="https://news.mit.edu/2015/brain-circuit-controls-decisions-causing-anxiety-0528"&gt;2015 study&lt;/a&gt;, Graybiel found that one of these cell types, D1, sends input to the substantia nigra, which is the brain’s major dopamine-producing center.&lt;/p&gt;&lt;p&gt;It took much longer to trace the output of the other set, D2 neurons. In the new &lt;em&gt;Current Biology&lt;/em&gt; study, the researchers discovered that those neurons also eventually project to the substantia nigra, but first they connect to a set of neurons in the globus palladus, which inhibits dopamine output. This pathway, an indirect connection to the substantia nigra, reduces the brain’s dopamine output and inhibits movement.&lt;/p&gt;&lt;p&gt;The researchers also confirmed their earlier finding that the pathway arising from D1 striosomes connects directly to the substantia nigra, stimulating dopamine release and initiating movement.&lt;/p&gt;&lt;p&gt;“In the striosomes, we’ve found what is probably a mimic of the classical go/no-go pathways,” Graybiel says. “They’re like classic motor go/no-go pathways, but they don’t go to the motor output neurons of the basal ganglia. Instead, they go to the dopamine cells, which are so important to movement and motivation.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Emotional decisions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The findings suggest that the classical model of how the striatum controls movement needs to be modified to include the role of these newly identified pathways. The researchers now hope to test their hypothesis that input related to motivation and emotion, which enters the striosomes from the cortex and the limbic system, influences dopamine levels in a way that can encourage or discourage action.&lt;/p&gt;&lt;p&gt;That dopamine release may be especially relevant for actions that induce anxiety or stress. In their 2015 study, Graybiel’s lab found that striosomes play a key role in making decisions that provoke high levels of anxiety; in particular, those that are high risk but may also have a big payoff.&lt;/p&gt;&lt;p&gt;“Ann Graybiel and colleagues have earlier found that the striosome is concerned with inhibiting dopamine neurons. Now they show unexpectedly that another type of striosomal neuron exerts the opposite effect and can signal reward. The striosomes can thus both up- or down-regulate dopamine activity, a very important discovery. Clearly, the regulation of dopamine activity is critical in our everyday life with regard to both movements and mood, to which the striosomes contribute,” says Sten Grillner, a professor of neuroscience at the Karolinska Institute in Sweden, who was not involved in the research.&lt;/p&gt;&lt;p&gt;Another possibility the researchers plan to explore is whether striosomes and matrix cells are arranged in modules that affect motor control of specific parts of the body.&lt;/p&gt;&lt;p&gt;“The next step is trying to isolate some of these modules, and by simultaneously working with cells that belong to the same module, whether they are in the matrix or striosomes, try to pinpoint how the striosomes modulate the underlying function of each of these modules,” Lazaridis says.&lt;/p&gt;&lt;p&gt;They also hope to explore how the striosomal circuits, which project to the same region of the brain that is ravaged by Parkinson’s disease, may influence that disorder.&lt;/p&gt;&lt;p&gt;The research was funded by the National Institutes of Health, the Saks-Kavanaugh Foundation, the William N. and Bernice E. Bumpus Foundation, Jim and Joan Schattinger, the Hock E. Tan and K. Lisa Yang Center for Autism Research, Robert Buxton, the Simons Foundation, the CHDI Foundation, and an Ellen Schapiro and Gerald Axelbaum Investigator BBRF Young Investigator Grant.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202410/MIT-StriatalCircuits-01-press.jpg?itok=J3HbK8Mz" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[MIT researchers have discovered an additional two pathways that arise in the striatum, pictured in the center of the brain in orange.]]></media:description>
              <media:credit>Image: MIT News; iStock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/nih">National Institutes of Health (NIH)</category>
    </item>
<item>
  <title>Seven with MIT ties elected to National Academy of Medicine for 2024</title>
  <link>https://news.mit.edu/2024/seven-mit-ties-elected-national-academy-medicine-1022</link>
  <description><![CDATA[Professors Matthew Vander Heiden and Fan Wang, along with five MIT alumni, are honored for their outstanding professional achievement and commitment to service.]]></description>
  <pubDate>Tue, 22 Oct 2024 12:55:00 -0400</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/seven-mit-ties-elected-national-academy-medicine-1022</guid>
        <dc:creator>Nina Tamburello | Koch Institute</dc:creator>
  <content:encoded>&lt;div&gt;&lt;p paraid="1416075140" paraeid="{e18041f1-705b-4396-a0a5-3e305cc5b287}{220}"&gt;The National Academy of Medicine recently announced the election of more than 90 members during its annual meeting, including MIT faculty members Matthew Vander Heiden and Fan Wang, along with five MIT alumni.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="925467777" paraeid="{e18041f1-705b-4396-a0a5-3e305cc5b287}{236}"&gt;Election to the National Academy of Medicine (NAM) is considered one of the highest honors in the fields of health and medicine and recognizes individuals who have demonstrated outstanding professional achievement and commitment to service.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="1777304029" paraeid="{e18041f1-705b-4396-a0a5-3e305cc5b287}{242}"&gt;&lt;a href="https://ki.mit.edu/people/faculty/matthew-vander-heiden" target="_blank" rel="noreferrer noopener"&gt;Matthew Vander Heiden&lt;/a&gt; is the director of the Koch Institute for Integrative Cancer Research at MIT, a Lester Wolfe Professor of Molecular Biology, and a member of the Broad Institute of MIT and Harvard. His research explores how cancer cells reprogram their metabolism to fuel tumor growth and has provided key insights into metabolic pathways that support cancer progression, with implications for developing new therapeutic strategies. The National Academy of Medicine recognized Vander Heiden for his contributions to “the development of approved therapies for cancer and anemia” and his role as a “thought leader in understanding metabolic phenotypes and their relations to disease pathogenesis.”&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="2124537010" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{20}"&gt;Vander Heiden earned his MD and PhD from the University of Chicago and completed  his clinical training in internal medicine and medical oncology at the Brigham and Women’s Hospital and the Dana-Farber Cancer Institute. After postdoctoral research at Harvard Medical School, Vander Heiden joined the faculty of the MIT Department of Biology and the Koch Institute in 2010. He is also a practicing oncologist and instructor in medicine at Dana-Farber Cancer Institute and Harvard Medical School.&amp;nbsp;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="770488867" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{55}"&gt;&lt;a href="https://mcgovern.mit.edu/profile/fan-wang/" target="_blank" rel="noreferrer noopener"&gt;Fan Wang&lt;/a&gt; is a professor of brain and cognitive sciences, an investigator at the McGovern Institute, and director of the K. Lisa Yang and Hock E. Tan Center for Molecular Therapeutics at MIT.  Wang’s research focuses on the neural circuits governing the bidirectional interactions between the brain and body. She is specifically interested in the circuits that control the sensory and emotional aspects of pain and addiction, as well as the sensory and motor circuits that work together to execute behaviors such as eating, drinking, and moving. The National Academy of Medicine has recognized her body of work for “providing the foundational knowledge to develop new therapies to treat chronic pain and movement disorders.”&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="1416155071" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{70}"&gt;Before coming to MIT in 2021, Wang obtained her PhD from Columbia University and received her postdoctoral training at the University of California at San Francisco and Stanford University. She became a faculty member at Duke University in 2003 and was later appointed the Morris N. Broad Professor of Neurobiology. Wang is also a member of the American Academy of Arts and Sciences and she continues to make important contributions to the neural mechanisms underlying general anesthesia, pain perception, and movement control. &lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="472848738" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{80}"&gt;MIT alumni who were elected to the NAM for 2024 include:&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;ul role="list"&gt;&lt;li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" aria-setsize="-1" data-aria-posinset="1" data-aria-level="1" role="listitem"&gt;&lt;p paraid="1158086277" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{86}"&gt;Leemore Dafny PhD ’01 (Economics);&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;ul role="list"&gt;&lt;li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" aria-setsize="-1" data-aria-posinset="2" data-aria-level="1" role="listitem"&gt;&lt;p paraid="1400669042" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{102}"&gt;David Huang ’85 MS ’89&amp;nbsp; (Electrical Engineering and Computer Science) PhD ’93 Medical Engineering and Medical Physics);&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;ul role="list"&gt;&lt;li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" aria-setsize="-1" data-aria-posinset="3" data-aria-level="1" role="listitem"&gt;&lt;p paraid="1111953983" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{114}"&gt;Nola M. Hylton ’79 (Chemical Engineering);&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;ul role="list"&gt;&lt;li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" aria-setsize="-1" data-aria-posinset="4" data-aria-level="1" role="listitem"&gt;&lt;p paraid="993753622" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{126}"&gt;Mark R. Prausnitz PhD ’94 (Chemical Engineering); and&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;ul role="list"&gt;&lt;li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&amp;quot;335552541&amp;quot;:1,&amp;quot;335559685&amp;quot;:720,&amp;quot;335559991&amp;quot;:360,&amp;quot;469769226&amp;quot;:&amp;quot;Symbol&amp;quot;,&amp;quot;469769242&amp;quot;:[8226],&amp;quot;469777803&amp;quot;:&amp;quot;left&amp;quot;,&amp;quot;469777804&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;469777815&amp;quot;:&amp;quot;hybridMultilevel&amp;quot;}" aria-setsize="-1" data-aria-posinset="5" data-aria-level="1" role="listitem"&gt;&lt;p paraid="1427834830" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{138}"&gt;Konstantina M. Stankovic ’92 (Biology and Physics) PhD ’98 (Speech and Hearing Bioscience and Technology)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="533150799" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{174}"&gt;Established originally as the Institute of Medicine in 1970 by the National Academy of Sciences, the National Academy of Medicine addresses critical issues in health, science, medicine, and related policy and inspires positive actions across sectors.&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;p paraid="1772316274" paraeid="{d1c95ab9-8194-44bd-b841-bf09b80dec4b}{180}"&gt;“This class of new members represents the most exceptional researchers and leaders in health and medicine, who have made significant breakthroughs, led the response to major public health challenges, and advanced health equity,” said National Academy of Medicine President Victor J. Dzau. “Their expertise will be necessary to supporting NAM’s work to address the pressing health and scientific challenges we face today.”&amp;nbsp;&lt;/p&gt;&lt;/div&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202410/MIT-NAM-2024.png?itok=7rqAmLoo" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Professors Matthew Vander Heiden (left) and Fan Wang, along with 5 MIT alumni, were elected to the National Academy of Medicine for 2024.]]></media:description>
              <media:credit>Photos: Steve Boxall (left) and Caitlin Cunningham.</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/awards">Awards, honors and fellowships</category>
      <category domain="https://news.mit.edu/topic/faculty">Faculty</category>
      <category domain="https://news.mit.edu/topic/alumni">Alumni/ae</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/biology">Biology</category>
      <category domain="https://news.mit.edu/topic/koch-institute-0">Koch Institute</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/broad-institute">Broad Institute</category>
      <category domain="https://news.mit.edu/topic/cancer-research">Cancer</category>
      <category domain="https://news.mit.edu/topic/disease">Disease</category>
      <category domain="https://news.mit.edu/topic/health-care">Health care</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/medicine">Medicine</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
    </item>
<item>
  <title>Model reveals why debunking election misinformation often doesn’t work</title>
  <link>https://news.mit.edu/2024/model-reveals-why-debunking-election-misinformation-often-doesnt-work-1015</link>
  <description><![CDATA[The new study also identifies factors that can make these efforts more successful. ]]></description>
  <pubDate>Tue, 15 Oct 2024 10:00:00 -0400</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/model-reveals-why-debunking-election-misinformation-often-doesnt-work-1015</guid>
        <dc:creator>Anne Trafton | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;When an election result is disputed, people who are skeptical about the outcome&amp;nbsp;may be swayed by figures of authority who come down on one side or the other. Those figures can be independent monitors, political figures, or news organizations. However, these “debunking” efforts don’t always have the desired effect, and in some cases, they can lead people to cling more tightly to their original position.&lt;/p&gt;&lt;p&gt;Neuroscientists and political scientists at MIT and the University of California at Berkeley have now created a computational model that analyzes the factors that help to determine whether debunking efforts will persuade people to change their beliefs about the legitimacy of an election. Their findings suggest that while debunking fails much of the time, it can be successful under the right conditions.&lt;/p&gt;&lt;p&gt;For instance, the model showed that successful debunking is more likely if people are less certain of their original beliefs and if they believe the authority is unbiased or strongly motivated by a desire for accuracy. It also helps when an authority comes out in support of a result that goes against a bias they are perceived to hold: for example, Fox News declaring that Joseph R. Biden had won in Arizona in the 2020 U.S. presidential election.&lt;/p&gt;&lt;p&gt;“When people see an act of debunking, they treat it as a human action and understand it the way they understand human actions — that is, as something somebody did for their own reasons,” says Rebecca Saxe,&amp;nbsp;the John W. Jarve Professor of Brain and Cognitive Sciences, a member of MIT’s McGovern Institute for Brain Research, and the senior author of the study. “We’ve used a very simple, general model of how people understand other people’s actions, and found that that’s all you need to describe this complex phenomenon.”&lt;/p&gt;&lt;p&gt;The findings could have implications as the United States prepares for the presidential election taking place on Nov. 5, as they help to reveal the conditions that would be most likely to result in people accepting the election outcome.&lt;/p&gt;&lt;p&gt;MIT graduate student Setayesh Radkani is the lead author of the paper, which &lt;a href="https://academic.oup.com/pnasnexus/article/3/10/pgae393/7821174" target="_blank"&gt;appears today in a special election-themed issue of the journal &lt;em&gt;PNAS Nexus&lt;/em&gt;&lt;/a&gt;. Marika Landau-Wells PhD ’18, a former MIT postdoc who is now an assistant professor of political science at the University of California at Berkeley,&amp;nbsp;is also an author of the study.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Modeling motivation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In their work on election debunking, the MIT team took a novel approach, building on Saxe’s extensive work studying “theory of mind” —&amp;nbsp;how people think about the thoughts and motivations of other people.&lt;/p&gt;&lt;p&gt;As part of her PhD thesis, Radkani has been developing a computational model of the cognitive processes that occur when people see others being punished by an authority. Not everyone interprets punitive actions the same way, depending on their previous beliefs about the action and the authority. Some may see the authority as acting legitimately to punish an act that was wrong, while others may see an authority overreaching to issue an unjust punishment.&lt;/p&gt;&lt;p&gt;Last year, after participating in an MIT workshop on the topic of polarization in societies, Saxe and Radkani had the idea to apply the model to how people react to an authority attempting to sway their political beliefs. They enlisted Landau-Wells, who received her PhD in political science before working as a postdoc in Saxe’s lab, to join their effort, and Landau suggested applying the model to debunking of beliefs regarding the legitimacy of an election result.&lt;/p&gt;&lt;p&gt;The computational model created by Radkani is based on Bayesian inference, which allows the model to continually update its predictions of people’s beliefs as they receive new information. This approach treats debunking as an action that a person undertakes for his or her own reasons. People who observe the authority’s statement then make their own interpretation of why the person said what they did. Based on that interpretation, people may or may not change their own beliefs about the election result.&lt;/p&gt;&lt;p&gt;Additionally, the model does not assume that any beliefs are necessarily incorrect or that any group of people is acting irrationally.&lt;/p&gt;&lt;p&gt;“The only assumption that we made is that there are two groups in the society that differ in their perspectives about a topic: One of them thinks that the election was stolen and the other group doesn’t,” Radkani says. “Other than that, these groups are similar. They share their beliefs about the authority — what the different motives of the authority are and how motivated the authority is by each of those motives.”&lt;/p&gt;&lt;p&gt;The researchers modeled&amp;nbsp;more than 200 different scenarios in which an authority attempts to debunk a belief held by one group regarding the validity of an election outcome.&lt;/p&gt;&lt;p&gt;Each time they ran the model, the researchers altered the certainty levels of each group’s original beliefs, and they also varied the groups’ perceptions of the motivations of the authority. In some cases, groups believed the authority was motivated by promoting accuracy, and in others they did not. The researchers also altered the groups’ perceptions of whether the authority was biased toward a particular viewpoint, and how strongly the groups believed in those perceptions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building consensus&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In each scenario, the researchers used the model to predict how each group would respond to a series of five statements made by an authority trying to convince them that the election had been legitimate. The researchers found that in most of the scenarios they looked at, beliefs remained polarized and in some cases&amp;nbsp;became even further polarized. This polarization could also extend to new topics unrelated to the original context of the election, the researchers found.&lt;/p&gt;&lt;p&gt;However, under some circumstances, the debunking was successful, and beliefs converged on an accepted outcome. This was more likely to happen when people were initially more uncertain about their original beliefs.&lt;/p&gt;&lt;p&gt;“When people are very, very certain, they become hard to move. So, in essence, a lot of this authority debunking doesn’t matter,” Landau-Wells says. “However, there are a lot of people who are in this uncertain band. They have doubts, but they don’t have firm beliefs. One of the lessons from this paper is that we’re in a space where the model says you can affect people’s beliefs and move them towards true things.”&lt;/p&gt;&lt;p&gt;Another factor that can lead to belief convergence is if people believe that the authority is unbiased and highly motivated by accuracy. Even more persuasive is when an authority makes a claim that goes against their perceived bias — for instance,&amp;nbsp;Republican governors stating that elections in their states had been fair even though the Democratic candidate won.&lt;/p&gt;&lt;p&gt;As the 2024 presidential election approaches, grassroots efforts have been made to train nonpartisan election observers who can vouch for whether an election was legitimate. These types of organizations may be well-positioned to help sway people who might have doubts about the election’s legitimacy, the researchers say.&lt;/p&gt;&lt;p&gt;“They’re trying to train to people to be independent, unbiased, and committed to the truth of the outcome more than anything else. Those are the types of entities that you want. We want them to succeed in being seen as independent. We want them to succeed as being seen as truthful, because in this space of uncertainty, those are the voices that can move people toward an accurate outcome,” Landau-Wells says.&lt;/p&gt;&lt;p&gt;The research was funded, in part, by the Patrick J. McGovern Foundation and the Guggenheim Foundation.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202410/MIT-Polarization-Models-01-press.jpg?itok=Fss7MKDp" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[Scientists at MIT and the University of California at Berkeley have created a computational model that analyzes the factors that help to determine whether debunking efforts will persuade people to change their beliefs about the legitimacy of an election.]]></media:description>
              <media:credit>Credit: MIT News, iStock</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/research">Research</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/voting">Voting and elections</category>
      <category domain="https://news.mit.edu/topic/behavior">Behavior</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
    </item>
<item>
  <title>Tiny magnetic discs offer remote brain stimulation without transgenes</title>
  <link>https://news.mit.edu/2024/tiny-magnetic-discs-offer-remote-brain-stimulation-without-transgenes-1011</link>
  <description><![CDATA[The devices could be a useful tool for biomedical research, and possible clinical use in the future.]]></description>
  <pubDate>Fri, 11 Oct 2024 05:00:00 -0400</pubDate>
    <guid isPermaLink="true">https://news.mit.edu/2024/tiny-magnetic-discs-offer-remote-brain-stimulation-without-transgenes-1011</guid>
        <dc:creator>David L. Chandler | MIT News</dc:creator>
  <content:encoded>&lt;p&gt;Novel magnetic nanodiscs could provide a much less invasive way of stimulating parts of the brain, paving the way for stimulation therapies without implants or genetic modification, MIT researchers report.&lt;/p&gt;&lt;p&gt;The scientists envision that the tiny discs, which are about 250 nanometers across (about 1/500 the width of a human hair), would be injected directly into the desired location in the brain. From there, they could be activated at any time simply by applying a magnetic field outside the body. The new particles could quickly find applications in biomedical research, and eventually, after sufficient testing, might be applied to clinical uses.&lt;/p&gt;&lt;p&gt;The development of these nanoparticles is &lt;a href="https://www.nature.com/articles/s41565-024-01798-9" target="_blank"&gt;described in the journal &lt;em&gt;Nature Nanotechnology&lt;/em&gt;&lt;/a&gt;, in a paper by Polina Anikeeva, a professor in MIT’s departments of Materials Science and Engineering and Brain and Cognitive Sciences, graduate student Ye Ji Kim, and 17 others at MIT and in Germany.&lt;/p&gt;&lt;p&gt;Deep brain stimulation (DBS) is a common clinical procedure that uses electrodes implanted in the target brain regions to treat symptoms of neurological and psychiatric conditions such as Parkinson’s disease and obsessive-compulsive disorder. Despite its efficacy, the surgical difficulty and clinical complications associated with DBS limit the number of cases where such an invasive procedure is warranted. The new nanodiscs could provide a much more benign way of achieving the same results.&lt;/p&gt;&lt;p&gt;Over the past decade other implant-free methods of producing brain stimulation have been developed. However, these approaches were often limited by their spatial resolution or ability to target deep regions. For the past decade, Anikeeva’s Bioelectronics group as well as others in the field used magnetic nanomaterials to transduce remote magnetic signals into brain stimulation. However, these magnetic methods relied on genetic modifications and can’t be used in humans.&lt;/p&gt;&lt;p&gt;Since all nerve cells are sensitive to electrical signals, Kim, a graduate student in Anikeeva’s group, hypothesized that a magnetoelectric nanomaterial that can efficiently convert magnetization into electrical potential could offer a path toward remote magnetic brain stimulation. Creating a nanoscale magnetoelectric material was, however, a formidable challenge.&lt;/p&gt;&lt;p&gt;Kim synthesized novel magnetoelectric nanodiscs and collaborated with Noah Kent, a postdoc in Anikeeva’s lab with a background in physics who is a second author of the study, to understand the properties of these particles.&lt;/p&gt;&lt;p&gt;The structure of the new nanodiscs consists of a two-layer magnetic core and a piezoelectric shell. The magnetic core is magnetostrictive, which means it changes shape when magnetized. This deformation then induces strain in the piezoelectric shell which produces a varying electrical polarization. Through the combination of the two effects, these composite particles can deliver electrical pulses to neurons when exposed to magnetic fields.&lt;/p&gt;&lt;p&gt;One key to the discs’ effectiveness is their disc shape. Previous attempts to use magnetic nanoparticles had used spherical particles, but the magnetoelectric effect was very weak, says Kim. This anisotropy enhances magnetostriction by over a 1000-fold, adds Kent.&lt;/p&gt;&lt;p&gt;The team first added their nanodiscs to cultured neurons, which allowed then to activate these cells on demand with short pulses of magnetic field. This stimulation did not require any genetic modification.&lt;/p&gt;&lt;p&gt;They then injected small droplets of magnetoelectric nanodiscs solution into specific regions of the brains of mice. Then, simply turning on a relatively weak electromagnet nearby triggered the particles to release a tiny jolt of electricity in that brain region. The stimulation could be switched on and off remotely by the switching of the electromagnet. That electrical stimulation “had an impact on neuron activity and on behavior,” Kim says.&lt;/p&gt;&lt;p&gt;The team found that the magnetoelectric nanodiscs could stimulate a deep brain region, the ventral tegmental area, that is associated with feelings of reward.&lt;/p&gt;&lt;p&gt;The team also stimulated another brain area, the subthalamic nucleus, associated with motor control. “This is the region where electrodes typically get implanted to manage Parkinson’s disease,” Kim explains. The researchers were able to successfully demonstrate the&amp;nbsp;modulation of motor control through the particles. Specifically, by injecting nanodiscs only in one hemisphere, the researchers could induce rotations in healthy mice by applying magnetic field.&lt;/p&gt;&lt;p&gt;The nanodiscs could trigger the neuronal activity comparable with&amp;nbsp;conventional implanted electrodes delivering mild electrical stimulation. The authors achieved subsecond temporal precision for neural stimulation with their method yet observed significantly reduced foreign body responses as compared to the electrodes, potentially allowing for even&amp;nbsp;safer deep brain stimulation.&lt;/p&gt;&lt;p&gt;The multilayered chemical composition and physical shape&amp;nbsp;and size of the new multilayered nanodiscs is what made precise&amp;nbsp;stimulation&amp;nbsp;possible.&lt;/p&gt;&lt;p&gt;While the researchers successfully increased the magnetostrictive effect, the second part of the process, converting the magnetic effect into an electrical output, still needs more work, Anikeeva says. While the magnetic response was a thousand times greater, the conversion to an electric impulse was only four times greater than with conventional spherical particles.&lt;/p&gt;&lt;p&gt;“This massive enhancement of a thousand times didn’t completely translate into the magnetoelectric enhancement,” says Kim. “That’s where a lot of the future work will be focused, on making sure that the thousand times amplification in magnetostriction can be converted into a thousand times amplification in the magnetoelectric coupling.”&lt;/p&gt;&lt;p&gt;What the team found, in terms of the way the particles’ shapes affects their magnetostriction, was quite unexpected. “It’s kind of a new thing that just appeared when we tried to figure out why these particles worked so well,” says Kent.&lt;/p&gt;&lt;p&gt;Anikeeva adds: “Yes, it’s a record-breaking particle, but it’s not as record-breaking as it could be.” That remains a topic for further work, but the team has ideas about how to make further progress.&lt;/p&gt;&lt;p&gt;While these nanodiscs could in principle already be applied to basic research using animal models, to translate them to clinical use in humans would require several more steps, including large-scale safety studies, “which is something academic researchers are not necessarily most well-positioned to do,” Anikeeva says. “When we find that these particles are really useful in a particular clinical context, then we imagine that there will be a pathway for them to undergo more rigorous large animal safety studies.”&lt;/p&gt;&lt;p&gt;The team included researchers affiliated with MIT’s departments of Materials Science and Engineering, Electrical Engineering and Computer Science, Chemistry, and Brain and Cognitive Sciences; the Research Laboratory of Electronics; the McGovern Institute for Brain Research; and the Koch Institute for Integrative Cancer Research; and from the Friedrich-Alexander University of Erlangen, Germany. The work was supported, in part, by the National Institutes of Health, the National Center for Complementary and Integrative Health, the National Institute for Neurological Disorders and Stroke, the McGovern Institute for Brain Research, and the K. Lisa Yang and Hock E. Tan Center for Molecular Therapeutics in Neuroscience.&lt;/p&gt;</content:encoded>
      <media:content url="https://news.mit.edu/sites/default/files/styles/news_article__cover_image__original/public/images/202410/MIT-BrainStimulation-01-press.jpg?itok=uEIPzzAh" medium="image" type="image/jpeg" width="390" height="260">
              <media:description type="plain"><![CDATA[The magnetic core of the nanodisc is magnetostrictive, which means it changes shape when magnetized. The rainbow nanodisc on the right is changing shape, allowing for the pink brain neuron to be stimulated.]]></media:description>
              <media:credit>Image: Courtesy of the researchers</media:credit>
      </media:content>
        <category domain="https://news.mit.edu/topic/materialsscienceandengineering">Materials science and engineering</category>
      <category domain="https://news.mit.edu/topic/brain-cognitive">Brain and cognitive sciences</category>
      <category domain="https://news.mit.edu/topic/medicine">Medicine</category>
      <category domain="https://news.mit.edu/topic/mcgovern-institute-0">McGovern Institute</category>
      <category domain="https://news.mit.edu/topic/research-laboratory-electronics-1">Research Laboratory of Electronics</category>
      <category domain="https://news.mit.edu/topic/dmse">DMSE</category>
      <category domain="https://news.mit.edu/topic/school-engineering">School of Engineering</category>
      <category domain="https://news.mit.edu/topic/school-science">School of Science</category>
      <category domain="https://news.mit.edu/topic/nanotech">Nanoscience and nanotechnology</category>
      <category domain="https://news.mit.edu/topic/neuroscience">Neuroscience</category>
    </item>

  </channel>
</rss>
